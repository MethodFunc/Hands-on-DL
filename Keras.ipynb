{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore', '^internal gelsd')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(x_train_full, y_train_full), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid = 유효한\n",
    "x_valid, x_train = x_train_full[:5000] / 255.0, x_train_full[5000:] / 255.0\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names=['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coat'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names[y_train[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x345.6 with 40 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_rows = 4\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(x_train[index], cmap='binary', interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "        plt.title(class_names[y_train[index]], fontsize=12)\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 스퀸셜 API를 사용하여 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dence = 밀집한, Flatten = 납작해지다\n",
    "# # 모델 생성\n",
    "# model = keras.models.Sequential()\n",
    "# # 1D 배열로 변환한다. X 데이터를 받으면 reshape(-1, 1) \n",
    "# model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "# # 300개의 히든레이아웃 생성\n",
    "# model.add(keras.layers.Dense(300, activation='relu'))\n",
    "# model.add(keras.layers.Dense(100, activation='relu'))\n",
    "# model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트로 한번에 제작이 가능하다.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.core.Flatten at 0x24857ce4708>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x24857ce4ac8>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x24857abbb48>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x248579f9348>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모든 층을 출력함\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden1 = model.layers[1]\n",
    "hidden1.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('dense') is hidden1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights, biases = hidden1.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02550732, -0.02735044, -0.00519114, ..., -0.04180191,\n",
       "         0.02375359, -0.05850173],\n",
       "       [ 0.01946905, -0.06714166, -0.06517482, ..., -0.02281709,\n",
       "        -0.01701074, -0.03685649],\n",
       "       [ 0.06905811,  0.02847452,  0.04594326, ..., -0.02647167,\n",
       "        -0.03864872,  0.00228655],\n",
       "       ...,\n",
       "       [ 0.01645738, -0.04891685, -0.0058926 , ...,  0.01014884,\n",
       "        -0.05363333, -0.02499604],\n",
       "       [ 0.07228859, -0.04023219, -0.00766204, ..., -0.02889049,\n",
       "         0.05326839,  0.04322128],\n",
       "       [-0.06252505,  0.05052356, -0.02754802, ...,  0.0384405 ,\n",
       "        -0.05583369, -0.0704309 ]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 300)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Compiler\n",
    "model.compile(\n",
    "#               loss = keras.losses.sparse_categorical_crossentropy,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              # optimizer = 'SGD',\n",
    "              optimizer = keras.optimizers.SGD(lr = 0.01),\n",
    "#               metrics = [keras.metrics.sparse_categorical_accuracy]\n",
    "              metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(),\n",
    "              metrics=[keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/30\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.7292 - accuracy: 0.7585 - val_loss: 0.5140 - val_accuracy: 0.8300\n",
      "Epoch 2/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.4915 - accuracy: 0.8279 - val_loss: 0.4386 - val_accuracy: 0.8548\n",
      "Epoch 3/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.4456 - accuracy: 0.8437 - val_loss: 0.4560 - val_accuracy: 0.8320\n",
      "Epoch 4/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.4178 - accuracy: 0.8531 - val_loss: 0.4085 - val_accuracy: 0.8534\n",
      "Epoch 5/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3987 - accuracy: 0.8598 - val_loss: 0.3830 - val_accuracy: 0.8686\n",
      "Epoch 6/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3824 - accuracy: 0.8651 - val_loss: 0.3723 - val_accuracy: 0.8688\n",
      "Epoch 7/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3679 - accuracy: 0.8700 - val_loss: 0.4643 - val_accuracy: 0.8310\n",
      "Epoch 8/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3570 - accuracy: 0.8729 - val_loss: 0.3900 - val_accuracy: 0.8578\n",
      "Epoch 9/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3458 - accuracy: 0.8774 - val_loss: 0.3501 - val_accuracy: 0.8776\n",
      "Epoch 10/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3366 - accuracy: 0.8801 - val_loss: 0.3551 - val_accuracy: 0.8762\n",
      "Epoch 11/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3276 - accuracy: 0.8825 - val_loss: 0.3413 - val_accuracy: 0.8784\n",
      "Epoch 12/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3206 - accuracy: 0.8855 - val_loss: 0.3304 - val_accuracy: 0.8800\n",
      "Epoch 13/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3118 - accuracy: 0.8879 - val_loss: 0.3490 - val_accuracy: 0.8730\n",
      "Epoch 14/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3045 - accuracy: 0.8899 - val_loss: 0.3253 - val_accuracy: 0.8812\n",
      "Epoch 15/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2980 - accuracy: 0.8922 - val_loss: 0.3251 - val_accuracy: 0.8834\n",
      "Epoch 16/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2919 - accuracy: 0.8945 - val_loss: 0.3419 - val_accuracy: 0.8778\n",
      "Epoch 17/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2864 - accuracy: 0.8965 - val_loss: 0.3183 - val_accuracy: 0.8836\n",
      "Epoch 18/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2807 - accuracy: 0.8991 - val_loss: 0.3284 - val_accuracy: 0.8812\n",
      "Epoch 19/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2749 - accuracy: 0.9006 - val_loss: 0.3348 - val_accuracy: 0.8816\n",
      "Epoch 20/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2704 - accuracy: 0.9028 - val_loss: 0.3157 - val_accuracy: 0.8854\n",
      "Epoch 21/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2648 - accuracy: 0.9044 - val_loss: 0.3009 - val_accuracy: 0.8926\n",
      "Epoch 22/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2594 - accuracy: 0.9068 - val_loss: 0.3096 - val_accuracy: 0.8856\n",
      "Epoch 23/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2555 - accuracy: 0.9073 - val_loss: 0.3021 - val_accuracy: 0.8902\n",
      "Epoch 24/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2504 - accuracy: 0.9097 - val_loss: 0.3105 - val_accuracy: 0.8826\n",
      "Epoch 25/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2455 - accuracy: 0.9116 - val_loss: 0.2924 - val_accuracy: 0.8950\n",
      "Epoch 26/30\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.2427 - accuracy: 0.9122 - val_loss: 0.2941 - val_accuracy: 0.8958\n",
      "Epoch 27/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2384 - accuracy: 0.9133 - val_loss: 0.2890 - val_accuracy: 0.8934\n",
      "Epoch 28/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2331 - accuracy: 0.9153 - val_loss: 0.3200 - val_accuracy: 0.8828\n",
      "Epoch 29/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2298 - accuracy: 0.9173 - val_loss: 0.2922 - val_accuracy: 0.8932\n",
      "Epoch 30/30\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.2267 - accuracy: 0.9183 - val_loss: 0.2999 - val_accuracy: 0.8870\n"
     ]
    }
   ],
   "source": [
    "# model Training and Evalution\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75847274, 0.82789093, 0.84374547, 0.8530909, 0.8598, 0.86514544, 0.8700182, 0.8728727, 0.8774, 0.8800727, 0.8825455, 0.8854727, 0.8878545, 0.8898727, 0.8921818, 0.89452726, 0.89654547, 0.8990727, 0.9006182, 0.90276366, 0.90436363, 0.9067636, 0.9072545, 0.90974545, 0.9115818, 0.9122364, 0.91325456, 0.91532725, 0.9172909, 0.91834545]\n"
     ]
    }
   ],
   "source": [
    "print(history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n"
     ]
    }
   ],
   "source": [
    "# Training Epochs\n",
    "print(history.epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 30,\n",
       " 'steps': 1719,\n",
       " 'samples': 55000,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss', 'accuracy', 'val_loss', 'val_accuracy']}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Parmametor\n",
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(history.history).plot(figsize=(8, 5))\n",
    "plt.grid()\n",
    "plt.gca().set_ylim(0, 1)\n",
    "# plt.gca().set_xlim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'accuracy']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 - 0s - loss: 0.3375 - accuracy: 0.8814\n"
     ]
    }
   ],
   "source": [
    "# 모델평가\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.6306137e-07 6.0876069e-09 5.5575282e-07 1.5083679e-06 3.0279827e-07\n",
      " 1.0309373e-03 4.0361030e-07 4.5886342e-03 2.1923852e-05 9.9435544e-01]\n",
      "Ankle boot => Ankle boot\n"
     ]
    }
   ],
   "source": [
    "# 분류 예측하기\n",
    "predictions = model.predict(x_test)\n",
    "print(predictions[0])\n",
    "print(class_names[y_test[0]], '=>', class_names[np.argmax(predictions[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8958"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(history.history['val_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot => Ankle boot\n",
      "Pullover => Pullover\n",
      "Trouser => Trouser\n",
      "Trouser => Trouser\n",
      "Shirt => Shirt\n",
      "Trouser => Trouser\n",
      "Coat => Coat\n",
      "Shirt => Shirt\n",
      "Sandal => Sandal\n",
      "Sneaker => Sneaker\n",
      "Coat => Coat\n",
      "Sandal => Sandal\n",
      "Sneaker => Sneaker\n",
      "Dress => Dress\n",
      "Coat => Coat\n",
      "Trouser => Trouser\n",
      "Pullover => Pullover\n",
      "Coat => Pullover\n",
      "Bag => Bag\n",
      "T-shirt/top => T-shirt/top\n",
      "Pullover => Pullover\n",
      "Sandal => Sandal\n",
      "Sneaker => Sneaker\n",
      "Ankle boot => Sandal\n",
      "Trouser => Trouser\n",
      "Coat => Pullover\n",
      "Shirt => Shirt\n",
      "T-shirt/top => T-shirt/top\n",
      "Ankle boot => Ankle boot\n",
      "Dress => Shirt\n",
      "Bag => Bag\n",
      "Bag => Bag\n",
      "Dress => Dress\n",
      "Dress => Dress\n",
      "Bag => Bag\n",
      "T-shirt/top => T-shirt/top\n",
      "Sneaker => Sneaker\n",
      "Sandal => Sandal\n",
      "Sneaker => Sneaker\n",
      "Ankle boot => Ankle boot\n",
      "Shirt => T-shirt/top\n",
      "Trouser => Trouser\n",
      "Dress => Shirt\n",
      "Sneaker => Sneaker\n",
      "Shirt => Shirt\n",
      "Sneaker => Sneaker\n",
      "Pullover => Pullover\n",
      "Trouser => Trouser\n",
      "Pullover => Shirt\n",
      "Pullover => Shirt\n",
      "Coat => Coat\n",
      "Coat => Shirt\n",
      "Sandal => Sandal\n",
      "Bag => Bag\n",
      "Pullover => Pullover\n",
      "Pullover => Pullover\n",
      "Bag => Bag\n",
      "Coat => Shirt\n",
      "Bag => Bag\n",
      "T-shirt/top => T-shirt/top\n",
      "Sneaker => Sneaker\n",
      "Sneaker => Sneaker\n",
      "Bag => Bag\n",
      "Sandal => Sandal\n",
      "Trouser => Trouser\n",
      "Trouser => Trouser\n",
      "Pullover => Shirt\n",
      "Dress => Coat\n",
      "Ankle boot => Sneaker\n",
      "Bag => Bag\n",
      "Sneaker => Sneaker\n",
      "T-shirt/top => T-shirt/top\n",
      "Pullover => Pullover\n",
      "Shirt => Shirt\n",
      "Pullover => Pullover\n",
      "Dress => Dress\n",
      "Trouser => Trouser\n",
      "Pullover => Pullover\n",
      "Bag => Bag\n",
      "Coat => Coat\n",
      "Trouser => Trouser\n",
      "Bag => Bag\n",
      "Sandal => Sandal\n",
      "Ankle boot => Ankle boot\n",
      "Sandal => Sandal\n",
      "T-shirt/top => T-shirt/top\n",
      "Dress => Dress\n",
      "Pullover => Pullover\n",
      "T-shirt/top => T-shirt/top\n",
      "Shirt => Pullover\n",
      "Sandal => Sandal\n",
      "Dress => Dress\n",
      "Shirt => Shirt\n",
      "Sneaker => Sneaker\n",
      "Trouser => Trouser\n",
      "Bag => Bag\n",
      "T-shirt/top => T-shirt/top\n",
      "Trouser => Trouser\n",
      "Coat => Shirt\n",
      "Pullover => Pullover\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 100):\n",
    "    print(class_names[y_test[i]], '=>', class_names[np.argmax(predictions[i])])               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.99],\n",
       "       [0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ],\n",
       "       [0.  , 1.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = x_test[:3]\n",
    "y_proba = model.predict(x_new)\n",
    "y_proba.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict_classes(x_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser'], dtype='<U11')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1], dtype=uint8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:3]\n",
    "y_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 시퀀셜 API를 사용하여 회귀용 다층 퍼셉트론 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_full, x_test, y_train_full, y_test = train_test_split(housing.data, housing.target)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정규화\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Valid = 검증세트\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_valid = scaler.transform(x_valid)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=keras.losses.mean_squared_error, optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 36us/sample - loss: 1.0417 - val_loss: 0.5663\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4979 - val_loss: 0.4916\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4535 - val_loss: 0.4636\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4368 - val_loss: 0.4465\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4239 - val_loss: 0.4362\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4166 - val_loss: 0.4482\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4098 - val_loss: 0.4504\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4032 - val_loss: 0.4216\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3993 - val_loss: 0.4235\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3943 - val_loss: 0.4173\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3889 - val_loss: 0.4189\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3862 - val_loss: 0.4086\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3814 - val_loss: 0.4093\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3787 - val_loss: 0.4210\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3754 - val_loss: 0.4093\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3752 - val_loss: 0.4048\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3775 - val_loss: 0.4106\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3704 - val_loss: 0.3991\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3668 - val_loss: 0.4000\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3660 - val_loss: 0.3990\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=20, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 11us/sample - loss: 0.3736\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate(x_test, y_test)\n",
    "x_new = x_test[:3]           #새로운 샘플이라 생각하면됩니다.\n",
    "y_pred = model.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZCcd33n8fe3z+menkNzaHTOWMI6cBwbW7JlOxgkjiB7vTFkIbHx2o6zlMsJZsnWUoEcS9hNpXIQSIJDcBlwAYFYhnBYGDkQQMIEMLFlLNk6LctoNNY5uubume7+7R/PMzOt0Rw9Z/c8/XlVPfVcv+7+zqPWp5/+PUebcw4REZn/QsUuQEREZoYCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAmLCQDezR83slJm9NMZ6M7NPmdkhM9ttZtfOfJkiIjKRQvbQvwBsHmf9LcAqf7gf+Mz0yxIRkcmaMNCdc08DZ8dpcjvwJed5Bqg1s8UzVaCIiBQmMgPPsRQ4mjff5i87PrKhmd2PtxdPIpFYt3z58im94EA2x2vdUFdhVMdsSs8xm3K5HKFQaR+eKPUaVd/0qL7pKeX6Dh482O6caxx1pXNuwgG4DHhpjHXfAd6YN/8DYN1Ez7lu3To3VT/84Q/d2j99yv3frXum/Byzafv27cUuYUKlXqPqmx7VNz2lXB/wnBsjV2fiI6gNyN/VXgYcm4HnHZOZ0VyXpPVs92y+jIjIvDITgb4VuMc/2+UG4IJz7pLulpnWXJ+k9WzPbL+MiMi8MWEfupk9BmwEGsysDfgzIArgnHsY2AbcChwCeoD7ZqvYfM11SX788mmcc5iVXj+6iMhcmzDQnXN3TrDeAe+fsYoK1FKfpG8gx6nONE3VFXP98iIiJac0D+MWoLkuCaBuFxER37wP9CNnFOgiIjCPA33ZgiQhg9YzOtNFRATmcaDHIiEW1yTU5SIi4pu3gQ5et8sRBbqICDDPA72lPkmr+tBFRIB5HujN9UnOdPfTlc4UuxQRkaKb34E+eOqi9tJFROZ3oLfUVQLoni4iIszzQG+u18VFIiKD5nWg1ySi1CSiurhIRIR5Hujgn+miPXQRkfkf6N590RXoIiLzPtBb6pO8dq6XTDZX7FJERIpq3gd6c12STM5x7HxfsUsRESmqAAT64KmL6nYRkfI27wO9xT918YjORReRMjfvA72puoJYOKSrRUWk7M37QA+HjGV1uo2uiMi8D3SAlrqkLi4SkbIXiEAfPBfd+71qEZHyFIxAr6+kK53hbHd/sUsRESmaQAR6S51u0iUiEohA110XRUSCEuj+HroOjIpIOQtEoFdEwzRVx7WHLiJlLRCBDv6ZLtpDF5EyFqBAr9Tl/yJS1gIT6C31SU52pOkbyBa7FBGRoghMoA8eGD2qfnQRKVPBCfR6nekiIuUtMIGui4tEpNwFJtDrKmOk4hEFuoiUrcAEupmxvC7JkTM600VEylNgAh28bhftoYtIuSoo0M1ss5kdMLNDZvaRUdbXmNm3zWyXme0xs/tmvtSJtdQnOXqul1xOt9EVkfIzYaCbWRj4NHALcAVwp5ldMaLZ+4G9zrmrgY3AJ8wsNsO1Tmh5XZL+TI4THX1z/dIiIkVXyB769cAh59xh51w/sAW4fUQbB1SZmQEp4CyQmdFKC9Ciuy6KSBmziX7lx8zeDWx2zr3Pn78b2OCcezCvTRWwFVgLVAG/7Zz7zijPdT9wP0BTU9O6LVu2TKnorq4uUqnUJctP9eT4w6d7+d0rY7xpWXRKzz0TxqqvlJR6japvelTf9JRyfZs2bdrpnFs/6krn3LgD8B7gc3nzdwMPjWjzbuDvAAMuB14Fqsd73nXr1rmp2r59+6jL+zNZt/KPvuP+5t/2Tfm5Z8JY9ZWSUq9R9U2P6pueUq4PeM6NkauFdLm0Acvz5pcBx0a0uQ/4hv96h/xAX1vQx80MioZDLK1N0Hq2d65fWkSk6AoJ9GeBVWa2wj/QeQde90q+VuCtAGbWBKwBDs9koYVqqU/SqnPRRaQMTRjozrkM8CDwXWAf8FXn3B4ze8DMHvCb/Tlwk5m9CPwA+LBzrn22ih7P8rokR3RQVETKUKSQRs65bcC2Ecsezps+Bvz6zJY2NS11Sc73DHChd4CaRPEOjIqIzLVAXSkKw6cu6ja6IlJuAhfoy/WD0SJSpgIX6C31lYAuLhKR8hO4QE/FI9RXxmjV74uKSJkJXKCDf6aLulxEpMwEMtBb6hXoIlJ+ghnodUmOX+ilP5MrdikiInMmkIHeXF9JzsFr53ULABEpH8EM9KFTF3VgVETKRyADXRcXiUg5CmSgL6yKE4+EdGBURMpKIAPdzGjWTbpEpMwEMtDB/8FoBbqIlJHABnpzXSWtZ3sGf1FJRCTwAhzoCXr6s5zuShe7FBGRORHYQB+8SZe6XUSkXAQ20JvrdRtdESkvgQ30ZQsSmCnQRaR8BDbQ45Ewi6sr1OUiImUjsIEOXreLzkUXkXIR7EDXfdFFpIwEOtBb6itp70rT058pdikiIrMu0IE+eNdF/b6oiJSDsgh0dbuISDkIdKDrNroiUk4CHei1yRjVFRHtoYtIWQh0oIN3YFSnLopIOQh8oDfX6Ta6IlIegh/o9UnazvWQzek2uiISbIEP9Ja6JANZx7HzvcUuRURkVgU+0HUuuoiUi+AHer0CXUTKQ+ADfXFNgmjYdOqiiARe4AM9HDKWLUjSera72KWIiMyqggLdzDab2QEzO2RmHxmjzUYze8HM9pjZj2a2zOlprkuqy0VEAi8yUQMzCwOfBt4OtAHPmtlW59zevDa1wD8Bm51zrWa2cLYKnoqW+iTPt57DOYeZFbscEZFZUcge+vXAIefcYedcP7AFuH1Em/cC33DOtQI4507NbJnT01yXpLMvw/megWKXIiIya8y58S+4MbN34+15v8+fvxvY4Jx7MK/N3wNR4FeAKuAfnHNfGuW57gfuB2hqalq3ZcuWKRXd1dVFKpUquP3zJzN86hdpPnpjBStrwlN6zcmYbH3FUOo1qr7pUX3TU8r1bdq0aadzbv2oK51z4w7Ae4DP5c3fDTw0os0/As8AlUAD8DKwerznXbdunZuq7du3T6r9/uMdruXDT7onXnhtyq85GZOtrxhKvUbVNz2qb3pKuT7gOTdGrk7Yh47Xb748b34ZcGyUNu3OuW6g28yeBq4GDhbyiTPbltclAGg9ozNdRCS4CulDfxZYZWYrzCwG3AFsHdHmCeBmM4uYWRLYAOyb2VKnLhmL0FgV15kuIhJoE+6hO+cyZvYg8F0gDDzqnNtjZg/46x92zu0zs38DdgM5vC6al2az8Mlq0Q9Gi0jAFdLlgnNuG7BtxLKHR8x/HPj4zJU2s5rrk/zslTPFLkNEZNbMyytFk91tk35Mc12SEx199A1kZ6EiEZHim3+B/sJjXPfsB2DvE5N6WEt9Eueg7ZxuoysiwTT/Av31t9FRvRr+9Xdh35MFP6y5rhJA93QRkcCaf4Eer2L3VX8Gi98AX/sdOPBUQQ8bui+6DoyKSEDNv0AHspEk3P0NWPSr8NV74OD3JnxMQypGMhbWD0aLSGDNy0AHoKIG7v4mLLwCHr8LDn1/3OZm5t11UXvoIhJQ8zfQARK1Xqg3roHH3guvbB+3uW6jKyJBNr8DHSBZB/dshYZV8NgdcHjsW7G31HuBnsuNf0MyEZH5aP4HOvih/gTUrYR/+W345X+M2qy5vpJ0JsepzvQcFygiMvuCEegAlQ3envqCFvjKe+DITy9pMnSmi7pdRCSAghPoAKlGuPfbULMMvvxuaH3motUtfqAf0V0XRSSAghXoAKmFXqhXL/ZC/eizQ6uWLkgQMu2hi0gwBS/QAaoWeaGeaoQv/ya07QQgGg6xpDahQBeRQApmoANUL4F7n/QOmP7zu+DYLwDvTBfdRldEgii4gQ5Qs9QL9UQNfOmdcHwXzXWV2kMXkUAKdqAD1C73Qj1eBV+6nWtibZzt7qezb6DYlYmIzKjgBzp4pzLe+22IVvLO3Q+wxlr54JYXOKo9dREJkPIIdIC6FXDvVqLxJE+k/oqrDz/Cf//k1/nUD17Wj16ISCCUT6AD1L8O+50nqVh2FR8MfZXtkQ/whh338Td/+xc8vfdosasTEZmW8gp0gPrXed0vH9xF6M1/yPVVZ/ho+hNc/fj17Pjk3Zw68DNwuteLiMw/5RfogxZcBpv+mIoP7WHgrm9xsulN3HDhKRY+tpkzf7uOzH98CrpOF7tKEZGClW+gDwqFiK7axOrff5yzv/cSX2n8X7R2GpHv/x9yn1gLW+6C/dsgq7NiRKS0KdDzLFm0iLve/zEu3PUU9yYe4rMD76Dj5Z/Aljvhk1fA9/4UTu0vdpkiIqOKFLuAUrRxzUJu/N938ciPbuTG7fvZGNrFhxLPcdkzn8F++hAsuQZWboTlN8Dy672rUUVEikyBPoZ4JMwH3rqKd16zlP/35GI27b2G9Q338fE1+1lx4nvw04cg93de48a1sHwDNN/gjXVQVUSKQIE+geV1ST57z3p+uP8kH9u6l00/uZL/8qtv57bbark+/ir1Z34BR38Oe78Fz38RgJuitXDqZm8PvvkGWHQVRGJF/ktEJOgU6AV6y9ombnpdAw//6BUeefow33nxOABLaq7h2pa3sO6NNdxU3c7lfS9xdudWFp14EfZ923twJAFL10HzBr+b5jpILJjbP8A56DoFp/fD2cMsO7obfrwTMv2Q6YNMGrJpb5xJe8uyg+tGtAFY9Q649h5oumJu/w4RGZMCfRIqomH+4G2ref+my9l3vIOdR86x88g5nj9yjid3H/fbLKEl9QBvvXoFNy4c4BoOkDq10/uxjZ/8A+Q+4T1Z5ULvJ/OGhhXD04naqRfpHHS85gX36QN5w37oOz/U7HKAV/yZcBwi/pA/nT9fUT08398Nz30efv4ZWLreC/Yrf9O7X46IFI0CfQqi4RBXLavlqmW13PdrKwA4dr6X51u9gN/xUiuPPH2Yf8o5IMHKxnewrvkOrrsyzo0VR1javZfQucNw9lV49Uew618ufoFE3YiwzxuSdWAGuRxcaB0O66HxQejvvPi5Fr7eC9zGtdC4Buov58fP7uLmjW+DcMx7vsnqPgO7H/e6mb79P+Hf/giufBdcey8su25qzyki06JAnyFLahMsqU1w21VLeHPVaTbcdDO7286zs9Xbg//+vpN8bad3LntVxRWsXbSBNYuqWLO2mtc3RFkTO0NVTyucPTw8HH0GXvwakHeQNV4DVU1w/ihkeoeXp5q8sH7Dnd64ca03VDaMWm82csjb456qynq48ffhht+Dtue8YH/pG/CLL3uve+09cNUdXjsRmRMK9FmSiIXZsLKeDSu9QHPO8Wp7NzuPnOOFo+c5cKKTJ35xjM5069BjFtdUsGbRBtYsehtrrqxizaIqLq+LEu967eKg7zgGl78dGld74dmwuninTpp5xwSWXweb/9IL9ee/BN/9Y/j3P4PX3+aF+4qNENJlDyKzSYE+R8yMlY0pVjameM/65YAX8scu9HHgRAcHTnRx4EQH+0908pND7Qxkvb3ycMhY0VDJmkWNrGlayZqWKlY3VbG4poKKaLiYf9Kl4lWw7l5vOLkXfvHPsOsx2PNNqGmGa++GN7zX+xHvqXDOu2I3l4FoQt06IiMo0IvIzFham2BpbYK3rG0aWj6QzfHL9m72n+jkwIlO9p/o5MW2C3zHP/A6qLoiQlN1BQur4yysyhtXxb3lVXEWVsdJxorwz9x0hbfH/raPwf4nvb327X8BO/4SLrvZ+0aR6ffOpMmm86b7IZNmQ3cH7Az5836bbP/w84djUNnodSlVNkKyYXh6aHnefDQxM39XLusN8012wDtm037Q+5ZX2eh9w2tYrYPZAaJAL0HRcIhVTVWsaqriv149vLw7neHgyU4OneriZEcfpzrTQ+P/fPUspzvT9GdzlzxfVTxCY3X8oqDvODXAuZo2GlJxGqviNKbiLEjGCIVmeK83Eocr/5s3nPul18e+70mv2ygS94I5HPPO049XDU1faD9HYsnyEW3iEI5CKAK956G7HbpPe0P7Qe9mavnHFfLFUpCs98O/HvD39rMDkBvwP0z8+Wy/9y0gf9lgG+dt35ui1fDy6vEPXBdDuhPaD9J0Yjt8/0fedhkM8Vxm9MdUL4WGVdCwZjjkG9ZAaqG+Bc0zCvR5pDIe4ZrmBVzTPPo57M45zvcMXBT0pzr7ONXhjU92pHm+9RynOtKkMzkeP7DroseHQ0Z9ZYzGqvhw0OdPp+I0VsVoTFVQnYhgk/3PvuAyeMufesME9u/YwaKNGyf3/OCdUtl92g/7vMDvbocef77rBGD+B0XU23uvqIFQ1JsPR711ocjwh0nYnw5FwYz2/c+xJNYLrT8b/cB13WWjh32qafoh6Rx0nfSC+vQBaH8Z2v1xx2sAvB68+utWegG99jZv3LgaFqzwtkf7Qe9xp/3Qf+Er0N81/DoVNV6wDz6uYY0X/Asug9Acd/c5B30XoOeM92GeaoTqZTouM0JBgW5mm4F/AMLA55xzfzVGu+uAZ4Dfds7964xVKQUxMxZUxlhQGWPNorG/RjvneOr7O1j7hus43ZnmdFeadn98ujNNe1c/pzvTHDjRSXtXmkzu0lsZxMIh6lMxGlJxGgbHfvg3pGI05s3XJqIzv+c/llilNyy4bFZf5qDbwZLBD5yBPjg/4gylc6/C8V2wdyu4vC6aaBJqW7wPDee8dS7ndeO4XN58bsR81p92wxd8Df3NKS9oL7vZGzeu4T8PX+D6d/zW2FcoJ+u8kOa24WXOed+cBj8cTh/wgv7Qv8MLXx5uF455XVwV1V7ox/3xJfM1o6+PJgll03ChzQvo7nboOetNDw2jLBv5DSOSgIbLhz90GlZ54/rXzVwX2zwzYaCbWRj4NPB2oA141sy2Ouf2jtLur4HvzkahMnPMjGR0+CDteHI5x4XegUtC35vvp70rzanONHuPd3Cmq3/U8I+EjLq8Pf/6VIzqiiipeITKeIRURYRUPEwqHqUyHqYqHuVEd45TnX2k4hES0fDkvw3MpWiFf8bR6kvXZQfgwlGv//qsf+3B+SNeOFnY21sPhcFC/nwobz40Yj5vfW2zH2KroXrJJXv9PSd3TP52E2ZQs9QbXveWi9f1nvO/CRz0xj1nvD3mdIcXvmcPe/N9F7zuqXFfJ8SbXA5+POpK78MmWe99aNSt9K5rSNYPD4la6DwxXE/bs/DS1xn+lmTe9mkcEfQNq73Hl/J7aZoK2UO/HjjknDsMYGZbgNuBvSPafQD4OnDdjFYoRRUKDe/1r24a/+DZYPi3d/mB39VPe2ea9q7BwfsAOHSqi86+AbrSGUbJ/2E//oFXg3ndTVV5HwA1iSg1iSi1/rgmGRueTw6vq05Ei3s2UDg63N3CW4tXx3QlFnh3Fl1+/fjtnPO+PfR1DAd82h8PLkt3crjtJCuvvM47cJ0f1hU1U+vOGeiFM68Mf7sYPHbw6o8vPq6SWOAFezQxfIA7l/G+/QzOuyzXdXXA7ri/LueNB78l5TLDH7ChsNe1NTQd9qcjXnfQResi/gdyxLvQ79p7Jv93TsDcBHcGNLN3A5udc+/z5+8GNjjnHsxrsxT4F+AtwOeBJ0frcjGz+4H7AZqamtZt2bJlSkV3dXWRSo2/Z1lMpV4flEaNzjn6c9CbcfRloC/j6M1AX9ZxvqsPF4lftKwv47XtzTh6BqA74+ge8KbHexfHQpCMGqmoN66MGqnBcYzh6aiRinntKqNGLDz2nlwpbL/xqD6fyxFPt5PsaSPZ89rQOJQbwFkIZ+GhMYSGpgeyOcLRuD8f8teF8+bBXBZzubyxNw2XLhucHlx3smkjx5beOqU/adOmTTudc+tHW1fIHvpo7+qR/3/+Hviwcy473ldj59wjwCMA69evdxunctAL2LFjB1N97Fwo9fqg9GucTH25nKOzL8OF3gHO9/Z7454BLvQOD+d7Ll5+vHOAcz39pDOXnhU0KBENsyDp7f0vSEZZkIxRm4xSm4xy4mQrr69ppiIaJhENUxENUxEN+eOLpxOD85HwnB1LCNK/bzHMdn01wCgddNNWSKC3Acvz5pcBx0a0WQ9s8cO8AbjVzDLOuW/NSJUi4wiFzOtmSUZpJjmpx/YNZDnX08+5bu/D4HyPF/Tne7wPgXP++HzPAPtPdHjLewfI5hy8vG/StcbCISqiIaoqvG6h6sRw91F1xWD30fB0dSJKTSLij6PEIyV2MZmUlEIC/VlglZmtAF4D7gDem9/AObdicNrMvoDX5aIwl5JXEQ2zuCbB4prCz4pwzvGD7Tu47sY3kh7I0jeQo3cgS58/9PrL0pksvf3+8kxueF1/dugbRUffAK+2d3vTvRl6B8a/aCkeCVGTiJKMeXv/8WiYxOC3gUiYRMz7NtB+Ms0zvfuHvx343xTi0RCJaJhkLEIyHiYZC1MZi3jjeIR4JFTSB6CdcwxkHdGwlXSdxTJhoDvnMmb2IN7ZK2HgUefcHjN7wF//8CzXKFJSzIxIyKhJRCERndHnTmeydPRm6Ogb7i7q8AfvAyDDhZ6BoQ+Q3oEs6YEcZ7v7L/ow6erN8KO2V0e90Gz8v42LAj4RDVMZ9z8AYsPjsN91NJipxsh5Lp73JwaXHz6S5nvnXiTtf/ClMzlvGMjSn82NunxwGqAiGqKxyrsyujHlXRE9NK4avmK6rjJGJFw+56oXdB66c24bsG3EslGD3Dn3O9MvS6Q8xSNhGqvCNFZN406YDPcBZ3Nu6JvD0LeEfi/4u9MZevuzdPdn6enP0J32xj2jzJ/vHeDY+V56+rN092fI5dzwgTR30YjBEy2G5wfXu6H5EDkqz5wkHgkRj4aIhUPEo2HikRCpeIT6Su/bRDwSIh4JD7WLR8LEwkZHX4ZT/sVzr5zu4meHz3Ch99LTJc2gvnIw5IfH1YkolfEIlf4HV2UsQmXcn45H6Op3DGRzROfZh4GuFBUJsHDIhkKqlMzGQcd0JsvpTu+6iPzx6c6+ofnxLpa7xA+fIhYODX1DScW9bqpUPEIkZIRDXrdP2LzpUMgIGYQtbzpkhMwbhqfh1y5vYNPahTP694MCXUQCIh4Js2xBkmULxj8w7pzzv6F431K6/W8jw9MZdu05wOLll9Hdf/Hynv4sXekMmawjm3PknDdkc867iDd/OufIOofzl+W3ScbCCnQRkekyM/9YQGTMrq2m7sNs3LhqjiubvvnVQSQiImNSoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAqKgQDezzWZ2wMwOmdlHRll/l5nt9oefmtnVM1+qiIiMZ8JAN7Mw8GngFuAK4E4zu2JEs1eBNzvnrgL+HHhkpgsVEZHxFbKHfj1wyDl32DnXD2wBbs9v4Jz7qXPunD/7DLBsZssUEZGJmHNu/AZm7wY2O+fe58/fDWxwzj04RvsPAWsH249Ydz9wP0BTU9O6LVu2TKnorq4uUqnUlB47F0q9Pij9GlXf9Ki+6Snl+jZt2rTTObd+1JXOuXEH4D3A5/Lm7wYeGqPtJmAfUD/R865bt85N1fbt26f82LlQ6vU5V/o1qr7pUX3TU8r1Ac+5MXI1UsAHQhuwPG9+GXBsZCMzuwr4HHCLc+5MoZ82IiIyMwrpQ38WWGVmK8wsBtwBbM1vYGbNwDeAu51zB2e+TBERmciEe+jOuYyZPQh8FwgDjzrn9pjZA/76h4GPAvXAP5kZQMaN1ccjIiKzopAuF5xz24BtI5Y9nDf9PuCSg6AiIjJ3dKWoiEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQCnQRkYBQoIuIBIQCXUQkIBToIiIBoUAXEQkIBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCAU6CIiAaFAFxEJCAW6iEhAKNBFRAJCgS4iEhAKdBGRgFCgi4gEhAJdRCQgFOgiIgGhQBcRCQgFuohIQCjQRUQCQoEuIhIQBQW6mW02swNmdsjMPjLKejOzT/nrd5vZtTNfqoiIjGfCQDezMPBp4BbgCuBOM7tiRLNbgFX+cD/wmRmuU0REJlDIHvr1wCHn3GHnXD+wBbh9RJvbgS85zzNArZktnuFaRURkHJEC2iwFjubNtwEbCmizFDie38jM7sfbgwfoMrMDk6p2WAPQPsXHzoVSrw9Kv0bVNz2qb3pKub6WsVYUEug2yjI3hTY45x4BHingNccvyOw559z66T7PbCn1+qD0a1R906P6pqfU6xtLIV0ubcDyvPllwLEptBERkVlUSKA/C6wysxVmFgPuALaOaLMVuMc/2+UG4IJz7vjIJxIRkdkzYZeLcy5jZg8C3wXCwKPOuT1m9oC//mFgG3ArcAjoAe6bvZKBGei2mWWlXh+Ufo2qb3pU3/SUen2jMucu6eoWEZF5SFeKiogEhAJdRCQgSjrQS/mWA2a23My2m9k+M9tjZh8cpc1GM7tgZi/4w0fnqj7/9X9pZi/6r/3cKOuLuf3W5G2XF8ysw8z+YESbOd9+ZvaomZ0ys5fyltWZ2b+b2cv+eMEYjx33/TqL9X3czPb7/4bfNLPaMR477vthFuv7mJm9lvfveOsYjy3W9ns8r7ZfmtkLYzx21rfftDnnSnLAOwD7CrASiAG7gCtGtLkVeArvPPgbgJ/PYX2LgWv96Srg4Cj1bQSeLOI2/CXQMM76om2/Uf6tTwAtxd5+wJuAa4GX8pb9DfARf/ojwF+P8TeM+36dxfp+HYj40389Wn2FvB9msb6PAR8q4D1QlO03Yv0ngI8Wa/tNdyjlPfSSvuWAc+64c+55f7oT2Id3dex8Uiq3bHgr8Ipz7kgRXvsizrmngbMjFu+G05MAAAK2SURBVN8OfNGf/iLwzlEeWsj7dVbqc859zzmX8WefwbsOpCjG2H6FKNr2G2RmBvwW8NhMv+5cKeVAH+t2ApNtM+vM7DLgGuDno6y+0cx2mdlTZvYrc1qYd7Xu98xsp3/bhZFKYvvhXdsw1n+iYm6/QU3Ov67CHy8cpU2pbMvfxfvWNZqJ3g+z6UG/S+jRMbqsSmH73QycdM69PMb6Ym6/gpRyoM/YLQdmk5mlgK8Df+Cc6xix+nm8boSrgYeAb81lbcCvOeeuxbsb5vvN7E0j1pfC9osBvwF8bZTVxd5+k1EK2/JPgAzwlTGaTPR+mC2fAV4HvAHv/k6fGKVN0bcfcCfj750Xa/sVrJQDveRvOWBmUbww/4pz7hsj1zvnOpxzXf70NiBqZg1zVZ9z7pg/PgV8E+9rbb5SuGXDLcDzzrmTI1cUe/vlOTnYFeWPT43SptjvxXuB24C7nN/hO1IB74dZ4Zw76ZzLOudywGfHeN1ib78I8JvA42O1Kdb2m4xSDvSSvuWA39/2eWCfc+6TY7RZ5LfDzK7H295n5qi+SjOrGpzGO3D20ohmpXDLhjH3ioq5/UbYCtzrT98LPDFKm0Ler7PCzDYDHwZ+wznXM0abQt4Ps1Vf/nGZd43xukXbfr63Afudc22jrSzm9puUYh+VHW/AOwvjIN7R7z/xlz0APOBPG96Pb7wCvAisn8Pa3oj3lXA38II/3DqivgeBPXhH7J8BbprD+lb6r7vLr6Gktp//+km8gK7JW1bU7Yf34XIcGMDba/wfQD3wA+Blf1znt10CbBvv/TpH9R3C638efB8+PLK+sd4Pc1TfP/vvr914Ib24lLafv/wLg++7vLZzvv2mO+jSfxGRgCjlLhcREZkEBbqISEAo0EVEAkKBLiISEAp0EZGAUKCLiASEAl1EJCD+P9EwucRiUKPRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 함수형 API를 사용해 복잡한 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(x_train.shape[1:])\n",
    "hidden1 = keras.layers.Dense(30, 'relu')(input_)\n",
    "hidden2 = keras.layers.Dense(30, 'relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 30)           270         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 30)           930         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 38)           0           input_1[0][0]                    \n",
      "                                                                 dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            39          concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.11021575],\n",
       "       [-0.2672109 ],\n",
       "       [ 0.01973808]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new = x_test[:3]           #새로운 샘플이라 생각하면됩니다.\n",
    "y_pred = model.predict(x_new)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input_B는 딥러닝을 하고 마지막에 Input_A와 합친 후에 출력한다.\n",
    "input_A = keras.layers.Input([5], name='wide_input')\n",
    "input_B = keras.layers.Input([6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, 'relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='output')(concat)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 30)           930         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 1)            36          concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,176\n",
      "Trainable params: 1,176\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_A, x_train_B = x_train[:, :5], x_train[:, 2:]\n",
    "x_valid_A, x_valid_B = x_valid[:, :5], x_valid[:, 2:]\n",
    "x_test_A, x_test_B = x_test[:, :5], x_test[:, 2:]\n",
    "x_new_A, x_new_B = x_test_A[:3], x_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 51us/sample - loss: 2.1061 - val_loss: 0.8011\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.7024 - val_loss: 0.6389\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.6151 - val_loss: 0.5960\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.5798 - val_loss: 0.5735\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5595 - val_loss: 0.5571\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5441 - val_loss: 0.5450\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5327 - val_loss: 0.5371\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5242 - val_loss: 0.5323\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5173 - val_loss: 0.5267\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5118 - val_loss: 0.5216\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5070 - val_loss: 0.5200\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5033 - val_loss: 0.5157\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.5001 - val_loss: 0.5125\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4962 - val_loss: 0.5121\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4943 - val_loss: 0.5079\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.4916 - val_loss: 0.5056\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.4891 - val_loss: 0.5025\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4865 - val_loss: 0.5009\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.4845 - val_loss: 0.4984\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.4820 - val_loss: 0.4966\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((x_train_A, x_train_B), y_train, epochs=20, validation_data=((x_valid_A, x_valid_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 12us/sample - loss: 0.4933\n"
     ]
    }
   ],
   "source": [
    "mse_test = model.evaluate((x_test_A, x_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict((x_new_A, x_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6794081],\n",
       "       [1.8213902],\n",
       "       [2.8398013]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input_B는 딥러닝을 하고 마지막에 Input_A와 합친 후에 출력한다.\n",
    "# 출력층 2개 메인출력층, 보조출력층ㄴ\n",
    "input_A = keras.layers.Input([5], name='wide_input')\n",
    "input_B = keras.layers.Input([6], name='deep_input')\n",
    "hidden1 = keras.layers.Dense(30, 'relu')(input_B)\n",
    "hidden2 = keras.layers.Dense(30, 'relu')(hidden1)\n",
    "concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "output = keras.layers.Dense(1, name='main_output')(concat)\n",
    "aux_output = keras.layers.Dense(1, name='aux_output')(hidden2)\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "deep_input (InputLayer)         [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 30)           210         deep_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "wide_input (InputLayer)         [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 30)           930         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 35)           0           wide_input[0][0]                 \n",
      "                                                                 dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "main_output (Dense)             (None, 1)            36          concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "aux_output (Dense)              (None, 1)            31          dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 1,207\n",
      "Trainable params: 1,207\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_A, x_train_B = x_train[:, :5], x_train[:, 2:]\n",
    "x_valid_A, x_valid_B = x_valid[:, :5], x_valid[:, 2:]\n",
    "x_test_A, x_test_B = x_test[:, :5], x_test[:, 2:]\n",
    "x_new_A, x_new_B = x_test_A[:3], x_test_B[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=['mse', 'mse'], loss_weights=[0.9, 0.1], optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 1s 57us/sample - loss: 0.9594 - main_output_loss: 0.8585 - aux_output_loss: 1.8652 - val_loss: 0.7311 - val_main_output_loss: 0.6651 - val_aux_output_loss: 1.3233\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6046 - main_output_loss: 0.5470 - aux_output_loss: 1.1227 - val_loss: 0.5907 - val_main_output_loss: 0.5429 - val_aux_output_loss: 1.0202\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.5671 - main_output_loss: 0.5264 - aux_output_loss: 0.9327 - val_loss: 0.5310 - val_main_output_loss: 0.4897 - val_aux_output_loss: 0.9013\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4973 - main_output_loss: 0.4605 - aux_output_loss: 0.8275 - val_loss: 0.5023 - val_main_output_loss: 0.4695 - val_aux_output_loss: 0.7972\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.4730 - main_output_loss: 0.4426 - aux_output_loss: 0.7453 - val_loss: 0.4820 - val_main_output_loss: 0.4540 - val_aux_output_loss: 0.7330\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4566 - main_output_loss: 0.4304 - aux_output_loss: 0.6929 - val_loss: 0.4700 - val_main_output_loss: 0.4460 - val_aux_output_loss: 0.6856\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4459 - main_output_loss: 0.4225 - aux_output_loss: 0.6557 - val_loss: 0.4632 - val_main_output_loss: 0.4406 - val_aux_output_loss: 0.6655\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4422 - main_output_loss: 0.4209 - aux_output_loss: 0.6336 - val_loss: 0.4570 - val_main_output_loss: 0.4358 - val_aux_output_loss: 0.6476\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4298 - main_output_loss: 0.4091 - aux_output_loss: 0.6149 - val_loss: 0.4524 - val_main_output_loss: 0.4322 - val_aux_output_loss: 0.6340\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4217 - main_output_loss: 0.4017 - aux_output_loss: 0.6005 - val_loss: 0.4370 - val_main_output_loss: 0.4179 - val_aux_output_loss: 0.6085\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4127 - main_output_loss: 0.3936 - aux_output_loss: 0.5841 - val_loss: 0.4350 - val_main_output_loss: 0.4157 - val_aux_output_loss: 0.6072\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.4073 - main_output_loss: 0.3887 - aux_output_loss: 0.5740 - val_loss: 0.4218 - val_main_output_loss: 0.4037 - val_aux_output_loss: 0.5838\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3985 - main_output_loss: 0.3804 - aux_output_loss: 0.5607 - val_loss: 0.4225 - val_main_output_loss: 0.4056 - val_aux_output_loss: 0.5742\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3934 - main_output_loss: 0.3761 - aux_output_loss: 0.5493 - val_loss: 0.4141 - val_main_output_loss: 0.3970 - val_aux_output_loss: 0.5671\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3920 - main_output_loss: 0.3756 - aux_output_loss: 0.5396 - val_loss: 0.4181 - val_main_output_loss: 0.4016 - val_aux_output_loss: 0.5659\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3848 - main_output_loss: 0.3685 - aux_output_loss: 0.5311 - val_loss: 0.4211 - val_main_output_loss: 0.4057 - val_aux_output_loss: 0.5590\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3779 - main_output_loss: 0.3621 - aux_output_loss: 0.5194 - val_loss: 0.4004 - val_main_output_loss: 0.3846 - val_aux_output_loss: 0.5415\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3732 - main_output_loss: 0.3579 - aux_output_loss: 0.5097 - val_loss: 0.3935 - val_main_output_loss: 0.3781 - val_aux_output_loss: 0.5305\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3705 - main_output_loss: 0.3557 - aux_output_loss: 0.5047 - val_loss: 0.3902 - val_main_output_loss: 0.3755 - val_aux_output_loss: 0.5216\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3666 - main_output_loss: 0.3523 - aux_output_loss: 0.4951 - val_loss: 0.3866 - val_main_output_loss: 0.3723 - val_aux_output_loss: 0.5146\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([x_train_A, x_train_B], [y_train, y_train], epochs=20, validation_data=([x_valid_A, x_valid_B], [y_valid, y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장\n",
    "model.save('.\\models\\my_keras_model_multi_IO_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3623 - main_output_loss: 0.3485 - aux_output_loss: 0.4879 - val_loss: 0.4029 - val_main_output_loss: 0.3905 - val_aux_output_loss: 0.5143\n",
      "Epoch 2/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3621 - main_output_loss: 0.3485 - aux_output_loss: 0.4834 - val_loss: 0.3907 - val_main_output_loss: 0.3777 - val_aux_output_loss: 0.5071\n",
      "Epoch 3/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3564 - main_output_loss: 0.3434 - aux_output_loss: 0.4732 - val_loss: 0.3845 - val_main_output_loss: 0.3720 - val_aux_output_loss: 0.4965\n",
      "Epoch 4/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3550 - main_output_loss: 0.3421 - aux_output_loss: 0.4711 - val_loss: 0.3863 - val_main_output_loss: 0.3733 - val_aux_output_loss: 0.5018\n",
      "Epoch 5/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3521 - main_output_loss: 0.3398 - aux_output_loss: 0.4632 - val_loss: 0.3761 - val_main_output_loss: 0.3633 - val_aux_output_loss: 0.4900\n",
      "Epoch 6/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3502 - main_output_loss: 0.3380 - aux_output_loss: 0.4584 - val_loss: 0.3856 - val_main_output_loss: 0.3743 - val_aux_output_loss: 0.4865\n",
      "Epoch 7/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3497 - main_output_loss: 0.3381 - aux_output_loss: 0.4540 - val_loss: 0.3780 - val_main_output_loss: 0.3663 - val_aux_output_loss: 0.4823\n",
      "Epoch 8/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3477 - main_output_loss: 0.3364 - aux_output_loss: 0.4505 - val_loss: 0.3704 - val_main_output_loss: 0.3583 - val_aux_output_loss: 0.4786\n",
      "Epoch 9/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3459 - main_output_loss: 0.3349 - aux_output_loss: 0.4464 - val_loss: 0.3763 - val_main_output_loss: 0.3651 - val_aux_output_loss: 0.4765\n",
      "Epoch 10/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3436 - main_output_loss: 0.3329 - aux_output_loss: 0.4415 - val_loss: 0.3725 - val_main_output_loss: 0.3608 - val_aux_output_loss: 0.4772\n",
      "Epoch 11/20\n",
      "11610/11610 [==============================] - 0s 28us/sample - loss: 0.3423 - main_output_loss: 0.3316 - aux_output_loss: 0.4379 - val_loss: 0.3689 - val_main_output_loss: 0.3574 - val_aux_output_loss: 0.4719\n",
      "Epoch 12/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3441 - main_output_loss: 0.3336 - aux_output_loss: 0.4408 - val_loss: 0.3895 - val_main_output_loss: 0.3792 - val_aux_output_loss: 0.4816\n",
      "Epoch 13/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3422 - main_output_loss: 0.3318 - aux_output_loss: 0.4353 - val_loss: 0.3627 - val_main_output_loss: 0.3515 - val_aux_output_loss: 0.4624\n",
      "Epoch 14/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3392 - main_output_loss: 0.3290 - aux_output_loss: 0.4307 - val_loss: 0.3626 - val_main_output_loss: 0.3517 - val_aux_output_loss: 0.4601\n",
      "Epoch 15/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3390 - main_output_loss: 0.3292 - aux_output_loss: 0.4283 - val_loss: 0.3638 - val_main_output_loss: 0.3537 - val_aux_output_loss: 0.4539\n",
      "Epoch 16/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3382 - main_output_loss: 0.3282 - aux_output_loss: 0.4278 - val_loss: 0.3616 - val_main_output_loss: 0.3512 - val_aux_output_loss: 0.4548\n",
      "Epoch 17/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3371 - main_output_loss: 0.3273 - aux_output_loss: 0.4247 - val_loss: 0.3600 - val_main_output_loss: 0.3500 - val_aux_output_loss: 0.4496\n",
      "Epoch 18/20\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3364 - main_output_loss: 0.3269 - aux_output_loss: 0.4227 - val_loss: 0.3603 - val_main_output_loss: 0.3499 - val_aux_output_loss: 0.4527\n",
      "Epoch 19/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3347 - main_output_loss: 0.3253 - aux_output_loss: 0.4199 - val_loss: 0.3552 - val_main_output_loss: 0.3451 - val_aux_output_loss: 0.4448\n",
      "Epoch 20/20\n",
      "11610/11610 [==============================] - 0s 27us/sample - loss: 0.3337 - main_output_loss: 0.3244 - aux_output_loss: 0.4175 - val_loss: 0.3626 - val_main_output_loss: 0.3534 - val_aux_output_loss: 0.4447\n"
     ]
    }
   ],
   "source": [
    "# 콜백\n",
    "checkpoint_cv = keras.callbacks.ModelCheckpoint('.\\models\\my_keras_model_multi_IO_model.h5', save_best_only=True)\n",
    "history = model.fit([x_train_A, x_train_B], [y_train, y_train], epochs=20, validation_data=([x_valid_A, x_valid_B], [y_valid, y_valid]), callbacks=[checkpoint_cv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('.\\weights\\my_keras_model_multi_IO_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x248585cb848>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights('.\\weights\\my_keras_model_multi_IO_model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('.\\models\\my_keras_model_multi_IO_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 28us/sample - loss: 0.3370 - main_output_loss: 0.3279 - aux_output_loss: 0.4144\n"
     ]
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss = model.evaluate([x_test_A, x_test_B], [y_test, y_test])\n",
    "y_pred, y_pred_aux = model.predict([x_new_A, x_new_B])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3370176742243212, 0.32790646, 0.4144236)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_loss, main_loss, aux_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.5355965],\n",
       "        [1.4718468],\n",
       "        [3.561123 ]], dtype=float32),\n",
       " array([[0.6603018],\n",
       "        [1.7209829],\n",
       "        [2.991622 ]], dtype=float32))"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_pred_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 서브클래싱 API로 동적 모델 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units=30, activation='relu', **kwargs):\n",
    "        super().__init__(**kwargs)         # 표준 매개변수를 처리함(name같은거)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "       \n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 64us/sample - loss: 2.6257 - output_1_loss: 2.4718 - output_2_loss: 4.0021 - val_loss: 1.0797 - val_output_1_loss: 0.8443 - val_output_2_loss: 3.1974\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.9046 - output_1_loss: 0.7107 - output_2_loss: 2.6495 - val_loss: 0.8348 - val_output_1_loss: 0.6581 - val_output_2_loss: 2.4242\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.7652 - output_1_loss: 0.6170 - output_2_loss: 2.0980 - val_loss: 0.7565 - val_output_1_loss: 0.6160 - val_output_2_loss: 2.0194\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.7025 - output_1_loss: 0.5805 - output_2_loss: 1.7996 - val_loss: 0.7109 - val_output_1_loss: 0.5921 - val_output_2_loss: 1.7800\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6641 - output_1_loss: 0.5576 - output_2_loss: 1.6220 - val_loss: 0.6809 - val_output_1_loss: 0.5749 - val_output_2_loss: 1.6348\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6385 - output_1_loss: 0.5411 - output_2_loss: 1.5148 - val_loss: 0.6580 - val_output_1_loss: 0.5603 - val_output_2_loss: 1.5360\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6195 - output_1_loss: 0.5284 - output_2_loss: 1.4392 - val_loss: 0.6405 - val_output_1_loss: 0.5490 - val_output_2_loss: 1.4630\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.6047 - output_1_loss: 0.5182 - output_2_loss: 1.3826 - val_loss: 0.6274 - val_output_1_loss: 0.5408 - val_output_2_loss: 1.4058\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.5931 - output_1_loss: 0.5102 - output_2_loss: 1.3381 - val_loss: 0.6160 - val_output_1_loss: 0.5334 - val_output_2_loss: 1.3584\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.5831 - output_1_loss: 0.5035 - output_2_loss: 1.2992 - val_loss: 0.6067 - val_output_1_loss: 0.5277 - val_output_2_loss: 1.3170\n"
     ]
    }
   ],
   "source": [
    "history = model.fit((x_train_A, x_train_B), (y_train, y_train), epochs=10, validation_data=((x_valid_A, x_valid_B), (y_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 14us/sample - loss: 0.5953 - output_1_loss: 0.5181 - output_2_loss: 1.3012\n"
     ]
    }
   ],
   "source": [
    "# evaluate 오차추정치\n",
    "total_loss, main_loss, aux_loss = model.evaluate((x_test_A, x_test_B), (y_test, y_test))\n",
    "y_pred_main, y_pred_aux = model.predict((x_new_A, x_new_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 및 복원\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 1.9914 - val_loss: 1.0118\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.8552 - val_loss: 0.7744\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.7188 - val_loss: 0.7073\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.6628 - val_loss: 0.6642\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.6230 - val_loss: 0.6325\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5922 - val_loss: 0.6014\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5675 - val_loss: 0.5823\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5465 - val_loss: 0.5602\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5289 - val_loss: 0.5431\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5150 - val_loss: 0.5305\n",
      "5160/5160 [==============================] - 0s 11us/sample - loss: 0.5229\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid))\n",
    "mse_test = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\".\\models\\my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\".\\models\\my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.87226343],\n",
       "       [1.3419807 ],\n",
       "       [2.729253  ]], dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\".\\models\\my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x24857697a08>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\".\\models\\my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 훈련과정에서 콜백하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer = keras.optimizers.SGD(1e-3))\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('.\\models\\my_keras_model.h5', save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 0s 39us/sample - loss: 1.9575 - val_loss: 0.8953\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.8295 - val_loss: 0.7458\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.7110 - val_loss: 0.7009\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.6702 - val_loss: 0.6660\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.6395 - val_loss: 0.6404\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.6153 - val_loss: 0.6201\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5957 - val_loss: 0.6018\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5788 - val_loss: 0.5870\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5640 - val_loss: 0.5722\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5513 - val_loss: 0.5602\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('.\\models\\my_keras_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 18us/sample - loss: 0.5448\n"
     ]
    }
   ],
   "source": [
    "mse_test =model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer=keras.optimizers.SGD(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 조기 종료 (모델이 향상되지 않으면)\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/1000\n",
      "11610/11610 [==============================] - 1s 47us/sample - loss: 0.5391 - val_loss: 0.5501\n",
      "Epoch 2/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5286 - val_loss: 0.5395\n",
      "Epoch 3/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5187 - val_loss: 0.5302\n",
      "Epoch 4/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.5104 - val_loss: 0.5226\n",
      "Epoch 5/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5026 - val_loss: 0.5159\n",
      "Epoch 6/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4959 - val_loss: 0.5100\n",
      "Epoch 7/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4896 - val_loss: 0.5038\n",
      "Epoch 8/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4843 - val_loss: 0.4985\n",
      "Epoch 9/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4792 - val_loss: 0.4930\n",
      "Epoch 10/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4749 - val_loss: 0.4895\n",
      "Epoch 11/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4708 - val_loss: 0.4855\n",
      "Epoch 12/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4671 - val_loss: 0.4821\n",
      "Epoch 13/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4637 - val_loss: 0.4796\n",
      "Epoch 14/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4607 - val_loss: 0.4770\n",
      "Epoch 15/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4579 - val_loss: 0.4745\n",
      "Epoch 16/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4552 - val_loss: 0.4726\n",
      "Epoch 17/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4527 - val_loss: 0.4702\n",
      "Epoch 18/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4505 - val_loss: 0.4679\n",
      "Epoch 19/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4480 - val_loss: 0.4660\n",
      "Epoch 20/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4458 - val_loss: 0.4644\n",
      "Epoch 21/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4437 - val_loss: 0.4614\n",
      "Epoch 22/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4415 - val_loss: 0.4597\n",
      "Epoch 23/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4396 - val_loss: 0.4580\n",
      "Epoch 24/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4376 - val_loss: 0.4561\n",
      "Epoch 25/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4358 - val_loss: 0.4556\n",
      "Epoch 26/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4340 - val_loss: 0.4525\n",
      "Epoch 27/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4321 - val_loss: 0.4512\n",
      "Epoch 28/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.4304 - val_loss: 0.4496\n",
      "Epoch 29/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4287 - val_loss: 0.4477\n",
      "Epoch 30/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4267 - val_loss: 0.4476\n",
      "Epoch 31/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4254 - val_loss: 0.4450\n",
      "Epoch 32/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4237 - val_loss: 0.4438\n",
      "Epoch 33/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4222 - val_loss: 0.4424\n",
      "Epoch 34/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4208 - val_loss: 0.4411\n",
      "Epoch 35/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4193 - val_loss: 0.4398\n",
      "Epoch 36/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4175 - val_loss: 0.4400\n",
      "Epoch 37/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4164 - val_loss: 0.4377\n",
      "Epoch 38/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4149 - val_loss: 0.4359\n",
      "Epoch 39/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4139 - val_loss: 0.4353\n",
      "Epoch 40/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4126 - val_loss: 0.4338\n",
      "Epoch 41/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4113 - val_loss: 0.4336\n",
      "Epoch 42/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4100 - val_loss: 0.4323\n",
      "Epoch 43/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4088 - val_loss: 0.4313\n",
      "Epoch 44/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4076 - val_loss: 0.4306\n",
      "Epoch 45/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4065 - val_loss: 0.4295\n",
      "Epoch 46/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4053 - val_loss: 0.4280\n",
      "Epoch 47/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4041 - val_loss: 0.4278\n",
      "Epoch 48/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4030 - val_loss: 0.4266\n",
      "Epoch 49/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4017 - val_loss: 0.4258\n",
      "Epoch 50/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4009 - val_loss: 0.4246\n",
      "Epoch 51/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3997 - val_loss: 0.4248\n",
      "Epoch 52/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3987 - val_loss: 0.4232\n",
      "Epoch 53/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3977 - val_loss: 0.4229\n",
      "Epoch 54/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3967 - val_loss: 0.4215\n",
      "Epoch 55/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3958 - val_loss: 0.4212\n",
      "Epoch 56/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3947 - val_loss: 0.4203\n",
      "Epoch 57/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3935 - val_loss: 0.4208\n",
      "Epoch 58/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3928 - val_loss: 0.4188\n",
      "Epoch 59/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3918 - val_loss: 0.4183\n",
      "Epoch 60/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3910 - val_loss: 0.4179\n",
      "Epoch 61/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3898 - val_loss: 0.4179\n",
      "Epoch 62/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3892 - val_loss: 0.4164\n",
      "Epoch 63/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3881 - val_loss: 0.4164\n",
      "Epoch 64/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3876 - val_loss: 0.4154\n",
      "Epoch 65/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3864 - val_loss: 0.4158\n",
      "Epoch 66/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3857 - val_loss: 0.4139\n",
      "Epoch 67/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3849 - val_loss: 0.4131\n",
      "Epoch 68/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3839 - val_loss: 0.4133\n",
      "Epoch 69/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3830 - val_loss: 0.4128\n",
      "Epoch 70/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3824 - val_loss: 0.4122\n",
      "Epoch 71/1000\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3815 - val_loss: 0.4116\n",
      "Epoch 72/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3807 - val_loss: 0.4107\n",
      "Epoch 73/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3800 - val_loss: 0.4103\n",
      "Epoch 74/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3791 - val_loss: 0.4103\n",
      "Epoch 75/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3783 - val_loss: 0.4095\n",
      "Epoch 76/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3776 - val_loss: 0.4088\n",
      "Epoch 77/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3768 - val_loss: 0.4083\n",
      "Epoch 78/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3760 - val_loss: 0.4075\n",
      "Epoch 79/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3754 - val_loss: 0.4083\n",
      "Epoch 80/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3746 - val_loss: 0.4073\n",
      "Epoch 81/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3739 - val_loss: 0.4062\n",
      "Epoch 82/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3733 - val_loss: 0.4058\n",
      "Epoch 83/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3724 - val_loss: 0.4064\n",
      "Epoch 84/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3717 - val_loss: 0.4047\n",
      "Epoch 85/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3709 - val_loss: 0.4042\n",
      "Epoch 86/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3704 - val_loss: 0.4041\n",
      "Epoch 87/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3695 - val_loss: 0.4036\n",
      "Epoch 88/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3687 - val_loss: 0.4040\n",
      "Epoch 89/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3685 - val_loss: 0.4030\n",
      "Epoch 90/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3676 - val_loss: 0.4020\n",
      "Epoch 91/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3670 - val_loss: 0.4013\n",
      "Epoch 92/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3664 - val_loss: 0.4008\n",
      "Epoch 93/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3656 - val_loss: 0.3999\n",
      "Epoch 94/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3649 - val_loss: 0.4000\n",
      "Epoch 95/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3644 - val_loss: 0.4000\n",
      "Epoch 96/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3639 - val_loss: 0.3986\n",
      "Epoch 97/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3633 - val_loss: 0.3985\n",
      "Epoch 98/1000\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3627 - val_loss: 0.3987\n",
      "Epoch 99/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3623 - val_loss: 0.3991\n",
      "Epoch 100/1000\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.3617 - val_loss: 0.3969\n",
      "Epoch 101/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3606 - val_loss: 0.3981\n",
      "Epoch 102/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3605 - val_loss: 0.3977\n",
      "Epoch 103/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3597 - val_loss: 0.3973\n",
      "Epoch 104/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3592 - val_loss: 0.3960\n",
      "Epoch 105/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3588 - val_loss: 0.3953\n",
      "Epoch 106/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3582 - val_loss: 0.3956\n",
      "Epoch 107/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3576 - val_loss: 0.3955\n",
      "Epoch 108/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3570 - val_loss: 0.3942\n",
      "Epoch 109/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3565 - val_loss: 0.3954\n",
      "Epoch 110/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3559 - val_loss: 0.3941\n",
      "Epoch 111/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3551 - val_loss: 0.3948\n",
      "Epoch 112/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3548 - val_loss: 0.3930\n",
      "Epoch 113/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3543 - val_loss: 0.3935\n",
      "Epoch 114/1000\n",
      "11610/11610 [==============================] - ETA: 0s - loss: 0.353 - 0s 24us/sample - loss: 0.3539 - val_loss: 0.3922\n",
      "Epoch 115/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3532 - val_loss: 0.3929\n",
      "Epoch 116/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3527 - val_loss: 0.3920\n",
      "Epoch 117/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3524 - val_loss: 0.3923\n",
      "Epoch 118/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3519 - val_loss: 0.3920\n",
      "Epoch 119/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3515 - val_loss: 0.3914\n",
      "Epoch 120/1000\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3508 - val_loss: 0.3908\n",
      "Epoch 121/1000\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3505 - val_loss: 0.3900\n",
      "Epoch 122/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3497 - val_loss: 0.3918\n",
      "Epoch 123/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3494 - val_loss: 0.3905\n",
      "Epoch 124/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3491 - val_loss: 0.3894\n",
      "Epoch 125/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3487 - val_loss: 0.3893\n",
      "Epoch 126/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3480 - val_loss: 0.3895\n",
      "Epoch 127/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3473 - val_loss: 0.3884\n",
      "Epoch 128/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3471 - val_loss: 0.3884\n",
      "Epoch 129/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3468 - val_loss: 0.3889\n",
      "Epoch 130/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3461 - val_loss: 0.3885\n",
      "Epoch 131/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3458 - val_loss: 0.3870\n",
      "Epoch 132/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3454 - val_loss: 0.3877\n",
      "Epoch 133/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3448 - val_loss: 0.3870\n",
      "Epoch 134/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3446 - val_loss: 0.3869\n",
      "Epoch 135/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3441 - val_loss: 0.3856\n",
      "Epoch 136/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3435 - val_loss: 0.3859\n",
      "Epoch 137/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3434 - val_loss: 0.3853\n",
      "Epoch 138/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3428 - val_loss: 0.3857\n",
      "Epoch 139/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3425 - val_loss: 0.3855\n",
      "Epoch 140/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3423 - val_loss: 0.3850\n",
      "Epoch 141/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3412 - val_loss: 0.3852\n",
      "Epoch 142/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3409 - val_loss: 0.3859\n",
      "Epoch 143/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3405 - val_loss: 0.3838\n",
      "Epoch 144/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3401 - val_loss: 0.3841\n",
      "Epoch 145/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3398 - val_loss: 0.3835\n",
      "Epoch 146/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3396 - val_loss: 0.3829\n",
      "Epoch 147/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3392 - val_loss: 0.3829\n",
      "Epoch 148/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3389 - val_loss: 0.3827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3383 - val_loss: 0.3820\n",
      "Epoch 150/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3382 - val_loss: 0.3813\n",
      "Epoch 151/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3373 - val_loss: 0.3814\n",
      "Epoch 152/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3374 - val_loss: 0.3814\n",
      "Epoch 153/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3368 - val_loss: 0.3816\n",
      "Epoch 154/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3365 - val_loss: 0.3813\n",
      "Epoch 155/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3359 - val_loss: 0.3796\n",
      "Epoch 156/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3358 - val_loss: 0.3806\n",
      "Epoch 157/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3356 - val_loss: 0.3810\n",
      "Epoch 158/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3349 - val_loss: 0.3787\n",
      "Epoch 159/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3345 - val_loss: 0.3792\n",
      "Epoch 160/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3338 - val_loss: 0.3797\n",
      "Epoch 161/1000\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.3341 - val_loss: 0.3788\n",
      "Epoch 162/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3335 - val_loss: 0.3788\n",
      "Epoch 163/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3333 - val_loss: 0.3791\n",
      "Epoch 164/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3325 - val_loss: 0.3778\n",
      "Epoch 165/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3325 - val_loss: 0.3773\n",
      "Epoch 166/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3322 - val_loss: 0.3777\n",
      "Epoch 167/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3318 - val_loss: 0.3762\n",
      "Epoch 168/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3312 - val_loss: 0.3772\n",
      "Epoch 169/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3311 - val_loss: 0.3763\n",
      "Epoch 170/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3305 - val_loss: 0.3760\n",
      "Epoch 171/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3303 - val_loss: 0.3761\n",
      "Epoch 172/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3297 - val_loss: 0.3745\n",
      "Epoch 173/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3295 - val_loss: 0.3750\n",
      "Epoch 174/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3290 - val_loss: 0.3778\n",
      "Epoch 175/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3290 - val_loss: 0.3751\n",
      "Epoch 176/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3287 - val_loss: 0.3741\n",
      "Epoch 177/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3281 - val_loss: 0.3748\n",
      "Epoch 178/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3280 - val_loss: 0.3740\n",
      "Epoch 179/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3276 - val_loss: 0.3725\n",
      "Epoch 180/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3274 - val_loss: 0.3729\n",
      "Epoch 181/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3266 - val_loss: 0.3727\n",
      "Epoch 182/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3266 - val_loss: 0.3720\n",
      "Epoch 183/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3262 - val_loss: 0.3717\n",
      "Epoch 184/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3261 - val_loss: 0.3727\n",
      "Epoch 185/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3248 - val_loss: 0.3739\n",
      "Epoch 186/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3255 - val_loss: 0.3713\n",
      "Epoch 187/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3251 - val_loss: 0.3714\n",
      "Epoch 188/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3247 - val_loss: 0.3704\n",
      "Epoch 189/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3241 - val_loss: 0.3709\n",
      "Epoch 190/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3238 - val_loss: 0.3708\n",
      "Epoch 191/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3236 - val_loss: 0.3702\n",
      "Epoch 192/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3234 - val_loss: 0.3698\n",
      "Epoch 193/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3232 - val_loss: 0.3692\n",
      "Epoch 194/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3223 - val_loss: 0.3695\n",
      "Epoch 195/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3224 - val_loss: 0.3691\n",
      "Epoch 196/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3221 - val_loss: 0.3691\n",
      "Epoch 197/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3218 - val_loss: 0.3682\n",
      "Epoch 198/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3216 - val_loss: 0.3678\n",
      "Epoch 199/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3212 - val_loss: 0.3672\n",
      "Epoch 200/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3208 - val_loss: 0.3694\n",
      "Epoch 201/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3208 - val_loss: 0.3684\n",
      "Epoch 202/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3201 - val_loss: 0.3687\n",
      "Epoch 203/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3200 - val_loss: 0.3664\n",
      "Epoch 204/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3193 - val_loss: 0.3665\n",
      "Epoch 205/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3193 - val_loss: 0.3658\n",
      "Epoch 206/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3189 - val_loss: 0.3657\n",
      "Epoch 207/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3184 - val_loss: 0.3663\n",
      "Epoch 208/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3183 - val_loss: 0.3670\n",
      "Epoch 209/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3176 - val_loss: 0.3674\n",
      "Epoch 210/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3177 - val_loss: 0.3662\n",
      "Epoch 211/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3174 - val_loss: 0.3657\n",
      "Epoch 212/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3171 - val_loss: 0.3658\n",
      "Epoch 213/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3170 - val_loss: 0.3645\n",
      "Epoch 214/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3163 - val_loss: 0.3646\n",
      "Epoch 215/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3162 - val_loss: 0.3634\n",
      "Epoch 216/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3159 - val_loss: 0.3643\n",
      "Epoch 217/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3156 - val_loss: 0.3632\n",
      "Epoch 218/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3154 - val_loss: 0.3632\n",
      "Epoch 219/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3152 - val_loss: 0.3640\n",
      "Epoch 220/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3148 - val_loss: 0.3636\n",
      "Epoch 221/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3144 - val_loss: 0.3642\n",
      "Epoch 222/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3141 - val_loss: 0.3619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3138 - val_loss: 0.3621\n",
      "Epoch 224/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3135 - val_loss: 0.3610\n",
      "Epoch 225/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.3129 - val_loss: 0.3610\n",
      "Epoch 226/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3127 - val_loss: 0.3622\n",
      "Epoch 227/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3125 - val_loss: 0.3601\n",
      "Epoch 228/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3122 - val_loss: 0.3601\n",
      "Epoch 229/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3123 - val_loss: 0.3603\n",
      "Epoch 230/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3120 - val_loss: 0.3592\n",
      "Epoch 231/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3116 - val_loss: 0.3593\n",
      "Epoch 232/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3116 - val_loss: 0.3604\n",
      "Epoch 233/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3109 - val_loss: 0.3595\n",
      "Epoch 234/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3110 - val_loss: 0.3580\n",
      "Epoch 235/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3104 - val_loss: 0.3614\n",
      "Epoch 236/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3099 - val_loss: 0.3601\n",
      "Epoch 237/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3101 - val_loss: 0.3578\n",
      "Epoch 238/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3098 - val_loss: 0.3576\n",
      "Epoch 239/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3090 - val_loss: 0.3578\n",
      "Epoch 240/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3088 - val_loss: 0.3580\n",
      "Epoch 241/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3093 - val_loss: 0.3567\n",
      "Epoch 242/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3090 - val_loss: 0.3564\n",
      "Epoch 243/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3082 - val_loss: 0.3612\n",
      "Epoch 244/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3084 - val_loss: 0.3565\n",
      "Epoch 245/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3079 - val_loss: 0.3564\n",
      "Epoch 246/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3076 - val_loss: 0.3558\n",
      "Epoch 247/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3074 - val_loss: 0.3556\n",
      "Epoch 248/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3071 - val_loss: 0.3575\n",
      "Epoch 249/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3068 - val_loss: 0.3567\n",
      "Epoch 250/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3069 - val_loss: 0.3554\n",
      "Epoch 251/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3062 - val_loss: 0.3542\n",
      "Epoch 252/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3061 - val_loss: 0.3555\n",
      "Epoch 253/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3057 - val_loss: 0.3543\n",
      "Epoch 254/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3060 - val_loss: 0.3546\n",
      "Epoch 255/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3056 - val_loss: 0.3547\n",
      "Epoch 256/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3051 - val_loss: 0.3539\n",
      "Epoch 257/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3051 - val_loss: 0.3537\n",
      "Epoch 258/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3047 - val_loss: 0.3568\n",
      "Epoch 259/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3047 - val_loss: 0.3545\n",
      "Epoch 260/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3044 - val_loss: 0.3543\n",
      "Epoch 261/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3042 - val_loss: 0.3535\n",
      "Epoch 262/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3039 - val_loss: 0.3542\n",
      "Epoch 263/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3035 - val_loss: 0.3518\n",
      "Epoch 264/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3034 - val_loss: 0.3526\n",
      "Epoch 265/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3033 - val_loss: 0.3520\n",
      "Epoch 266/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3031 - val_loss: 0.3512\n",
      "Epoch 267/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3027 - val_loss: 0.3514\n",
      "Epoch 268/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3024 - val_loss: 0.3536\n",
      "Epoch 269/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3023 - val_loss: 0.3514\n",
      "Epoch 270/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3023 - val_loss: 0.3516\n",
      "Epoch 271/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3020 - val_loss: 0.3513\n",
      "Epoch 272/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3013 - val_loss: 0.3510\n",
      "Epoch 273/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3014 - val_loss: 0.3535\n",
      "Epoch 274/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3016 - val_loss: 0.3517\n",
      "Epoch 275/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3011 - val_loss: 0.3504\n",
      "Epoch 276/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3007 - val_loss: 0.3502\n",
      "Epoch 277/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3012 - val_loss: 0.3495\n",
      "Epoch 278/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3003 - val_loss: 0.3514\n",
      "Epoch 279/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3006 - val_loss: 0.3486\n",
      "Epoch 280/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2999 - val_loss: 0.3523\n",
      "Epoch 281/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3000 - val_loss: 0.3483\n",
      "Epoch 282/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2994 - val_loss: 0.3487\n",
      "Epoch 283/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2990 - val_loss: 0.3490\n",
      "Epoch 284/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2995 - val_loss: 0.3480\n",
      "Epoch 285/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2987 - val_loss: 0.3493\n",
      "Epoch 286/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2992 - val_loss: 0.3483\n",
      "Epoch 287/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2990 - val_loss: 0.3477\n",
      "Epoch 288/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2986 - val_loss: 0.3489\n",
      "Epoch 289/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2985 - val_loss: 0.3467\n",
      "Epoch 290/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2981 - val_loss: 0.3483\n",
      "Epoch 291/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2979 - val_loss: 0.3475\n",
      "Epoch 292/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2976 - val_loss: 0.3496\n",
      "Epoch 293/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2978 - val_loss: 0.3471\n",
      "Epoch 294/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2973 - val_loss: 0.3469\n",
      "Epoch 295/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2975 - val_loss: 0.3465\n",
      "Epoch 296/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2968 - val_loss: 0.3486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 297/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2973 - val_loss: 0.3456\n",
      "Epoch 298/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2968 - val_loss: 0.3470\n",
      "Epoch 299/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2969 - val_loss: 0.3451\n",
      "Epoch 300/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2961 - val_loss: 0.3471\n",
      "Epoch 301/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2958 - val_loss: 0.3457\n",
      "Epoch 302/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2959 - val_loss: 0.3491\n",
      "Epoch 303/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2957 - val_loss: 0.3448\n",
      "Epoch 304/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2953 - val_loss: 0.3474\n",
      "Epoch 305/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2956 - val_loss: 0.3455\n",
      "Epoch 306/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2949 - val_loss: 0.3477\n",
      "Epoch 307/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2950 - val_loss: 0.3475\n",
      "Epoch 308/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2947 - val_loss: 0.3456\n",
      "Epoch 309/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2950 - val_loss: 0.3445\n",
      "Epoch 310/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2946 - val_loss: 0.3436\n",
      "Epoch 311/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2942 - val_loss: 0.3453\n",
      "Epoch 312/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2942 - val_loss: 0.3434\n",
      "Epoch 313/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2943 - val_loss: 0.3446\n",
      "Epoch 314/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2943 - val_loss: 0.3467\n",
      "Epoch 315/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2941 - val_loss: 0.3440\n",
      "Epoch 316/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2938 - val_loss: 0.3430\n",
      "Epoch 317/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2936 - val_loss: 0.3436\n",
      "Epoch 318/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2936 - val_loss: 0.3434\n",
      "Epoch 319/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2929 - val_loss: 0.3429\n",
      "Epoch 320/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2929 - val_loss: 0.3443\n",
      "Epoch 321/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2930 - val_loss: 0.3422\n",
      "Epoch 322/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2929 - val_loss: 0.3444\n",
      "Epoch 323/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.2926 - val_loss: 0.3426\n",
      "Epoch 324/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2922 - val_loss: 0.3424\n",
      "Epoch 325/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2923 - val_loss: 0.3421\n",
      "Epoch 326/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2919 - val_loss: 0.3419\n",
      "Epoch 327/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.2920 - val_loss: 0.3418\n",
      "Epoch 328/1000\n",
      "11610/11610 [==============================] - 0s 24us/sample - loss: 0.2915 - val_loss: 0.3415\n",
      "Epoch 329/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2919 - val_loss: 0.3413\n",
      "Epoch 330/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2916 - val_loss: 0.3429\n",
      "Epoch 331/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2915 - val_loss: 0.3415\n",
      "Epoch 332/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2909 - val_loss: 0.3429\n",
      "Epoch 333/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2908 - val_loss: 0.3448\n",
      "Epoch 334/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2914 - val_loss: 0.3403\n",
      "Epoch 335/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2906 - val_loss: 0.3402\n",
      "Epoch 336/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2909 - val_loss: 0.3399\n",
      "Epoch 337/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2908 - val_loss: 0.3389\n",
      "Epoch 338/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2902 - val_loss: 0.3394\n",
      "Epoch 339/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2903 - val_loss: 0.3405\n",
      "Epoch 340/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2901 - val_loss: 0.3405\n",
      "Epoch 341/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2895 - val_loss: 0.3425\n",
      "Epoch 342/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2896 - val_loss: 0.3401\n",
      "Epoch 343/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2894 - val_loss: 0.3412\n",
      "Epoch 344/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2898 - val_loss: 0.3403\n",
      "Epoch 345/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2896 - val_loss: 0.3395\n",
      "Epoch 346/1000\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.2892 - val_loss: 0.3404\n",
      "Epoch 347/1000\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2897 - val_loss: 0.3392\n"
     ]
    }
   ],
   "source": [
    "# 체크포인트 저장 (위 checkpoint_cb), 조기 종료(early_stopping_cb)를 callbacks 인자에 넣어둠 (리스트형식)\n",
    "# epochs  횟수는 상관없음\n",
    "history = model.fit(x_train, y_train, epochs=1000, validation_data=(x_valid, y_valid), callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintValTrainRatioCallBack(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        print('\\nval/train: {:.2f}'.format(logs['val_loss'] / logs['loss']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      " 8832/11610 [=====================>........] - ETA: 0s - loss: 0.2844\n",
      "val/train: 1.17\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.2903 - val_loss: 0.3399\n"
     ]
    }
   ],
   "source": [
    "val_train_ratio_cb = PrintValTrainRatioCallBack()\n",
    "history = model.fit(x_train , y_train, epochs=1, validation_data=(x_valid, y_valid), callbacks=[val_train_ratio_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 텐서보드 ↓"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir,'my_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime('run_%Y_%m_%d-%H_%M_%S')\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2020_06_27-21_00_50'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation='relu', input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation='relu'),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 67us/sample - loss: 1.6104 - val_loss: 0.8706\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.8061 - val_loss: 0.7314\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.7002 - val_loss: 0.6657\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.6407 - val_loss: 0.6201\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.6003 - val_loss: 0.5869\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5715 - val_loss: 0.5618\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5482 - val_loss: 0.5436\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5308 - val_loss: 0.5291\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.5181 - val_loss: 0.5159\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.5069 - val_loss: 0.5078\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4983 - val_loss: 0.5006\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4909 - val_loss: 0.4935\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4853 - val_loss: 0.4883\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4795 - val_loss: 0.4842\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4750 - val_loss: 0.4799\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4703 - val_loss: 0.4771\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4676 - val_loss: 0.4741\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4636 - val_loss: 0.4702\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4602 - val_loss: 0.4683\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4577 - val_loss: 0.4655\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4550 - val_loss: 0.4639\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4524 - val_loss: 0.4615\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4497 - val_loss: 0.4604\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4478 - val_loss: 0.4574\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4460 - val_loss: 0.4564\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4439 - val_loss: 0.4550\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4419 - val_loss: 0.4544\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4401 - val_loss: 0.4516\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4390 - val_loss: 0.4504\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4369 - val_loss: 0.4486\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=./my_logs --port = 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2020_06_27-21_01_02'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir2 = get_run_logdir()\n",
    "run_logdir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/30\n",
      "11610/11610 [==============================] - 1s 59us/sample - loss: 0.4356 - val_loss: 0.4486\n",
      "Epoch 2/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4356 - val_loss: 0.4485\n",
      "Epoch 3/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4355 - val_loss: 0.4485\n",
      "Epoch 4/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4355 - val_loss: 0.4485\n",
      "Epoch 5/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4354 - val_loss: 0.4485\n",
      "Epoch 6/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4354 - val_loss: 0.4484\n",
      "Epoch 7/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4354 - val_loss: 0.4484\n",
      "Epoch 8/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4353 - val_loss: 0.4484\n",
      "Epoch 9/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4353 - val_loss: 0.4484\n",
      "Epoch 10/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4352 - val_loss: 0.4484\n",
      "Epoch 11/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4352 - val_loss: 0.4483\n",
      "Epoch 12/30\n",
      "11610/11610 [==============================] - 0s 32us/sample - loss: 0.4352 - val_loss: 0.4483\n",
      "Epoch 13/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4352 - val_loss: 0.4483\n",
      "Epoch 14/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4351 - val_loss: 0.4483\n",
      "Epoch 15/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4351 - val_loss: 0.4483\n",
      "Epoch 16/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4351 - val_loss: 0.4483\n",
      "Epoch 17/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4350 - val_loss: 0.4482\n",
      "Epoch 18/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4350 - val_loss: 0.4482\n",
      "Epoch 19/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4350 - val_loss: 0.4482\n",
      "Epoch 20/30\n",
      "11610/11610 [==============================] - 0s 31us/sample - loss: 0.4350 - val_loss: 0.4482\n",
      "Epoch 21/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4349 - val_loss: 0.4482\n",
      "Epoch 22/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4349 - val_loss: 0.4482\n",
      "Epoch 23/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4349 - val_loss: 0.4481\n",
      "Epoch 24/30\n",
      "11610/11610 [==============================] - 0s 34us/sample - loss: 0.4349 - val_loss: 0.4481\n",
      "Epoch 25/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4348 - val_loss: 0.4481\n",
      "Epoch 26/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4348 - val_loss: 0.4481\n",
      "Epoch 27/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4348 - val_loss: 0.4481\n",
      "Epoch 28/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4348 - val_loss: 0.4481\n",
      "Epoch 29/30\n",
      "11610/11610 [==============================] - 0s 30us/sample - loss: 0.4347 - val_loss: 0.4481\n",
      "Epoch 30/30\n",
      "11610/11610 [==============================] - 0s 29us/sample - loss: 0.4347 - val_loss: 0.4481\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='mse', optimizer=keras.optimizers.SGD(1e-5))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir2)\n",
    "history = model.fit(x_train, y_train, epochs=30, validation_data=(x_valid, y_valid), callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function __init__ in module tensorflow.python.keras.callbacks:\n",
      "\n",
      "__init__(self, log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None, **kwargs)\n",
      "    Initialize self.  See help(type(self)) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(keras.callbacks.TensorBoard.__init__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_logdir = get_run_logdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.create_file_writer(test_logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "with writer.as_default():\n",
    "    for step in range(1, 1000+1):\n",
    "        tf.summary.scalar('my_scaler', np.sin(step/10), step = step)\n",
    "        data = (np.random.randn(100)+2) * step / 100\n",
    "        tf.summary.histogram('my_hist', data, buckets=50, step = step)\n",
    "        images = np.random.rand(2, 32, 32, 3)\n",
    "        tf.summary.image('my_images', images * step / 1000, step = step)\n",
    "        texts = ['the step is ' + str(step), 'Its square is ' + str(step**2)]\n",
    "        tf.summary.text('my_text', texts, step = step)\n",
    "        sine_wave = tf.math.sin(tf.range(12000) / 48000 * 2 * np.pi * step)\n",
    "        audio = tf.reshape(tf.cast(sine_wave,  tf.float32), [1, -1, 1])\n",
    "        tf.summary.audio('my_audio', audio, sample_rate=48000, step = step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate = 3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation='relu'))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate)\n",
    "    model.compile(loss='mse', optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrappers = 포장지\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "11610/11610 [==============================] - 0s 37us/sample - loss: 1.5436 - val_loss: 0.7196\n",
      "Epoch 2/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.6562 - val_loss: 0.6269\n",
      "Epoch 3/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5901 - val_loss: 0.5808\n",
      "Epoch 4/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.5480 - val_loss: 0.5491\n",
      "Epoch 5/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5242 - val_loss: 0.5258\n",
      "Epoch 6/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.5018 - val_loss: 0.5105\n",
      "Epoch 7/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4919 - val_loss: 0.4989\n",
      "Epoch 8/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4802 - val_loss: 0.4926\n",
      "Epoch 9/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4754 - val_loss: 0.4854\n",
      "Epoch 10/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4658 - val_loss: 0.4817\n",
      "Epoch 11/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4610 - val_loss: 0.4770\n",
      "Epoch 12/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4560 - val_loss: 0.4714\n",
      "Epoch 13/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4502 - val_loss: 0.4700\n",
      "Epoch 14/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4461 - val_loss: 0.4676\n",
      "Epoch 15/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4448 - val_loss: 0.4616\n",
      "Epoch 16/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4397 - val_loss: 0.4605\n",
      "Epoch 17/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4360 - val_loss: 0.4568\n",
      "Epoch 18/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4336 - val_loss: 0.4595\n",
      "Epoch 19/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4319 - val_loss: 0.4517\n",
      "Epoch 20/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4283 - val_loss: 0.4491\n",
      "Epoch 21/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4273 - val_loss: 0.4487\n",
      "Epoch 22/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4236 - val_loss: 0.4463\n",
      "Epoch 23/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4208 - val_loss: 0.4484\n",
      "Epoch 24/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4202 - val_loss: 0.4418\n",
      "Epoch 25/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4168 - val_loss: 0.4410\n",
      "Epoch 26/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4153 - val_loss: 0.4401\n",
      "Epoch 27/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4135 - val_loss: 0.4401\n",
      "Epoch 28/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4113 - val_loss: 0.4394\n",
      "Epoch 29/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4121 - val_loss: 0.4370\n",
      "Epoch 30/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4112 - val_loss: 0.4349\n",
      "Epoch 31/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4068 - val_loss: 0.4346\n",
      "Epoch 32/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4059 - val_loss: 0.4311\n",
      "Epoch 33/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4030 - val_loss: 0.4315\n",
      "Epoch 34/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.4018 - val_loss: 0.4302\n",
      "Epoch 35/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.4002 - val_loss: 0.4278\n",
      "Epoch 36/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3994 - val_loss: 0.4293\n",
      "Epoch 37/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3980 - val_loss: 0.4261\n",
      "Epoch 38/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3981 - val_loss: 0.4254\n",
      "Epoch 39/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3948 - val_loss: 0.4243\n",
      "Epoch 40/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3932 - val_loss: 0.4248\n",
      "Epoch 41/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3924 - val_loss: 0.4219\n",
      "Epoch 42/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3912 - val_loss: 0.4218\n",
      "Epoch 43/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3892 - val_loss: 0.4218\n",
      "Epoch 44/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3888 - val_loss: 0.4190\n",
      "Epoch 45/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3868 - val_loss: 0.4181\n",
      "Epoch 46/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3860 - val_loss: 0.4145\n",
      "Epoch 47/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3853 - val_loss: 0.4154\n",
      "Epoch 48/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3836 - val_loss: 0.4131\n",
      "Epoch 49/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3824 - val_loss: 0.4146\n",
      "Epoch 50/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3813 - val_loss: 0.4138\n",
      "Epoch 51/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3805 - val_loss: 0.4111\n",
      "Epoch 52/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3802 - val_loss: 0.4089\n",
      "Epoch 53/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3784 - val_loss: 0.4087\n",
      "Epoch 54/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3769 - val_loss: 0.4135\n",
      "Epoch 55/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3817 - val_loss: 0.4083\n",
      "Epoch 56/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3760 - val_loss: 0.4193\n",
      "Epoch 57/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3770 - val_loss: 0.4063\n",
      "Epoch 58/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3739 - val_loss: 0.4114\n",
      "Epoch 59/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3886 - val_loss: 0.4144\n",
      "Epoch 60/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3803 - val_loss: 0.4216\n",
      "Epoch 61/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.4124 - val_loss: 0.4264\n",
      "Epoch 62/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3926 - val_loss: 0.4219\n",
      "Epoch 63/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3828 - val_loss: 0.4046\n",
      "Epoch 64/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3767 - val_loss: 0.4017\n",
      "Epoch 65/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3697 - val_loss: 0.4006\n",
      "Epoch 66/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3699 - val_loss: 0.3990\n",
      "Epoch 67/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3670 - val_loss: 0.3980\n",
      "Epoch 68/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3667 - val_loss: 0.4003\n",
      "Epoch 69/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3657 - val_loss: 0.3986\n",
      "Epoch 70/100\n",
      "11610/11610 [==============================] - 0s 23us/sample - loss: 0.3651 - val_loss: 0.3989\n",
      "Epoch 71/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3637 - val_loss: 0.3969\n",
      "Epoch 72/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3627 - val_loss: 0.3988\n",
      "Epoch 73/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3631 - val_loss: 0.3985\n",
      "Epoch 74/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3633 - val_loss: 0.3998\n",
      "Epoch 75/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3646 - val_loss: 0.3980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3598 - val_loss: 0.3967\n",
      "Epoch 77/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3608 - val_loss: 0.3937\n",
      "Epoch 78/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3590 - val_loss: 0.3965\n",
      "Epoch 79/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3586 - val_loss: 0.3921\n",
      "Epoch 80/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3572 - val_loss: 0.3943\n",
      "Epoch 81/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3578 - val_loss: 0.3940\n",
      "Epoch 82/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3573 - val_loss: 0.3925\n",
      "Epoch 83/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3562 - val_loss: 0.3957\n",
      "Epoch 84/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3557 - val_loss: 0.3928\n",
      "Epoch 85/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3563 - val_loss: 0.3992\n",
      "Epoch 86/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3553 - val_loss: 0.3884\n",
      "Epoch 87/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3549 - val_loss: 0.3881\n",
      "Epoch 88/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3526 - val_loss: 0.3896\n",
      "Epoch 89/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3524 - val_loss: 0.3879\n",
      "Epoch 90/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3508 - val_loss: 0.3863\n",
      "Epoch 91/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3523 - val_loss: 0.3858\n",
      "Epoch 92/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3485 - val_loss: 0.3938\n",
      "Epoch 93/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3497 - val_loss: 0.3904\n",
      "Epoch 94/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3510 - val_loss: 0.3890\n",
      "Epoch 95/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3547 - val_loss: 0.3897\n",
      "Epoch 96/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3488 - val_loss: 0.3852\n",
      "Epoch 97/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3503 - val_loss: 0.3868\n",
      "Epoch 98/100\n",
      "11610/11610 [==============================] - 0s 21us/sample - loss: 0.3471 - val_loss: 0.3835\n",
      "Epoch 99/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3491 - val_loss: 0.3834\n",
      "Epoch 100/100\n",
      "11610/11610 [==============================] - 0s 22us/sample - loss: 0.3465 - val_loss: 0.3865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x24839e76148>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# patience = 참을성\n",
    "keras_reg.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160/5160 [==============================] - 0s 10us/sample - loss: 0.3580\n"
     ]
    }
   ],
   "source": [
    "mse_test = keras_reg.score(x_test, y_test)\n",
    "y_pred = keras_reg.predict(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'n_hidden' : [0, 1, 2, 3],\n",
    "    'n_neurons' : np.arange(1, 100),\n",
    "    'learning_rate' : reciprocal(3e-4, 3e-2),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.0011195351881132835, n_hidden=3, n_neurons=35 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 55us/sample - loss: 1.6233 - val_loss: 0.8471\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.7282 - val_loss: 0.7171\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.6586 - val_loss: 0.6611\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6199 - val_loss: 0.6241\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5902 - val_loss: 0.5947\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5654 - val_loss: 0.5697\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5448 - val_loss: 0.5484\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5280 - val_loss: 0.5322\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5134 - val_loss: 0.5177\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5006 - val_loss: 0.5068\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4900 - val_loss: 0.4966\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4808 - val_loss: 0.4918\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4736 - val_loss: 0.4816\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4666 - val_loss: 0.4752\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4604 - val_loss: 0.4698\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4550 - val_loss: 0.4654\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4505 - val_loss: 0.4618\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4455 - val_loss: 0.4584\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4425 - val_loss: 0.4549\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4386 - val_loss: 0.4528\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4359 - val_loss: 0.4518\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4328 - val_loss: 0.4482\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4296 - val_loss: 0.4460\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4275 - val_loss: 0.4433\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4248 - val_loss: 0.4424\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4226 - val_loss: 0.4397\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4201 - val_loss: 0.4381\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4179 - val_loss: 0.4364\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4157 - val_loss: 0.4341\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4141 - val_loss: 0.4341\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4120 - val_loss: 0.4323\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4101 - val_loss: 0.4307\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4085 - val_loss: 0.4296\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4070 - val_loss: 0.4282\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4054 - val_loss: 0.4270\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4037 - val_loss: 0.4259\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4018 - val_loss: 0.4250\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4005 - val_loss: 0.4236\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3991 - val_loss: 0.4233\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3978 - val_loss: 0.4224\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3967 - val_loss: 0.4219\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3953 - val_loss: 0.4198\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3940 - val_loss: 0.4191\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3927 - val_loss: 0.4191\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3913 - val_loss: 0.4175\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3903 - val_loss: 0.4167\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3891 - val_loss: 0.4166\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3880 - val_loss: 0.4163\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3867 - val_loss: 0.4141\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3854 - val_loss: 0.4167\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3847 - val_loss: 0.4125\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3833 - val_loss: 0.4135\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3824 - val_loss: 0.4111\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3809 - val_loss: 0.4112\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3800 - val_loss: 0.4117\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3786 - val_loss: 0.4095\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3772 - val_loss: 0.4095\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3770 - val_loss: 0.4091\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3758 - val_loss: 0.4079\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3747 - val_loss: 0.4065\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3738 - val_loss: 0.4065\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3727 - val_loss: 0.4046\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3721 - val_loss: 0.4045\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3707 - val_loss: 0.4044\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3703 - val_loss: 0.4037\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3688 - val_loss: 0.4031\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3680 - val_loss: 0.4022\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3669 - val_loss: 0.4045\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3663 - val_loss: 0.3995\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3655 - val_loss: 0.3998\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3646 - val_loss: 0.3985\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3636 - val_loss: 0.3983\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3628 - val_loss: 0.3974\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3619 - val_loss: 0.3974\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3607 - val_loss: 0.3968\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3600 - val_loss: 0.3988\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3591 - val_loss: 0.3946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3587 - val_loss: 0.3939\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3570 - val_loss: 0.3952\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3569 - val_loss: 0.3946\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3560 - val_loss: 0.3922\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3551 - val_loss: 0.3920\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3544 - val_loss: 0.3939\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.3535 - val_loss: 0.3903\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3530 - val_loss: 0.3902\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3520 - val_loss: 0.3894\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3514 - val_loss: 0.3885\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3505 - val_loss: 0.3880\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3494 - val_loss: 0.3883\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3489 - val_loss: 0.3873\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3481 - val_loss: 0.3866\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3474 - val_loss: 0.3859\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3465 - val_loss: 0.3846\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3454 - val_loss: 0.3866\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3451 - val_loss: 0.3844\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3444 - val_loss: 0.3849\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3437 - val_loss: 0.3828\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3427 - val_loss: 0.3821\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3420 - val_loss: 0.3834\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3409 - val_loss: 0.3826\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3666\n",
      "[CV]  learning_rate=0.0011195351881132835, n_hidden=3, n_neurons=35, total=  20.5s\n",
      "[CV] learning_rate=0.0011195351881132835, n_hidden=3, n_neurons=35 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - ETA: 0s - loss: 2.5151 - 0s 64us/sample - loss: 2.1246 - val_loss: 0.9633\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8269 - val_loss: 0.7459\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6990 - val_loss: 0.6947\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6539 - val_loss: 0.6673\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6237 - val_loss: 0.6455\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6001 - val_loss: 0.6233\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5791 - val_loss: 0.6052\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5608 - val_loss: 0.5890\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5443 - val_loss: 0.5739\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5301 - val_loss: 0.5606\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5170 - val_loss: 0.5501\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5058 - val_loss: 0.5386\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4960 - val_loss: 0.5292\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4870 - val_loss: 0.5187\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4788 - val_loss: 0.5115\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4719 - val_loss: 0.5035\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4652 - val_loss: 0.4970\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4597 - val_loss: 0.4902\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4544 - val_loss: 0.4851\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4497 - val_loss: 0.4807\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4452 - val_loss: 0.4749\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4409 - val_loss: 0.4703\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4376 - val_loss: 0.4671\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4339 - val_loss: 0.4634\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4309 - val_loss: 0.4600\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4279 - val_loss: 0.4574\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4251 - val_loss: 0.4543\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4226 - val_loss: 0.4521\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4203 - val_loss: 0.4504\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4181 - val_loss: 0.4477\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4158 - val_loss: 0.4466\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4141 - val_loss: 0.4442\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4125 - val_loss: 0.4430\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4104 - val_loss: 0.4413\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4090 - val_loss: 0.4395\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4075 - val_loss: 0.4394\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4060 - val_loss: 0.4363\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4042 - val_loss: 0.4350\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4031 - val_loss: 0.4358\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4017 - val_loss: 0.4328\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4005 - val_loss: 0.4319\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3989 - val_loss: 0.4307\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3983 - val_loss: 0.4293\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3968 - val_loss: 0.4281\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3957 - val_loss: 0.4273\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3945 - val_loss: 0.4257\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3931 - val_loss: 0.4249\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3921 - val_loss: 0.4243\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3907 - val_loss: 0.4238\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3897 - val_loss: 0.4226\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3892 - val_loss: 0.4219\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3878 - val_loss: 0.4199\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3867 - val_loss: 0.4200\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3855 - val_loss: 0.4195\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3846 - val_loss: 0.4180\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3836 - val_loss: 0.4164\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3825 - val_loss: 0.4159\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3813 - val_loss: 0.4152\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3806 - val_loss: 0.4142\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3792 - val_loss: 0.4140\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3785 - val_loss: 0.4127\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3775 - val_loss: 0.4122\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3764 - val_loss: 0.4113\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3754 - val_loss: 0.4095\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3744 - val_loss: 0.4105\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3736 - val_loss: 0.4086\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3726 - val_loss: 0.4088\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3723 - val_loss: 0.4072\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3706 - val_loss: 0.4056\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3699 - val_loss: 0.4055\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3686 - val_loss: 0.4057\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3687 - val_loss: 0.4038\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3670 - val_loss: 0.4045\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3661 - val_loss: 0.4043\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3653 - val_loss: 0.4026\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3647 - val_loss: 0.4018\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3635 - val_loss: 0.4025\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3634 - val_loss: 0.4004\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3627 - val_loss: 0.4005\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3612 - val_loss: 0.4006\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3603 - val_loss: 0.3998\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3593 - val_loss: 0.3963\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3588 - val_loss: 0.3969\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3580 - val_loss: 0.3954\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3569 - val_loss: 0.3977\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3565 - val_loss: 0.3947\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3553 - val_loss: 0.3942\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3548 - val_loss: 0.3940\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3541 - val_loss: 0.3937\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3530 - val_loss: 0.3930\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3529 - val_loss: 0.3914\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3512 - val_loss: 0.3916\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3506 - val_loss: 0.3903\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3503 - val_loss: 0.3903\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3493 - val_loss: 0.3891\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3486 - val_loss: 0.3898\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3476 - val_loss: 0.3891\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3468 - val_loss: 0.3881\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3464 - val_loss: 0.3869\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3453 - val_loss: 0.3866\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3783\n",
      "[CV]  learning_rate=0.0011195351881132835, n_hidden=3, n_neurons=35, total=  20.2s\n",
      "[CV] learning_rate=0.0011195351881132835, n_hidden=3, n_neurons=35 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 2.3004 - val_loss: 0.9862\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8815 - val_loss: 0.7902\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7562 - val_loss: 0.7346\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7023 - val_loss: 0.6962\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.6656 - val_loss: 0.6573\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.6358 - val_loss: 0.6332\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6110 - val_loss: 0.6087\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5900 - val_loss: 0.5911\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5716 - val_loss: 0.5759\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5563 - val_loss: 0.5589\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5411 - val_loss: 0.5473\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5292 - val_loss: 0.5333\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5169 - val_loss: 0.5268\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5073 - val_loss: 0.5163\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4987 - val_loss: 0.5085\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4910 - val_loss: 0.5019\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4836 - val_loss: 0.4971\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4772 - val_loss: 0.4903\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4717 - val_loss: 0.4840\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4666 - val_loss: 0.4799\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4620 - val_loss: 0.4776\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4577 - val_loss: 0.4737\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4535 - val_loss: 0.4699\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4497 - val_loss: 0.4680\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4464 - val_loss: 0.4641\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4430 - val_loss: 0.4600\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4394 - val_loss: 0.4577\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4366 - val_loss: 0.4581\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4347 - val_loss: 0.4540\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4316 - val_loss: 0.4527\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4287 - val_loss: 0.4493\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4267 - val_loss: 0.4478\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4241 - val_loss: 0.4467\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4219 - val_loss: 0.4433\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4202 - val_loss: 0.4411\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4181 - val_loss: 0.4413\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4171 - val_loss: 0.4405\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4150 - val_loss: 0.4411\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4146 - val_loss: 0.4386\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4126 - val_loss: 0.4376\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4138 - val_loss: 0.4354\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4125 - val_loss: 0.4381\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4128 - val_loss: 0.4456\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4130 - val_loss: 0.4357\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4120 - val_loss: 0.4310\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4078 - val_loss: 0.4342\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4081 - val_loss: 0.4451\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4081 - val_loss: 0.4316\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4087 - val_loss: 0.4265\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4006 - val_loss: 0.4273\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4004 - val_loss: 0.4253\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3971 - val_loss: 0.4232\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3957 - val_loss: 0.4230\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3944 - val_loss: 0.4232\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3936 - val_loss: 0.4218\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3931 - val_loss: 0.4196\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3925 - val_loss: 0.4219\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3912 - val_loss: 0.4173\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3896 - val_loss: 0.4176\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3889 - val_loss: 0.4178\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3878 - val_loss: 0.4158\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3870 - val_loss: 0.4162\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3869 - val_loss: 0.4142\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3856 - val_loss: 0.4141\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3847 - val_loss: 0.4137\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3840 - val_loss: 0.4131\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3831 - val_loss: 0.4140\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3822 - val_loss: 0.4113\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3822 - val_loss: 0.4095\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3814 - val_loss: 0.4108\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3807 - val_loss: 0.4081\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3788 - val_loss: 0.4106\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3785 - val_loss: 0.4079\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3771 - val_loss: 0.4063\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3768 - val_loss: 0.4058\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3754 - val_loss: 0.4067\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3756 - val_loss: 0.4057\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3735 - val_loss: 0.4067\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3739 - val_loss: 0.4043\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3727 - val_loss: 0.4047\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3730 - val_loss: 0.4059\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3732 - val_loss: 0.4054\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3740 - val_loss: 0.4029\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3729 - val_loss: 0.4029\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3740 - val_loss: 0.4070\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3744 - val_loss: 0.4034\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3768 - val_loss: 0.4034\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3724 - val_loss: 0.4014\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3716 - val_loss: 0.3997\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3675 - val_loss: 0.3980\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3659 - val_loss: 0.3963\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3648 - val_loss: 0.3957\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3642 - val_loss: 0.3959\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3635 - val_loss: 0.3966\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3627 - val_loss: 0.3952\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3622 - val_loss: 0.3945\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3617 - val_loss: 0.3930\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3605 - val_loss: 0.3923\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3601 - val_loss: 0.3916\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3596 - val_loss: 0.3922\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3611\n",
      "[CV]  learning_rate=0.0011195351881132835, n_hidden=3, n_neurons=35, total=  20.2s\n",
      "[CV] learning_rate=0.0019193781100231727, n_hidden=1, n_neurons=75 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.9345 - val_loss: 0.8783\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7496 - val_loss: 0.7071\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6655 - val_loss: 0.6555\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6266 - val_loss: 0.6197\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5977 - val_loss: 0.5924\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5754 - val_loss: 0.5715\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5575 - val_loss: 0.5565\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5424 - val_loss: 0.5450\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5302 - val_loss: 0.5376\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5198 - val_loss: 0.5275\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5113 - val_loss: 0.5190\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5041 - val_loss: 0.5137\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4977 - val_loss: 0.5073\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4920 - val_loss: 0.5020\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4867 - val_loss: 0.4979\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4826 - val_loss: 0.4959\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4790 - val_loss: 0.4920\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4754 - val_loss: 0.4886\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4720 - val_loss: 0.4870\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4690 - val_loss: 0.4826\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4664 - val_loss: 0.4802\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4634 - val_loss: 0.4816\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4611 - val_loss: 0.4766\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4589 - val_loss: 0.4746\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4569 - val_loss: 0.4722\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4550 - val_loss: 0.4710\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4528 - val_loss: 0.4694\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4511 - val_loss: 0.4672\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4494 - val_loss: 0.4652\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4474 - val_loss: 0.4646\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4455 - val_loss: 0.4625\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4440 - val_loss: 0.4612\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4426 - val_loss: 0.4600\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4408 - val_loss: 0.4586\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4391 - val_loss: 0.4584\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4376 - val_loss: 0.4571\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4365 - val_loss: 0.4560\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4347 - val_loss: 0.4542\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4337 - val_loss: 0.4522\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4321 - val_loss: 0.4519\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4309 - val_loss: 0.4506\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4301 - val_loss: 0.4499\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4286 - val_loss: 0.4487\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4274 - val_loss: 0.4481\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4262 - val_loss: 0.4467\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4250 - val_loss: 0.4475\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4241 - val_loss: 0.4453\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4228 - val_loss: 0.4425\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4217 - val_loss: 0.4434\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4208 - val_loss: 0.4407\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4194 - val_loss: 0.4408\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 33us/sample - loss: 0.4186 - val_loss: 0.4398\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4176 - val_loss: 0.4398\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4169 - val_loss: 0.4377\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4153 - val_loss: 0.4364\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4145 - val_loss: 0.4359\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4137 - val_loss: 0.4352\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4129 - val_loss: 0.4341\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4120 - val_loss: 0.4348\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4109 - val_loss: 0.4332\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4100 - val_loss: 0.4313\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4091 - val_loss: 0.4314\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4082 - val_loss: 0.4300\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4074 - val_loss: 0.4304\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4064 - val_loss: 0.4287\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4055 - val_loss: 0.4296\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4050 - val_loss: 0.4271\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 31us/sample - loss: 0.4039 - val_loss: 0.4262\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.4030 - val_loss: 0.4273\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4021 - val_loss: 0.4263\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4015 - val_loss: 0.4239\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4008 - val_loss: 0.4255\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3998 - val_loss: 0.4266\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3995 - val_loss: 0.4235\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3983 - val_loss: 0.4228\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3976 - val_loss: 0.4234\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3969 - val_loss: 0.4202\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3963 - val_loss: 0.4191\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3955 - val_loss: 0.4200\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3949 - val_loss: 0.4194\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3938 - val_loss: 0.4188\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3930 - val_loss: 0.4205\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3927 - val_loss: 0.4177\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3920 - val_loss: 0.4167\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3911 - val_loss: 0.4153\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3905 - val_loss: 0.4165\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3897 - val_loss: 0.4159\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3890 - val_loss: 0.4144\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3877 - val_loss: 0.4203\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3875 - val_loss: 0.4141\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3868 - val_loss: 0.4142\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3865 - val_loss: 0.4126\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3860 - val_loss: 0.4133\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3854 - val_loss: 0.4105\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3843 - val_loss: 0.4109\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3842 - val_loss: 0.4097\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3833 - val_loss: 0.4131\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3823 - val_loss: 0.4141\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3818 - val_loss: 0.4081\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3815 - val_loss: 0.4096\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  learning_rate=0.0019193781100231727, n_hidden=1, n_neurons=75, total=  20.1s\n",
      "[CV] learning_rate=0.0019193781100231727, n_hidden=1, n_neurons=75 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 1.9536 - val_loss: 0.8487\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7680 - val_loss: 0.7421\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7011 - val_loss: 0.7047\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6628 - val_loss: 0.6699\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6319 - val_loss: 0.6425\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6059 - val_loss: 0.6192\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5849 - val_loss: 0.5988\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5647 - val_loss: 0.5817\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5496 - val_loss: 0.5698\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5357 - val_loss: 0.5540\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5242 - val_loss: 0.5466\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5134 - val_loss: 0.5379\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5034 - val_loss: 0.5277\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4962 - val_loss: 0.5224\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4889 - val_loss: 0.5175\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4840 - val_loss: 0.5100\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4779 - val_loss: 0.5022\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4728 - val_loss: 0.5003\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4685 - val_loss: 0.4931\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4638 - val_loss: 0.4952\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4602 - val_loss: 0.4878\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4583 - val_loss: 0.4859\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4552 - val_loss: 0.4811\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4520 - val_loss: 0.4785\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4513 - val_loss: 0.4765\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4464 - val_loss: 0.4747\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4440 - val_loss: 0.4751\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4422 - val_loss: 0.4706\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4403 - val_loss: 0.4697\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4386 - val_loss: 0.4650\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4374 - val_loss: 0.4622\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4340 - val_loss: 0.4627\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4324 - val_loss: 0.4596\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4311 - val_loss: 0.4601\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4298 - val_loss: 0.4571\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4280 - val_loss: 0.4556\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4254 - val_loss: 0.4540\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4238 - val_loss: 0.4532\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4226 - val_loss: 0.4501\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4213 - val_loss: 0.4493\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4190 - val_loss: 0.4472\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4177 - val_loss: 0.4459\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4163 - val_loss: 0.4462\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4158 - val_loss: 0.4455\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4157 - val_loss: 0.4438\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4150 - val_loss: 0.4403\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4111 - val_loss: 0.4400\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4101 - val_loss: 0.4377\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4097 - val_loss: 0.4364\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4075 - val_loss: 0.4351\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4064 - val_loss: 0.4353\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4061 - val_loss: 0.4331\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4048 - val_loss: 0.4340\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4031 - val_loss: 0.4315\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4024 - val_loss: 0.4304\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4000 - val_loss: 0.4335\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4006 - val_loss: 0.4296\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3985 - val_loss: 0.4311\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3986 - val_loss: 0.4266\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3967 - val_loss: 0.4275\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3963 - val_loss: 0.4253\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3954 - val_loss: 0.4242\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3947 - val_loss: 0.4247\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3934 - val_loss: 0.4257\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3928 - val_loss: 0.4227\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3922 - val_loss: 0.4218\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3909 - val_loss: 0.4222\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3906 - val_loss: 0.4210\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3890 - val_loss: 0.4200\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3887 - val_loss: 0.4189\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3879 - val_loss: 0.4191\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3870 - val_loss: 0.4179\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3872 - val_loss: 0.4177\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3858 - val_loss: 0.4181\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3857 - val_loss: 0.4162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3848 - val_loss: 0.4165\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3852 - val_loss: 0.4151\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3825 - val_loss: 0.4159\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3823 - val_loss: 0.4142\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3833 - val_loss: 0.4164\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3816 - val_loss: 0.4150\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3823 - val_loss: 0.4138\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3807 - val_loss: 0.4131\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3801 - val_loss: 0.4131\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3782 - val_loss: 0.4113\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3785 - val_loss: 0.4124\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3779 - val_loss: 0.4099\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3770 - val_loss: 0.4095\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3746 - val_loss: 0.4090\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3748 - val_loss: 0.4090\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3739 - val_loss: 0.4089\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3734 - val_loss: 0.4067\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3724 - val_loss: 0.4075\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3731 - val_loss: 0.4064\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3711 - val_loss: 0.4060\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3711 - val_loss: 0.4060\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3708 - val_loss: 0.4051\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3692 - val_loss: 0.4046\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3694 - val_loss: 0.4055\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3706 - val_loss: 0.4032\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3925\n",
      "[CV]  learning_rate=0.0019193781100231727, n_hidden=1, n_neurons=75, total=  18.9s\n",
      "[CV] learning_rate=0.0019193781100231727, n_hidden=1, n_neurons=75 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.7553 - val_loss: 0.8022\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8360 - val_loss: 1.1262\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.0511 - val_loss: 0.7739\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.9760 - val_loss: 0.6259\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6112 - val_loss: 0.5958\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5832 - val_loss: 0.5753\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5622 - val_loss: 0.5575\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5449 - val_loss: 0.5433\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5307 - val_loss: 0.5307\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5186 - val_loss: 0.5212\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5086 - val_loss: 0.5136\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5003 - val_loss: 0.5061\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4925 - val_loss: 0.4996\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4862 - val_loss: 0.4944\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4806 - val_loss: 0.4899\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4755 - val_loss: 0.4852\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4709 - val_loss: 0.4801\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4670 - val_loss: 0.4778\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4629 - val_loss: 0.4733\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4594 - val_loss: 0.4707\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4564 - val_loss: 0.4697\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4536 - val_loss: 0.4672\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4506 - val_loss: 0.4628\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4484 - val_loss: 0.4605\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4458 - val_loss: 0.4593\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4440 - val_loss: 0.4577\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4414 - val_loss: 0.4563\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4397 - val_loss: 0.4534\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4378 - val_loss: 0.4523\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4357 - val_loss: 0.4497\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4342 - val_loss: 0.4491\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4325 - val_loss: 0.4468\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4310 - val_loss: 0.4470\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4295 - val_loss: 0.4447\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4278 - val_loss: 0.4441\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4265 - val_loss: 0.4423\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4251 - val_loss: 0.4408\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4237 - val_loss: 0.4406\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4223 - val_loss: 0.4394\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4207 - val_loss: 0.4381\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4195 - val_loss: 0.4371\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4184 - val_loss: 0.4358\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4171 - val_loss: 0.4341\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4156 - val_loss: 0.4345\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4146 - val_loss: 0.4332\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4133 - val_loss: 0.4326\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4124 - val_loss: 0.4314\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4113 - val_loss: 0.4302\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4103 - val_loss: 0.4302\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4093 - val_loss: 0.4293\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4083 - val_loss: 0.4286\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4074 - val_loss: 0.4269\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4061 - val_loss: 0.4285\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4055 - val_loss: 0.4254\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4044 - val_loss: 0.4257\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4034 - val_loss: 0.4251\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4026 - val_loss: 0.4248\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4021 - val_loss: 0.4234\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4009 - val_loss: 0.4218\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4004 - val_loss: 0.4213\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3995 - val_loss: 0.4204\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3984 - val_loss: 0.4200\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3979 - val_loss: 0.4199\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3968 - val_loss: 0.4199\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3962 - val_loss: 0.4200\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3956 - val_loss: 0.4189\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3949 - val_loss: 0.4165\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3941 - val_loss: 0.4176\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3936 - val_loss: 0.4159\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3929 - val_loss: 0.4160\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3923 - val_loss: 0.4155\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3912 - val_loss: 0.4148\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3908 - val_loss: 0.4155\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3903 - val_loss: 0.4147\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3896 - val_loss: 0.4141\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3890 - val_loss: 0.4126\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3882 - val_loss: 0.4134\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3875 - val_loss: 0.4130\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3870 - val_loss: 0.4118\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3866 - val_loss: 0.4125\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3859 - val_loss: 0.4114\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3854 - val_loss: 0.4101\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3847 - val_loss: 0.4112\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3842 - val_loss: 0.4106\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3837 - val_loss: 0.4103\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3829 - val_loss: 0.4098\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3824 - val_loss: 0.4088\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3821 - val_loss: 0.4088\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3815 - val_loss: 0.4088\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3810 - val_loss: 0.4085\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3801 - val_loss: 0.4072\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3799 - val_loss: 0.4065\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3790 - val_loss: 0.4087\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3789 - val_loss: 0.4073\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3781 - val_loss: 0.4056\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3778 - val_loss: 0.4062\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3773 - val_loss: 0.4053\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3769 - val_loss: 0.4042\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3765 - val_loss: 0.4048\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3760 - val_loss: 0.4047\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.3758\n",
      "[CV]  learning_rate=0.0019193781100231727, n_hidden=1, n_neurons=75, total=  18.7s\n",
      "[CV] learning_rate=0.0007617196357040952, n_hidden=2, n_neurons=13 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.9778 - val_loss: 1.5146\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.0580 - val_loss: 0.8981\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7974 - val_loss: 0.7855\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7320 - val_loss: 0.7395\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6987 - val_loss: 0.7087\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6746 - val_loss: 0.6851\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6554 - val_loss: 0.6655\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6391 - val_loss: 0.6503\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6252 - val_loss: 0.6363\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6126 - val_loss: 0.6240\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6011 - val_loss: 0.6139\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5907 - val_loss: 0.6033\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5811 - val_loss: 0.5956\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5720 - val_loss: 0.5850\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5638 - val_loss: 0.5771\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5555 - val_loss: 0.5702\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5483 - val_loss: 0.5629\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5409 - val_loss: 0.5567\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5344 - val_loss: 0.5503\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5284 - val_loss: 0.5436\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5221 - val_loss: 0.5394\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5170 - val_loss: 0.5328\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5115 - val_loss: 0.5281\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5064 - val_loss: 0.5221\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5014 - val_loss: 0.5177\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4971 - val_loss: 0.5134\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4927 - val_loss: 0.5098\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4886 - val_loss: 0.5056\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4846 - val_loss: 0.5029\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4809 - val_loss: 0.4989\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4775 - val_loss: 0.4954\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4743 - val_loss: 0.4925\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4710 - val_loss: 0.4895\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4679 - val_loss: 0.4873\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4651 - val_loss: 0.4844\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4625 - val_loss: 0.4819\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4600 - val_loss: 0.4794\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4577 - val_loss: 0.4777\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4555 - val_loss: 0.4758\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4534 - val_loss: 0.4739\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4511 - val_loss: 0.4720\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4493 - val_loss: 0.4700\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4475 - val_loss: 0.4687\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4458 - val_loss: 0.4674\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4439 - val_loss: 0.4664\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4424 - val_loss: 0.4642\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4408 - val_loss: 0.4637\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4394 - val_loss: 0.4622\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4378 - val_loss: 0.4625\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4367 - val_loss: 0.4601\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4352 - val_loss: 0.4585\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4340 - val_loss: 0.4579\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4327 - val_loss: 0.4571\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4314 - val_loss: 0.4558\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4300 - val_loss: 0.4562\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4291 - val_loss: 0.4535\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4281 - val_loss: 0.4531\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4268 - val_loss: 0.4520\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4258 - val_loss: 0.4512\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4249 - val_loss: 0.4500\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4239 - val_loss: 0.4490\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4228 - val_loss: 0.4484\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4219 - val_loss: 0.4475\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4210 - val_loss: 0.4467\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4201 - val_loss: 0.4459\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4193 - val_loss: 0.4452\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4181 - val_loss: 0.4444\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4173 - val_loss: 0.4444\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4164 - val_loss: 0.4421\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4157 - val_loss: 0.4417\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4147 - val_loss: 0.4423\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4141 - val_loss: 0.4401\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4131 - val_loss: 0.4398\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4123 - val_loss: 0.4389\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4115 - val_loss: 0.4381\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4107 - val_loss: 0.4375\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4100 - val_loss: 0.4372\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4090 - val_loss: 0.4367\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4083 - val_loss: 0.4360\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4075 - val_loss: 0.4348\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4067 - val_loss: 0.4346\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4060 - val_loss: 0.4333\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4054 - val_loss: 0.4332\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4047 - val_loss: 0.4324\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4041 - val_loss: 0.4313\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4033 - val_loss: 0.4310\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4025 - val_loss: 0.4298\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4020 - val_loss: 0.4297\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4013 - val_loss: 0.4291\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4006 - val_loss: 0.4291\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4001 - val_loss: 0.4279\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3994 - val_loss: 0.4272\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3988 - val_loss: 0.4266\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3982 - val_loss: 0.4266\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3976 - val_loss: 0.4259\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3968 - val_loss: 0.4252\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3964 - val_loss: 0.4244\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3959 - val_loss: 0.4241\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3953 - val_loss: 0.4232\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3946 - val_loss: 0.4252\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.4153\n",
      "[CV]  learning_rate=0.0007617196357040952, n_hidden=2, n_neurons=13, total=  19.4s\n",
      "[CV] learning_rate=0.0007617196357040952, n_hidden=2, n_neurons=13 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 3.3300 - val_loss: 1.6281\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 1.3092 - val_loss: 1.0123\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.9691 - val_loss: 0.9133\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8685 - val_loss: 0.8463\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.8201 - val_loss: 0.8170\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7868 - val_loss: 0.7885\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7595 - val_loss: 0.7665\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.7360 - val_loss: 0.7478\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.7160 - val_loss: 0.7314\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6988 - val_loss: 0.7173\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6831 - val_loss: 0.7033\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6693 - val_loss: 0.6911\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6561 - val_loss: 0.6798\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6448 - val_loss: 0.6697\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6338 - val_loss: 0.6604\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6232 - val_loss: 0.6530\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6145 - val_loss: 0.6429\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6053 - val_loss: 0.6370\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5974 - val_loss: 0.6281\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5897 - val_loss: 0.6213\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5821 - val_loss: 0.6155\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5758 - val_loss: 0.6081\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5692 - val_loss: 0.6023\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5632 - val_loss: 0.5970\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5573 - val_loss: 0.5916\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5521 - val_loss: 0.5864\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5469 - val_loss: 0.5814\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5422 - val_loss: 0.5772\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5375 - val_loss: 0.5727\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5328 - val_loss: 0.5686\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5285 - val_loss: 0.5645\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5243 - val_loss: 0.5597\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5206 - val_loss: 0.5556\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5166 - val_loss: 0.5520\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5131 - val_loss: 0.5482\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5093 - val_loss: 0.5448\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5067 - val_loss: 0.5417\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5031 - val_loss: 0.5377\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5003 - val_loss: 0.5349\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4974 - val_loss: 0.5317\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4946 - val_loss: 0.5289\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4916 - val_loss: 0.5258\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4890 - val_loss: 0.5237\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4866 - val_loss: 0.5206\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4839 - val_loss: 0.5185\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4817 - val_loss: 0.5152\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4794 - val_loss: 0.5130\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4770 - val_loss: 0.5110\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4750 - val_loss: 0.5097\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4733 - val_loss: 0.5063\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4712 - val_loss: 0.5045\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4694 - val_loss: 0.5032\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4677 - val_loss: 0.5012\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4656 - val_loss: 0.4999\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4645 - val_loss: 0.4978\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4622 - val_loss: 0.4983\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4617 - val_loss: 0.4949\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4595 - val_loss: 0.4943\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4578 - val_loss: 0.4926\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4570 - val_loss: 0.4911\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4555 - val_loss: 0.4909\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4544 - val_loss: 0.4892\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4533 - val_loss: 0.4878\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4519 - val_loss: 0.4864\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4509 - val_loss: 0.4855\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4499 - val_loss: 0.4847\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4487 - val_loss: 0.4833\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4476 - val_loss: 0.4821\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4467 - val_loss: 0.4815\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4454 - val_loss: 0.4805\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4448 - val_loss: 0.4791\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4435 - val_loss: 0.4781\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4432 - val_loss: 0.4770\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4424 - val_loss: 0.4774\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4409 - val_loss: 0.4771\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4402 - val_loss: 0.4750\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4401 - val_loss: 0.4742\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4391 - val_loss: 0.4743\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4380 - val_loss: 0.4744\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4378 - val_loss: 0.4732\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4367 - val_loss: 0.4716\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4364 - val_loss: 0.4717\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4356 - val_loss: 0.4718\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4351 - val_loss: 0.4703\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4345 - val_loss: 0.4698\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4335 - val_loss: 0.4694\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4333 - val_loss: 0.4688\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4327 - val_loss: 0.4683\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4321 - val_loss: 0.4672\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4318 - val_loss: 0.4671\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4310 - val_loss: 0.4670\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4305 - val_loss: 0.4665\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4296 - val_loss: 0.4659\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4295 - val_loss: 0.4653\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4289 - val_loss: 0.4651\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4283 - val_loss: 0.4642\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4277 - val_loss: 0.4640\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4276 - val_loss: 0.4638\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4269 - val_loss: 0.4641\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4267 - val_loss: 0.4636\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.4590\n",
      "[CV]  learning_rate=0.0007617196357040952, n_hidden=2, n_neurons=13, total=  19.6s\n",
      "[CV] learning_rate=0.0007617196357040952, n_hidden=2, n_neurons=13 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.6026 - val_loss: 1.3434\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 1.0625 - val_loss: 0.8834\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8770 - val_loss: 0.8073\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8166 - val_loss: 0.7717\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7772 - val_loss: 0.7424\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7454 - val_loss: 0.7169\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7178 - val_loss: 0.6953\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6931 - val_loss: 0.6750\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6706 - val_loss: 0.6552\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6499 - val_loss: 0.6378\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6309 - val_loss: 0.6213\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6133 - val_loss: 0.6063\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5978 - val_loss: 0.5918\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5837 - val_loss: 0.5796\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5707 - val_loss: 0.5697\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5599 - val_loss: 0.5590\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5495 - val_loss: 0.5499\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5404 - val_loss: 0.5412\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5317 - val_loss: 0.5342\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5243 - val_loss: 0.5270\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5174 - val_loss: 0.5206\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5111 - val_loss: 0.5153\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5054 - val_loss: 0.5103\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5000 - val_loss: 0.5054\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4950 - val_loss: 0.5009\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4905 - val_loss: 0.4972\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4863 - val_loss: 0.4936\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4825 - val_loss: 0.4901\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4790 - val_loss: 0.4875\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4758 - val_loss: 0.4845\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4727 - val_loss: 0.4814\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4700 - val_loss: 0.4789\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4671 - val_loss: 0.4771\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4647 - val_loss: 0.4748\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4624 - val_loss: 0.4721\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4600 - val_loss: 0.4702\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4579 - val_loss: 0.4682\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4559 - val_loss: 0.4663\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4540 - val_loss: 0.4646\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4522 - val_loss: 0.4624\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4504 - val_loss: 0.4608\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4486 - val_loss: 0.4597\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4471 - val_loss: 0.4580\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4455 - val_loss: 0.4566\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4439 - val_loss: 0.4555\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4424 - val_loss: 0.4543\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4409 - val_loss: 0.4531\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4397 - val_loss: 0.4518\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4385 - val_loss: 0.4507\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4371 - val_loss: 0.4498\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4360 - val_loss: 0.4490\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4349 - val_loss: 0.4472\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4336 - val_loss: 0.4461\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4324 - val_loss: 0.4452\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4313 - val_loss: 0.4443\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4302 - val_loss: 0.4431\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4293 - val_loss: 0.4417\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4281 - val_loss: 0.4408\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4269 - val_loss: 0.4397\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4261 - val_loss: 0.4392\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4249 - val_loss: 0.4385\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4240 - val_loss: 0.4365\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4231 - val_loss: 0.4364\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4224 - val_loss: 0.4351\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4213 - val_loss: 0.4344\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4205 - val_loss: 0.4339\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4196 - val_loss: 0.4332\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4188 - val_loss: 0.4324\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4180 - val_loss: 0.4317\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4170 - val_loss: 0.4312\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4164 - val_loss: 0.4303\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4156 - val_loss: 0.4296\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4149 - val_loss: 0.4285\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4140 - val_loss: 0.4279\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4133 - val_loss: 0.4277\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4126 - val_loss: 0.4270\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4120 - val_loss: 0.4265\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4112 - val_loss: 0.4262\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4105 - val_loss: 0.4258\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4099 - val_loss: 0.4248\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4093 - val_loss: 0.4242\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4086 - val_loss: 0.4234\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4077 - val_loss: 0.4234\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4073 - val_loss: 0.4222\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4067 - val_loss: 0.4214\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4060 - val_loss: 0.4208\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4054 - val_loss: 0.4207\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4047 - val_loss: 0.4202\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4042 - val_loss: 0.4192\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4036 - val_loss: 0.4191\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4030 - val_loss: 0.4182\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4026 - val_loss: 0.4181\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4020 - val_loss: 0.4181\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4015 - val_loss: 0.4173\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4007 - val_loss: 0.4167\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4004 - val_loss: 0.4161\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3997 - val_loss: 0.4158\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3993 - val_loss: 0.4152\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3985 - val_loss: 0.4154\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3981 - val_loss: 0.4146\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3930\n",
      "[CV]  learning_rate=0.0007617196357040952, n_hidden=2, n_neurons=13, total=  19.3s\n",
      "[CV] learning_rate=0.001529089812000745, n_hidden=2, n_neurons=19 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.2928 - val_loss: 1.0577\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8719 - val_loss: 0.7680\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7251 - val_loss: 0.6903\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6702 - val_loss: 0.6531\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6361 - val_loss: 0.6250\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6093 - val_loss: 0.6012\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5865 - val_loss: 0.5800\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5669 - val_loss: 0.5632\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5497 - val_loss: 0.5491\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5352 - val_loss: 0.5350\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5226 - val_loss: 0.5241\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5118 - val_loss: 0.5149\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5020 - val_loss: 0.5066\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4938 - val_loss: 0.5002\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4868 - val_loss: 0.4933\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4798 - val_loss: 0.4883\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4737 - val_loss: 0.4829\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4684 - val_loss: 0.4796\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4636 - val_loss: 0.4742\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4589 - val_loss: 0.4708\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4545 - val_loss: 0.4676\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4508 - val_loss: 0.4647\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4468 - val_loss: 0.4612\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4438 - val_loss: 0.4590\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4405 - val_loss: 0.4566\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4382 - val_loss: 0.4552\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4355 - val_loss: 0.4532\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4329 - val_loss: 0.4518\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4307 - val_loss: 0.4496\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4286 - val_loss: 0.4462\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4264 - val_loss: 0.4466\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4241 - val_loss: 0.4430\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4223 - val_loss: 0.4421\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4205 - val_loss: 0.4408\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4190 - val_loss: 0.4389\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4174 - val_loss: 0.4375\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4156 - val_loss: 0.4353\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4143 - val_loss: 0.4353\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4127 - val_loss: 0.4342\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4113 - val_loss: 0.4329\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4100 - val_loss: 0.4315\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4079 - val_loss: 0.4327\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4076 - val_loss: 0.4287\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4061 - val_loss: 0.4273\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4047 - val_loss: 0.4266\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4036 - val_loss: 0.4257\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4023 - val_loss: 0.4255\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4013 - val_loss: 0.4245\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3997 - val_loss: 0.4239\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3991 - val_loss: 0.4225\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3974 - val_loss: 0.4211\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3968 - val_loss: 0.4198\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3961 - val_loss: 0.4186\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3946 - val_loss: 0.4176\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3934 - val_loss: 0.4173\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3924 - val_loss: 0.4158\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3916 - val_loss: 0.4162\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3905 - val_loss: 0.4161\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3893 - val_loss: 0.4150\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3886 - val_loss: 0.4125\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3878 - val_loss: 0.4120\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3865 - val_loss: 0.4105\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3851 - val_loss: 0.4122\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3849 - val_loss: 0.4087\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3836 - val_loss: 0.4084\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3827 - val_loss: 0.4090\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3822 - val_loss: 0.4072\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3810 - val_loss: 0.4077\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3803 - val_loss: 0.4062\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3797 - val_loss: 0.4042\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3785 - val_loss: 0.4044\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3778 - val_loss: 0.4041\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3770 - val_loss: 0.4041\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3763 - val_loss: 0.4018\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3754 - val_loss: 0.4019\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3745 - val_loss: 0.4016\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3740 - val_loss: 0.4008\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3734 - val_loss: 0.3995\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3725 - val_loss: 0.4004\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3716 - val_loss: 0.3993\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3707 - val_loss: 0.3979\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3702 - val_loss: 0.3973\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3694 - val_loss: 0.3973\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3685 - val_loss: 0.3968\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3678 - val_loss: 0.3979\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3672 - val_loss: 0.3961\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3664 - val_loss: 0.3960\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3660 - val_loss: 0.3940\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3651 - val_loss: 0.3950\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3646 - val_loss: 0.3951\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3639 - val_loss: 0.3942\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3631 - val_loss: 0.3946\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3626 - val_loss: 0.3928\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3622 - val_loss: 0.3925\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3616 - val_loss: 0.3926\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3608 - val_loss: 0.3914\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3597 - val_loss: 0.3927\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3595 - val_loss: 0.3920\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3589 - val_loss: 0.3908\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3585 - val_loss: 0.3893\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3749\n",
      "[CV]  learning_rate=0.001529089812000745, n_hidden=2, n_neurons=19, total=  19.5s\n",
      "[CV] learning_rate=0.001529089812000745, n_hidden=2, n_neurons=19 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.5446 - val_loss: 1.1110\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8469 - val_loss: 0.7220\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6703 - val_loss: 0.6649\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6231 - val_loss: 0.6349\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5925 - val_loss: 0.6106\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5697 - val_loss: 0.5911\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5507 - val_loss: 0.5746\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5344 - val_loss: 0.5602\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5203 - val_loss: 0.5472\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5084 - val_loss: 0.5358\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4973 - val_loss: 0.5257\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4877 - val_loss: 0.5164\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4789 - val_loss: 0.5104\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4727 - val_loss: 0.5025\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4651 - val_loss: 0.4990\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4601 - val_loss: 0.4934\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4562 - val_loss: 0.4874\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4508 - val_loss: 0.4859\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4475 - val_loss: 0.4794\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4436 - val_loss: 0.4758\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4405 - val_loss: 0.4739\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4373 - val_loss: 0.4697\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4346 - val_loss: 0.4681\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4325 - val_loss: 0.4652\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4299 - val_loss: 0.4631\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4281 - val_loss: 0.4598\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4262 - val_loss: 0.4576\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4241 - val_loss: 0.4567\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4224 - val_loss: 0.4541\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4206 - val_loss: 0.4528\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4197 - val_loss: 0.4521\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4175 - val_loss: 0.4498\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4161 - val_loss: 0.4484\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4142 - val_loss: 0.4474\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4132 - val_loss: 0.4464\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4116 - val_loss: 0.4448\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4107 - val_loss: 0.4428\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4090 - val_loss: 0.4432\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4086 - val_loss: 0.4416\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4066 - val_loss: 0.4396\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4053 - val_loss: 0.4407\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4048 - val_loss: 0.4374\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4035 - val_loss: 0.4371\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4025 - val_loss: 0.4354\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4016 - val_loss: 0.4340\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4004 - val_loss: 0.4349\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3994 - val_loss: 0.4330\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3989 - val_loss: 0.4328\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3979 - val_loss: 0.4313\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3969 - val_loss: 0.4312\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3959 - val_loss: 0.4299\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3950 - val_loss: 0.4294\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3950 - val_loss: 0.4282\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3928 - val_loss: 0.4295\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3926 - val_loss: 0.4269\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3917 - val_loss: 0.4276\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3920 - val_loss: 0.4256\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3897 - val_loss: 0.4265\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3894 - val_loss: 0.4255\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3886 - val_loss: 0.4244\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3875 - val_loss: 0.4239\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3877 - val_loss: 0.4225\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3867 - val_loss: 0.4241\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3868 - val_loss: 0.4206\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3846 - val_loss: 0.4211\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3843 - val_loss: 0.4193\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3837 - val_loss: 0.4191\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3826 - val_loss: 0.4196\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3822 - val_loss: 0.4185\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3817 - val_loss: 0.4173\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3801 - val_loss: 0.4194\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3802 - val_loss: 0.4153\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3790 - val_loss: 0.4157\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3782 - val_loss: 0.4169\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3786 - val_loss: 0.4164\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3775 - val_loss: 0.4162\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3769 - val_loss: 0.4151\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3752 - val_loss: 0.4132\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3752 - val_loss: 0.4140\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3750 - val_loss: 0.4127\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3749 - val_loss: 0.4121\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3730 - val_loss: 0.4121\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3727 - val_loss: 0.4102\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3718 - val_loss: 0.4102\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3713 - val_loss: 0.4102\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3706 - val_loss: 0.4093\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3706 - val_loss: 0.4083\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3685 - val_loss: 0.4099\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3692 - val_loss: 0.4083\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3680 - val_loss: 0.4080\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3676 - val_loss: 0.4077\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3670 - val_loss: 0.4064\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3668 - val_loss: 0.4067\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3661 - val_loss: 0.4070\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3658 - val_loss: 0.4066\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3669 - val_loss: 0.4063\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3640 - val_loss: 0.4055\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3638 - val_loss: 0.4062\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3635 - val_loss: 0.4032\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3625 - val_loss: 0.4033\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3917\n",
      "[CV]  learning_rate=0.001529089812000745, n_hidden=2, n_neurons=19, total=  19.3s\n",
      "[CV] learning_rate=0.001529089812000745, n_hidden=2, n_neurons=19 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.6211 - val_loss: 1.1779\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.9153 - val_loss: 0.7528\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7345 - val_loss: 0.6953\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6855 - val_loss: 0.6619\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6523 - val_loss: 0.6362\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6258 - val_loss: 0.6137\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6029 - val_loss: 0.5950\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5838 - val_loss: 0.5793\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5676 - val_loss: 0.5683\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5534 - val_loss: 0.5561\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5423 - val_loss: 0.5463\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5321 - val_loss: 0.5379\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5235 - val_loss: 0.5327\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5159 - val_loss: 0.5253\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5093 - val_loss: 0.5205\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5035 - val_loss: 0.5127\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4979 - val_loss: 0.5109\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4936 - val_loss: 0.5052\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4891 - val_loss: 0.5030\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4848 - val_loss: 0.4980\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4808 - val_loss: 0.4952\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4778 - val_loss: 0.4915\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4738 - val_loss: 0.4911\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4709 - val_loss: 0.4849\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4678 - val_loss: 0.4832\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4647 - val_loss: 0.4791\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4619 - val_loss: 0.4784\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4587 - val_loss: 0.4759\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4564 - val_loss: 0.4727\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4535 - val_loss: 0.4716\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4511 - val_loss: 0.4670\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4486 - val_loss: 0.4655\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4462 - val_loss: 0.4631\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4439 - val_loss: 0.4597\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4418 - val_loss: 0.4591\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4395 - val_loss: 0.4572\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4377 - val_loss: 0.4562\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4355 - val_loss: 0.4539\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4334 - val_loss: 0.4532\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4320 - val_loss: 0.4510\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4297 - val_loss: 0.4484\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4283 - val_loss: 0.4490\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4269 - val_loss: 0.4463\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4254 - val_loss: 0.4462\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4233 - val_loss: 0.4440\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4220 - val_loss: 0.4439\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4208 - val_loss: 0.4430\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4193 - val_loss: 0.4395\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4179 - val_loss: 0.4402\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4168 - val_loss: 0.4389\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4156 - val_loss: 0.4387\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4145 - val_loss: 0.4369\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4130 - val_loss: 0.4351\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4120 - val_loss: 0.4342\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4107 - val_loss: 0.4335\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4100 - val_loss: 0.4334\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4084 - val_loss: 0.4305\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4076 - val_loss: 0.4318\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4066 - val_loss: 0.4317\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4052 - val_loss: 0.4297\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4044 - val_loss: 0.4288\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4033 - val_loss: 0.4279\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4023 - val_loss: 0.4289\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4016 - val_loss: 0.4259\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4006 - val_loss: 0.4262\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3995 - val_loss: 0.4272\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3988 - val_loss: 0.4270\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3982 - val_loss: 0.4236\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3971 - val_loss: 0.4231\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3963 - val_loss: 0.4232\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3958 - val_loss: 0.4225\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3947 - val_loss: 0.4229\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3936 - val_loss: 0.4226\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3931 - val_loss: 0.4215\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3926 - val_loss: 0.4208\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3917 - val_loss: 0.4208\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3910 - val_loss: 0.4199\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3900 - val_loss: 0.4187\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3895 - val_loss: 0.4195\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3886 - val_loss: 0.4180\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3880 - val_loss: 0.4176\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3873 - val_loss: 0.4160\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3866 - val_loss: 0.4162\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3858 - val_loss: 0.4141\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3852 - val_loss: 0.4130\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3845 - val_loss: 0.4128\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3838 - val_loss: 0.4134\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3833 - val_loss: 0.4123\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3826 - val_loss: 0.4118\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3821 - val_loss: 0.4125\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3813 - val_loss: 0.4112\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3807 - val_loss: 0.4098\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3800 - val_loss: 0.4090\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3792 - val_loss: 0.4082\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3789 - val_loss: 0.4087\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3781 - val_loss: 0.4073\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3774 - val_loss: 0.4095\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3767 - val_loss: 0.4090\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3764 - val_loss: 0.4075\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3754 - val_loss: 0.4074\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3815\n",
      "[CV]  learning_rate=0.001529089812000745, n_hidden=2, n_neurons=19, total=  19.3s\n",
      "[CV] learning_rate=0.001609164958586291, n_hidden=2, n_neurons=13 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 64us/sample - loss: 1.9567 - val_loss: 0.9725\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7733 - val_loss: 0.7660\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6851 - val_loss: 0.7000\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6449 - val_loss: 0.6604\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6160 - val_loss: 0.6323\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5937 - val_loss: 0.6109\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5751 - val_loss: 0.5920\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5578 - val_loss: 0.5732\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5451 - val_loss: 0.5617\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5334 - val_loss: 0.5499\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5222 - val_loss: 0.5388\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5129 - val_loss: 0.5312\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5059 - val_loss: 0.5225\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4987 - val_loss: 0.5167\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4923 - val_loss: 0.5112\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4867 - val_loss: 0.5085\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4812 - val_loss: 0.5008\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4779 - val_loss: 0.4989\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4735 - val_loss: 0.4946\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4701 - val_loss: 0.4909\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4662 - val_loss: 0.4885\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4632 - val_loss: 0.4857\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4604 - val_loss: 0.4872\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4574 - val_loss: 0.4868\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4545 - val_loss: 0.4830\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4518 - val_loss: 0.4764\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4487 - val_loss: 0.4767\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4452 - val_loss: 0.4725\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4436 - val_loss: 0.4719\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4406 - val_loss: 0.4680\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4383 - val_loss: 0.4673\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4361 - val_loss: 0.4683\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4333 - val_loss: 0.4682\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4326 - val_loss: 0.4610\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4304 - val_loss: 0.4599\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4289 - val_loss: 0.4586\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4266 - val_loss: 0.4578\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4255 - val_loss: 0.4578\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4237 - val_loss: 0.4554\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4221 - val_loss: 0.4539\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4212 - val_loss: 0.4522\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4195 - val_loss: 0.4574\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4189 - val_loss: 0.4525\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4172 - val_loss: 0.4499\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4156 - val_loss: 0.4551\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4150 - val_loss: 0.4476\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4134 - val_loss: 0.4462\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4123 - val_loss: 0.4487\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4117 - val_loss: 0.4434\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4104 - val_loss: 0.4440\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4094 - val_loss: 0.4458\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4087 - val_loss: 0.4443\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4078 - val_loss: 0.4415\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4061 - val_loss: 0.4406\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4055 - val_loss: 0.4403\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4043 - val_loss: 0.4412\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4034 - val_loss: 0.4384\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4029 - val_loss: 0.4371\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4016 - val_loss: 0.4395\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4011 - val_loss: 0.4384\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3998 - val_loss: 0.4343\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3990 - val_loss: 0.4341\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3977 - val_loss: 0.4436\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3972 - val_loss: 0.4373\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3960 - val_loss: 0.4366\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3952 - val_loss: 0.4322\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3942 - val_loss: 0.4377\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3939 - val_loss: 0.4330\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3926 - val_loss: 0.4304\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3919 - val_loss: 0.4288\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3916 - val_loss: 0.4280\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3900 - val_loss: 0.4349\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3900 - val_loss: 0.4299\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3885 - val_loss: 0.4260\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3884 - val_loss: 0.4256\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3875 - val_loss: 0.4260\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3864 - val_loss: 0.4273\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3857 - val_loss: 0.4231\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3850 - val_loss: 0.4218\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3846 - val_loss: 0.4237\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3838 - val_loss: 0.4209\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3831 - val_loss: 0.4213\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3816 - val_loss: 0.4208\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3812 - val_loss: 0.4226\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3809 - val_loss: 0.4201\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3803 - val_loss: 0.4194\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3794 - val_loss: 0.4181\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3791 - val_loss: 0.4180\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3781 - val_loss: 0.4153\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3775 - val_loss: 0.4145\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3766 - val_loss: 0.4248\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3761 - val_loss: 0.4155\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3758 - val_loss: 0.4125\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3748 - val_loss: 0.4122\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3744 - val_loss: 0.4137\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3736 - val_loss: 0.4112\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3733 - val_loss: 0.4109\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3727 - val_loss: 0.4120\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3723 - val_loss: 0.4104\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3712 - val_loss: 0.4095\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3879\n",
      "[CV]  learning_rate=0.001609164958586291, n_hidden=2, n_neurons=13, total=  19.3s\n",
      "[CV] learning_rate=0.001609164958586291, n_hidden=2, n_neurons=13 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 2.5743 - val_loss: 1.5780\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 1.1642 - val_loss: 0.9346\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8059 - val_loss: 0.7251\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6639 - val_loss: 0.6557\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6038 - val_loss: 0.6145\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5638 - val_loss: 0.5782\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5315 - val_loss: 0.5499\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5059 - val_loss: 0.5288\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4864 - val_loss: 0.5146\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4724 - val_loss: 0.5028\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4623 - val_loss: 0.4941\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4544 - val_loss: 0.4880\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4494 - val_loss: 0.4839\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4446 - val_loss: 0.4806\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4407 - val_loss: 0.4768\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4379 - val_loss: 0.4742\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4350 - val_loss: 0.4714\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4326 - val_loss: 0.4696\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4298 - val_loss: 0.4686\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4279 - val_loss: 0.4668\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4257 - val_loss: 0.4645\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4237 - val_loss: 0.4623\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4213 - val_loss: 0.4629\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4200 - val_loss: 0.4603\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4185 - val_loss: 0.4589\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4168 - val_loss: 0.4586\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4152 - val_loss: 0.4571\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4138 - val_loss: 0.4564\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4119 - val_loss: 0.4561\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4111 - val_loss: 0.4541\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4094 - val_loss: 0.4544\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4081 - val_loss: 0.4538\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4070 - val_loss: 0.4505\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4057 - val_loss: 0.4487\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4044 - val_loss: 0.4485\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4030 - val_loss: 0.4473\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4020 - val_loss: 0.4452\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4008 - val_loss: 0.4454\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3999 - val_loss: 0.4443\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3989 - val_loss: 0.4427\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3976 - val_loss: 0.4419\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3965 - val_loss: 0.4408\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3955 - val_loss: 0.4394\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3943 - val_loss: 0.4389\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3936 - val_loss: 0.4372\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3931 - val_loss: 0.4381\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3919 - val_loss: 0.4360\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3911 - val_loss: 0.4360\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3901 - val_loss: 0.4350\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3893 - val_loss: 0.4342\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3884 - val_loss: 0.4336\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3878 - val_loss: 0.4322\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3866 - val_loss: 0.4347\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3861 - val_loss: 0.4310\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3851 - val_loss: 0.4301\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3844 - val_loss: 0.4292\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3835 - val_loss: 0.4283\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3827 - val_loss: 0.4281\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3825 - val_loss: 0.4285\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3814 - val_loss: 0.4270\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3809 - val_loss: 0.4258\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3803 - val_loss: 0.4260\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3797 - val_loss: 0.4249\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3787 - val_loss: 0.4236\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3784 - val_loss: 0.4225\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3774 - val_loss: 0.4227\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3766 - val_loss: 0.4230\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3759 - val_loss: 0.4229\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3754 - val_loss: 0.4206\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3748 - val_loss: 0.4209\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3745 - val_loss: 0.4195\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3737 - val_loss: 0.4193\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3731 - val_loss: 0.4183\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3724 - val_loss: 0.4181\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3717 - val_loss: 0.4165\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3711 - val_loss: 0.4180\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3706 - val_loss: 0.4162\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3699 - val_loss: 0.4159\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3694 - val_loss: 0.4148\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3690 - val_loss: 0.4143\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3686 - val_loss: 0.4135\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3681 - val_loss: 0.4134\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3674 - val_loss: 0.4123\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3670 - val_loss: 0.4119\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3664 - val_loss: 0.4121\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3655 - val_loss: 0.4127\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3656 - val_loss: 0.4109\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3647 - val_loss: 0.4127\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3644 - val_loss: 0.4107\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3634 - val_loss: 0.4102\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3636 - val_loss: 0.4082\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3623 - val_loss: 0.4087\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3624 - val_loss: 0.4088\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3618 - val_loss: 0.4080\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3615 - val_loss: 0.4077\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3613 - val_loss: 0.4076\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3600 - val_loss: 0.4087\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3602 - val_loss: 0.4077\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3598 - val_loss: 0.4051\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3590 - val_loss: 0.4059\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3907\n",
      "[CV]  learning_rate=0.001609164958586291, n_hidden=2, n_neurons=13, total=  19.3s\n",
      "[CV] learning_rate=0.001609164958586291, n_hidden=2, n_neurons=13 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 50us/sample - loss: 2.6005 - val_loss: 1.1215\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.0076 - val_loss: 0.8641\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8495 - val_loss: 0.7915\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7932 - val_loss: 0.7591\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7629 - val_loss: 0.7377\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7405 - val_loss: 0.7186\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7205 - val_loss: 0.7020\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7024 - val_loss: 0.6867\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6855 - val_loss: 0.6710\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6698 - val_loss: 0.6567\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6545 - val_loss: 0.6442\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6415 - val_loss: 0.6324\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6282 - val_loss: 0.6209\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6160 - val_loss: 0.6109\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6047 - val_loss: 0.6004\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5940 - val_loss: 0.5913\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5838 - val_loss: 0.5810\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5739 - val_loss: 0.5719\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5645 - val_loss: 0.5626\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5553 - val_loss: 0.5547\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5467 - val_loss: 0.5452\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5378 - val_loss: 0.5375\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5294 - val_loss: 0.5301\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5213 - val_loss: 0.5233\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5139 - val_loss: 0.5163\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5067 - val_loss: 0.5102\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5001 - val_loss: 0.5037\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4942 - val_loss: 0.4991\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4885 - val_loss: 0.4935\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4836 - val_loss: 0.4898\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4783 - val_loss: 0.4858\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4752 - val_loss: 0.4815\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4713 - val_loss: 0.4780\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4678 - val_loss: 0.4768\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4649 - val_loss: 0.4719\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4624 - val_loss: 0.4703\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4596 - val_loss: 0.4681\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4573 - val_loss: 0.4658\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4546 - val_loss: 0.4641\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4527 - val_loss: 0.4627\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4510 - val_loss: 0.4615\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4492 - val_loss: 0.4588\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4476 - val_loss: 0.4582\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4462 - val_loss: 0.4566\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4448 - val_loss: 0.4561\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4432 - val_loss: 0.4553\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4423 - val_loss: 0.4523\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4409 - val_loss: 0.4507\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4398 - val_loss: 0.4510\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4384 - val_loss: 0.4496\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4376 - val_loss: 0.4491\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4362 - val_loss: 0.4471\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4355 - val_loss: 0.4466\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4344 - val_loss: 0.4460\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4335 - val_loss: 0.4454\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4323 - val_loss: 0.4434\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4315 - val_loss: 0.4437\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4307 - val_loss: 0.4421\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4299 - val_loss: 0.4436\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4291 - val_loss: 0.4400\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4285 - val_loss: 0.4395\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4271 - val_loss: 0.4387\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4264 - val_loss: 0.4383\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4253 - val_loss: 0.4369\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4246 - val_loss: 0.4360\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4234 - val_loss: 0.4385\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4229 - val_loss: 0.4350\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4219 - val_loss: 0.4342\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4209 - val_loss: 0.4340\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4200 - val_loss: 0.4331\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4187 - val_loss: 0.4345\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4183 - val_loss: 0.4325\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4176 - val_loss: 0.4308\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4162 - val_loss: 0.4296\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4154 - val_loss: 0.4296\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4143 - val_loss: 0.4303\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4128 - val_loss: 0.4288\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4126 - val_loss: 0.4275\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4114 - val_loss: 0.4264\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4104 - val_loss: 0.4282\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4096 - val_loss: 0.4241\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4084 - val_loss: 0.4259\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4078 - val_loss: 0.4237\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4068 - val_loss: 0.4219\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4059 - val_loss: 0.4215\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4048 - val_loss: 0.4218\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4037 - val_loss: 0.4201\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4030 - val_loss: 0.4204\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4020 - val_loss: 0.4202\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4009 - val_loss: 0.4161\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3998 - val_loss: 0.4189\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3989 - val_loss: 0.4169\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3981 - val_loss: 0.4133\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3964 - val_loss: 0.4137\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3959 - val_loss: 0.4130\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3948 - val_loss: 0.4123\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3940 - val_loss: 0.4097\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3927 - val_loss: 0.4115\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3922 - val_loss: 0.4083\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3907 - val_loss: 0.4086\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3839\n",
      "[CV]  learning_rate=0.001609164958586291, n_hidden=2, n_neurons=13, total=  19.3s\n",
      "[CV] learning_rate=0.004778223340688506, n_hidden=2, n_neurons=79 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 1.0784 - val_loss: 0.6245\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5710 - val_loss: 0.5492\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5105 - val_loss: 0.5069\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4803 - val_loss: 0.4854\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4606 - val_loss: 0.4676\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4473 - val_loss: 0.4583\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4369 - val_loss: 0.4571\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4310 - val_loss: 0.4450\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4239 - val_loss: 0.4425\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4180 - val_loss: 0.4364\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4124 - val_loss: 0.4306\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4076 - val_loss: 0.4349\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4032 - val_loss: 0.4273\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3989 - val_loss: 0.4319\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3956 - val_loss: 0.4177\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3914 - val_loss: 0.4125\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3873 - val_loss: 0.4186\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3831 - val_loss: 0.4139\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3808 - val_loss: 0.4143\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3772 - val_loss: 0.4034\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3746 - val_loss: 0.4069\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3706 - val_loss: 0.4068\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3682 - val_loss: 0.3999\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3642 - val_loss: 0.3975\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3616 - val_loss: 0.3950\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3592 - val_loss: 0.3940\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3573 - val_loss: 0.3913\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3544 - val_loss: 0.3934\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3520 - val_loss: 0.3856\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3494 - val_loss: 0.3857\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3475 - val_loss: 0.3839\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3449 - val_loss: 0.3836\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3422 - val_loss: 0.3841\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3405 - val_loss: 0.3813\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3374 - val_loss: 0.3795\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3369 - val_loss: 0.3821\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3344 - val_loss: 0.3730\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3321 - val_loss: 0.3776\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3304 - val_loss: 0.3717\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3291 - val_loss: 0.3705\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3271 - val_loss: 0.3745\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3250 - val_loss: 0.3701\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3238 - val_loss: 0.3680\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3219 - val_loss: 0.3692\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3207 - val_loss: 0.3653\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3179 - val_loss: 0.3679\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3170 - val_loss: 0.3621\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3151 - val_loss: 0.3617\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3149 - val_loss: 0.3621\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3133 - val_loss: 0.3593\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3114 - val_loss: 0.3670\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3106 - val_loss: 0.3646\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3102 - val_loss: 0.3687\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3094 - val_loss: 0.3598\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3076 - val_loss: 0.3578\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3051 - val_loss: 0.3543\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3048 - val_loss: 0.3630\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3042 - val_loss: 0.3545\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3030 - val_loss: 0.3528\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3021 - val_loss: 0.3474\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3011 - val_loss: 0.3508\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2997 - val_loss: 0.3482\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2987 - val_loss: 0.3443\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2983 - val_loss: 0.3604\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2948 - val_loss: 0.3468\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2967 - val_loss: 0.3506\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2947 - val_loss: 0.3494\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2942 - val_loss: 0.3492\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2940 - val_loss: 0.3548\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2926 - val_loss: 0.3413\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2926 - val_loss: 0.3462\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2906 - val_loss: 0.3625\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2907 - val_loss: 0.3458\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2888 - val_loss: 0.3443\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2897 - val_loss: 0.3423\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2873 - val_loss: 0.3685\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2864 - val_loss: 0.3387\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2872 - val_loss: 0.3482\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2851 - val_loss: 0.3366\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2839 - val_loss: 0.3437\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2849 - val_loss: 0.3376\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2833 - val_loss: 0.3348\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2838 - val_loss: 0.3392\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2829 - val_loss: 0.3365\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2826 - val_loss: 0.3350\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2811 - val_loss: 0.3346\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2809 - val_loss: 0.3347\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2792 - val_loss: 0.3367\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2796 - val_loss: 0.3392\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2795 - val_loss: 0.3410\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2779 - val_loss: 0.3442\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2789 - val_loss: 0.3284\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2782 - val_loss: 0.3347\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2773 - val_loss: 0.3304\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2769 - val_loss: 0.3285\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2756 - val_loss: 0.3358\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2759 - val_loss: 0.3265\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2762 - val_loss: 0.3309\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2752 - val_loss: 0.3300\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2735 - val_loss: 0.3286\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3033\n",
      "[CV]  learning_rate=0.004778223340688506, n_hidden=2, n_neurons=79, total=  20.3s\n",
      "[CV] learning_rate=0.004778223340688506, n_hidden=2, n_neurons=79 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.2411 - val_loss: 0.6808\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5988 - val_loss: 0.5913\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5255 - val_loss: 0.5317\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4830 - val_loss: 0.4994\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4583 - val_loss: 0.4744\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4366 - val_loss: 0.4705\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4306 - val_loss: 0.4546\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4195 - val_loss: 0.4491\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4141 - val_loss: 0.4508\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4324 - val_loss: 0.4370\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4001 - val_loss: 0.4354\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3940 - val_loss: 0.4293\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3910 - val_loss: 0.4289\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3861 - val_loss: 0.4238\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3818 - val_loss: 0.4282\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3809 - val_loss: 0.4190\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3755 - val_loss: 0.4163\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3738 - val_loss: 0.4135\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3693 - val_loss: 0.4097\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3689 - val_loss: 0.4093\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3633 - val_loss: 0.4167\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3803 - val_loss: 0.4152\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4079 - val_loss: 0.4086\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3635 - val_loss: 0.4048\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3585 - val_loss: 0.4086\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3589 - val_loss: 0.4039\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3551 - val_loss: 0.4037\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3524 - val_loss: 0.3957\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3486 - val_loss: 0.3916\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3430 - val_loss: 0.3919\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3411 - val_loss: 0.3917\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3418 - val_loss: 0.3857\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3375 - val_loss: 0.3908\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3340 - val_loss: 0.3836\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3353 - val_loss: 0.3848\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3390 - val_loss: 0.3888\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3448 - val_loss: 0.3876\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3309 - val_loss: 0.3841\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3272 - val_loss: 0.3821\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3274 - val_loss: 0.3743\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3234 - val_loss: 0.3754\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3206 - val_loss: 0.3781\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3189 - val_loss: 0.3755\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3179 - val_loss: 0.3706\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3164 - val_loss: 0.3749\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3163 - val_loss: 0.3697\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3203 - val_loss: 0.3678\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3113 - val_loss: 0.3692\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3109 - val_loss: 0.3727\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3102 - val_loss: 0.3652\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3081 - val_loss: 0.3663\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3063 - val_loss: 0.3650\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3097 - val_loss: 0.3614\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3043 - val_loss: 0.3620\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3065 - val_loss: 0.3660\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3020 - val_loss: 0.3624\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3024 - val_loss: 0.3655\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3010 - val_loss: 0.3588\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3012 - val_loss: 0.3674\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2992 - val_loss: 0.3602\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2990 - val_loss: 0.3568\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2972 - val_loss: 0.3567\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3001 - val_loss: 0.3610\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3007 - val_loss: 0.3601\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2983 - val_loss: 0.3539\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2982 - val_loss: 0.3570\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2925 - val_loss: 0.3546\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2926 - val_loss: 0.3510\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2919 - val_loss: 0.3564\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2922 - val_loss: 0.3547\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2934 - val_loss: 0.3503\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2910 - val_loss: 0.3561\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2955 - val_loss: 0.3530\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2919 - val_loss: 0.3716\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3045 - val_loss: 0.3565\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2986 - val_loss: 0.3544\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2903 - val_loss: 0.3497\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2878 - val_loss: 0.3516\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2859 - val_loss: 0.3476\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2841 - val_loss: 0.3469\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2840 - val_loss: 0.3482\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2839 - val_loss: 0.3475\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2832 - val_loss: 0.3488\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2828 - val_loss: 0.3430\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2818 - val_loss: 0.3429\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2819 - val_loss: 0.3431\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2812 - val_loss: 0.3416\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2798 - val_loss: 0.3398\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2799 - val_loss: 0.3411\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2792 - val_loss: 0.3492\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2789 - val_loss: 0.3406\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2782 - val_loss: 0.3457\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2770 - val_loss: 0.3415\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2779 - val_loss: 0.3471\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2772 - val_loss: 0.3461\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2763 - val_loss: 0.3434\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2776 - val_loss: 0.3407\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2763 - val_loss: 0.3459\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3263\n",
      "[CV]  learning_rate=0.004778223340688506, n_hidden=2, n_neurons=79, total=  19.8s\n",
      "[CV] learning_rate=0.004778223340688506, n_hidden=2, n_neurons=79 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 51us/sample - loss: 1.4923 - val_loss: 0.6973\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.8951 - val_loss: 0.9233\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 1.4301 - val_loss: 0.5471\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5112 - val_loss: 0.4993\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4705 - val_loss: 0.4764\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4484 - val_loss: 0.4623\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4353 - val_loss: 0.4514\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4262 - val_loss: 0.4418\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4169 - val_loss: 0.4370\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4106 - val_loss: 0.4384\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4057 - val_loss: 0.4274\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4007 - val_loss: 0.4219\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3957 - val_loss: 0.4232\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3917 - val_loss: 0.4165\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3875 - val_loss: 0.4111\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3833 - val_loss: 0.4081\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3804 - val_loss: 0.4044\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3768 - val_loss: 0.4070\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3722 - val_loss: 0.3982\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3693 - val_loss: 0.3973\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3665 - val_loss: 0.3946\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3630 - val_loss: 0.3912\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3603 - val_loss: 0.3904\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3573 - val_loss: 0.3877\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3551 - val_loss: 0.3870\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3523 - val_loss: 0.3833\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3503 - val_loss: 0.3823\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3481 - val_loss: 0.3837\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3458 - val_loss: 0.3772\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3442 - val_loss: 0.3789\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3412 - val_loss: 0.3774\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3389 - val_loss: 0.3749\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3367 - val_loss: 0.3739\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3346 - val_loss: 0.3735\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3328 - val_loss: 0.3711\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3308 - val_loss: 0.3707\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3297 - val_loss: 0.3727\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3280 - val_loss: 0.3641\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3263 - val_loss: 0.3706\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3245 - val_loss: 0.3679\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3227 - val_loss: 0.3668\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3218 - val_loss: 0.3602\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3192 - val_loss: 0.3656\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3190 - val_loss: 0.3617\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3174 - val_loss: 0.3601\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3156 - val_loss: 0.3600\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3131 - val_loss: 0.3606\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3131 - val_loss: 0.3569\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3117 - val_loss: 0.3532\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3090 - val_loss: 0.3577\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3081 - val_loss: 0.3508\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3070 - val_loss: 0.3499\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3069 - val_loss: 0.3496\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3054 - val_loss: 0.3577\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3042 - val_loss: 0.3525\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3042 - val_loss: 0.3518\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3031 - val_loss: 0.3492\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3036 - val_loss: 0.3508\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3025 - val_loss: 0.3514\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3070 - val_loss: 0.3530\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3098 - val_loss: 0.3532\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3075 - val_loss: 0.3464\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3004 - val_loss: 0.3439\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2972 - val_loss: 0.3489\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2950 - val_loss: 0.3435\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2947 - val_loss: 0.3438\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2936 - val_loss: 0.3424\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2917 - val_loss: 0.3430\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2917 - val_loss: 0.3422\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2913 - val_loss: 0.3419\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2912 - val_loss: 0.3411\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2901 - val_loss: 0.3372\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2873 - val_loss: 0.3521\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2888 - val_loss: 0.3380\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2855 - val_loss: 0.3494\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2875 - val_loss: 0.3349\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2861 - val_loss: 0.3346\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2859 - val_loss: 0.3542\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2861 - val_loss: 0.3408\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2854 - val_loss: 0.3369\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2845 - val_loss: 0.3346\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2831 - val_loss: 0.3362\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2825 - val_loss: 0.3331\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2823 - val_loss: 0.3344\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2820 - val_loss: 0.3356\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2816 - val_loss: 0.3365\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2806 - val_loss: 0.3343\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2797 - val_loss: 0.3324\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2791 - val_loss: 0.3400\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2798 - val_loss: 0.3326\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2788 - val_loss: 0.3354\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2794 - val_loss: 0.3326\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2775 - val_loss: 0.3374\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2782 - val_loss: 0.3291\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2774 - val_loss: 0.3339\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2779 - val_loss: 0.3298\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2764 - val_loss: 0.3320\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2753 - val_loss: 0.3340\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2764 - val_loss: 0.3353\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2761 - val_loss: 0.3320\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3032\n",
      "[CV]  learning_rate=0.004778223340688506, n_hidden=2, n_neurons=79, total=  20.2s\n",
      "[CV] learning_rate=0.0025475864965582005, n_hidden=0, n_neurons=46 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 59us/sample - loss: 3.3961 - val_loss: 1.3398\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.9472 - val_loss: 0.7873\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.7274 - val_loss: 0.7073\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6752 - val_loss: 0.6685\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6433 - val_loss: 0.6414\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6186 - val_loss: 0.6195\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5990 - val_loss: 0.6014\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5834 - val_loss: 0.5882\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5709 - val_loss: 0.5771\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5610 - val_loss: 0.5683\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5528 - val_loss: 0.5611\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5464 - val_loss: 0.5567\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5412 - val_loss: 0.5529\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5371 - val_loss: 0.5488\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5335 - val_loss: 0.5460\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5309 - val_loss: 0.5444\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5286 - val_loss: 0.5426\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5268 - val_loss: 0.5411\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5257 - val_loss: 0.5405\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5243 - val_loss: 0.5390\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5234 - val_loss: 0.5390\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5228 - val_loss: 0.5388\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5221 - val_loss: 0.5384\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5218 - val_loss: 0.5379\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5213 - val_loss: 0.5368\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5211 - val_loss: 0.5366\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5207 - val_loss: 0.5368\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5202 - val_loss: 0.5371\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5204 - val_loss: 0.5367\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5203 - val_loss: 0.5365\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5196 - val_loss: 0.5391\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5201 - val_loss: 0.5367\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5200 - val_loss: 0.5366\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5195 - val_loss: 0.5370\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5200 - val_loss: 0.5364\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5197 - val_loss: 0.5367\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5195 - val_loss: 0.5371\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5198 - val_loss: 0.5370\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5195 - val_loss: 0.5373\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5197 - val_loss: 0.5364\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5194 - val_loss: 0.5375\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5193 - val_loss: 0.5367\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5194 - val_loss: 0.5367\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5197 - val_loss: 0.5368\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5193 - val_loss: 0.5386\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5195 - val_loss: 0.5367\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5194 - val_loss: 0.5379\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5187 - val_loss: 0.5367\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5197 - val_loss: 0.5366\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5194 - val_loss: 0.5369\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.5152\n",
      "[CV]  learning_rate=0.0025475864965582005, n_hidden=0, n_neurons=46, total=   9.2s\n",
      "[CV] learning_rate=0.0025475864965582005, n_hidden=0, n_neurons=46 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 2.9628 - val_loss: 1.3384\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.0161 - val_loss: 0.8573\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.7846 - val_loss: 0.7631\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.7125 - val_loss: 0.7105\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6669 - val_loss: 0.6758\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6334 - val_loss: 0.6454\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.6072 - val_loss: 0.6238\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5863 - val_loss: 0.6063\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5697 - val_loss: 0.5934\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5569 - val_loss: 0.5808\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5466 - val_loss: 0.5734\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5387 - val_loss: 0.5661\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5315 - val_loss: 0.5594\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5268 - val_loss: 0.5546\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5225 - val_loss: 0.5528\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5193 - val_loss: 0.5494\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5168 - val_loss: 0.5473\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5147 - val_loss: 0.5452\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5129 - val_loss: 0.5438\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5120 - val_loss: 0.5436\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5109 - val_loss: 0.5436\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5096 - val_loss: 0.5415\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5091 - val_loss: 0.5403\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5082 - val_loss: 0.5409\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5080 - val_loss: 0.5399\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5077 - val_loss: 0.5404\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5073 - val_loss: 0.5393\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5070 - val_loss: 0.5396\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5067 - val_loss: 0.5382\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5056 - val_loss: 0.5426\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5076 - val_loss: 0.5400\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5063 - val_loss: 0.5397\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5067 - val_loss: 0.5405\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5064 - val_loss: 0.5387\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5056 - val_loss: 0.5405\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5058 - val_loss: 0.5370\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5059 - val_loss: 0.5387\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5060 - val_loss: 0.5377\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5060 - val_loss: 0.5375\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5058 - val_loss: 0.5386\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5057 - val_loss: 0.5400\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5058 - val_loss: 0.5384\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5057 - val_loss: 0.5392\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5056 - val_loss: 0.5393\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5058 - val_loss: 0.5373\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5055 - val_loss: 0.5384\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.5418\n",
      "[CV]  learning_rate=0.0025475864965582005, n_hidden=0, n_neurons=46, total=   8.4s\n",
      "[CV] learning_rate=0.0025475864965582005, n_hidden=0, n_neurons=46 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 44us/sample - loss: 2.9888 - val_loss: 1.1139\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.7894 - val_loss: 0.6142\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5641 - val_loss: 0.5566\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5336 - val_loss: 0.5465\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5284 - val_loss: 0.5419\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5276 - val_loss: 0.5425\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5272 - val_loss: 0.5424\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5266 - val_loss: 0.5436\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5270 - val_loss: 0.5436\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5262 - val_loss: 0.5399\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5267 - val_loss: 0.5415\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5257 - val_loss: 0.5385\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5260 - val_loss: 0.5388\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5258 - val_loss: 0.5391\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5257 - val_loss: 0.5398\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5254 - val_loss: 0.5398\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5257 - val_loss: 0.5394\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5252 - val_loss: 0.5380\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5254 - val_loss: 0.5395\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5252 - val_loss: 0.5385\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5254 - val_loss: 0.5396\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5251 - val_loss: 0.5387\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5253 - val_loss: 0.5393\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5249 - val_loss: 0.5379\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5252 - val_loss: 0.5387\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5249 - val_loss: 0.5371\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5251 - val_loss: 0.5375\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5250 - val_loss: 0.5383\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5251 - val_loss: 0.5390\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5251 - val_loss: 0.5372\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5246 - val_loss: 0.5391\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5256 - val_loss: 0.5384\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5246 - val_loss: 0.5377\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5251 - val_loss: 0.5375\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5251 - val_loss: 0.5380\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5247 - val_loss: 0.5360\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5249 - val_loss: 0.5366\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5251 - val_loss: 0.5373\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5246 - val_loss: 0.5376\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5250 - val_loss: 0.5371\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5252 - val_loss: 0.5375\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5246 - val_loss: 0.5400\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5253 - val_loss: 0.5378\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 22us/sample - loss: 0.5246 - val_loss: 0.5384\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5253 - val_loss: 0.5363\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5245 - val_loss: 0.5381\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.5022\n",
      "[CV]  learning_rate=0.0025475864965582005, n_hidden=0, n_neurons=46, total=   8.4s\n",
      "[CV] learning_rate=0.0014026850748945893, n_hidden=1, n_neurons=22 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 2.6543 - val_loss: 1.1951\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8885 - val_loss: 0.7845\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7050 - val_loss: 0.6811\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.6438 - val_loss: 0.6361\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6107 - val_loss: 0.6092\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5883 - val_loss: 0.5880\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5713 - val_loss: 0.5710\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5577 - val_loss: 0.5599\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5462 - val_loss: 0.5485\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5367 - val_loss: 0.5389\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5291 - val_loss: 0.5322\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5225 - val_loss: 0.5280\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.520 - 0s 24us/sample - loss: 0.5168 - val_loss: 0.5204\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5121 - val_loss: 0.5165\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5078 - val_loss: 0.5128\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5037 - val_loss: 0.5099\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5000 - val_loss: 0.5069\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4972 - val_loss: 0.5029\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4938 - val_loss: 0.4980\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4915 - val_loss: 0.4971\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4886 - val_loss: 0.4967\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4861 - val_loss: 0.4924\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4838 - val_loss: 0.4924\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4812 - val_loss: 0.4870\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4789 - val_loss: 0.4853\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4765 - val_loss: 0.4882\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4751 - val_loss: 0.4843\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4729 - val_loss: 0.4820\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4710 - val_loss: 0.4804\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4692 - val_loss: 0.4773\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4674 - val_loss: 0.4763\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4659 - val_loss: 0.4764\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4641 - val_loss: 0.4730\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4627 - val_loss: 0.4708\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4607 - val_loss: 0.4733\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4597 - val_loss: 0.4705\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4579 - val_loss: 0.4696\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4564 - val_loss: 0.4670\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4549 - val_loss: 0.4656\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4533 - val_loss: 0.4648\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4521 - val_loss: 0.4627\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4509 - val_loss: 0.4618\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4498 - val_loss: 0.4608\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4485 - val_loss: 0.4595\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4473 - val_loss: 0.4590\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4460 - val_loss: 0.4591\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4449 - val_loss: 0.4584\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4439 - val_loss: 0.4572\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4429 - val_loss: 0.4560\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4419 - val_loss: 0.4556\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4409 - val_loss: 0.4535\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4401 - val_loss: 0.4536\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4391 - val_loss: 0.4530\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4382 - val_loss: 0.4526\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4373 - val_loss: 0.4517\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4364 - val_loss: 0.4507\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4355 - val_loss: 0.4515\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4346 - val_loss: 0.4502\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4337 - val_loss: 0.4488\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4330 - val_loss: 0.4483\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4323 - val_loss: 0.4475\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4313 - val_loss: 0.4477\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4307 - val_loss: 0.4475\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4299 - val_loss: 0.4467\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4291 - val_loss: 0.4458\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4283 - val_loss: 0.4462\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4273 - val_loss: 0.4459\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4269 - val_loss: 0.4439\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4260 - val_loss: 0.4442\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4254 - val_loss: 0.4436\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4248 - val_loss: 0.4430\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4240 - val_loss: 0.4428\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4231 - val_loss: 0.4423\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4226 - val_loss: 0.4428\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4221 - val_loss: 0.4417\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4213 - val_loss: 0.4418\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4207 - val_loss: 0.4405\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4197 - val_loss: 0.4430\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4196 - val_loss: 0.4404\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4187 - val_loss: 0.4394\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4184 - val_loss: 0.4390\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4176 - val_loss: 0.4393\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4171 - val_loss: 0.4381\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4163 - val_loss: 0.4379\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4161 - val_loss: 0.4368\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4154 - val_loss: 0.4370\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4147 - val_loss: 0.4368\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4140 - val_loss: 0.4364\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4136 - val_loss: 0.4354\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4131 - val_loss: 0.4362\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4125 - val_loss: 0.4349\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4121 - val_loss: 0.4348\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4114 - val_loss: 0.4346\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4107 - val_loss: 0.4351\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4104 - val_loss: 0.4342\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4096 - val_loss: 0.4328\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4095 - val_loss: 0.4335\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4087 - val_loss: 0.4336\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4081 - val_loss: 0.4352\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4080 - val_loss: 0.4324\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.4075\n",
      "[CV]  learning_rate=0.0014026850748945893, n_hidden=1, n_neurons=22, total=  18.9s\n",
      "[CV] learning_rate=0.0014026850748945893, n_hidden=1, n_neurons=22 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 1.8866 - val_loss: 1.0227\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8348 - val_loss: 0.7737\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7023 - val_loss: 0.7164\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6573 - val_loss: 0.6846\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6278 - val_loss: 0.6573\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6037 - val_loss: 0.6344\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5834 - val_loss: 0.6151\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5659 - val_loss: 0.5975\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5506 - val_loss: 0.5825\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5370 - val_loss: 0.5689\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5246 - val_loss: 0.5581\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5140 - val_loss: 0.5473\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5044 - val_loss: 0.5363\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4959 - val_loss: 0.5281\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4885 - val_loss: 0.5198\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4819 - val_loss: 0.5124\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4765 - val_loss: 0.5076\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4712 - val_loss: 0.5022\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4663 - val_loss: 0.4971\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4626 - val_loss: 0.4941\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4589 - val_loss: 0.4905\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4556 - val_loss: 0.4874\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4523 - val_loss: 0.4867\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4499 - val_loss: 0.4836\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4472 - val_loss: 0.4812\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4450 - val_loss: 0.4770\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4428 - val_loss: 0.4761\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4410 - val_loss: 0.4747\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4391 - val_loss: 0.4716\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4373 - val_loss: 0.4716\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4357 - val_loss: 0.4695\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4341 - val_loss: 0.4696\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4328 - val_loss: 0.4679\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4314 - val_loss: 0.4648\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4301 - val_loss: 0.4642\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4290 - val_loss: 0.4629\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4277 - val_loss: 0.4616\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4266 - val_loss: 0.4608\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4256 - val_loss: 0.4593\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4246 - val_loss: 0.4585\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4236 - val_loss: 0.4581\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4226 - val_loss: 0.4567\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4216 - val_loss: 0.4560\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4207 - val_loss: 0.4565\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4199 - val_loss: 0.4550\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4188 - val_loss: 0.4559\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4182 - val_loss: 0.4536\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4172 - val_loss: 0.4536\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4162 - val_loss: 0.4518\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4157 - val_loss: 0.4502\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4148 - val_loss: 0.4514\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4140 - val_loss: 0.4505\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4133 - val_loss: 0.4482\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4123 - val_loss: 0.4505\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4118 - val_loss: 0.4482\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4107 - val_loss: 0.4470\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4101 - val_loss: 0.4478\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4093 - val_loss: 0.4458\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4088 - val_loss: 0.4459\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4079 - val_loss: 0.4444\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4073 - val_loss: 0.4460\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4065 - val_loss: 0.4425\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4061 - val_loss: 0.4446\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4051 - val_loss: 0.4451\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4045 - val_loss: 0.4412\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4040 - val_loss: 0.4426\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4033 - val_loss: 0.4406\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4026 - val_loss: 0.4394\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4020 - val_loss: 0.4408\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4014 - val_loss: 0.4389\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4006 - val_loss: 0.4389\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4000 - val_loss: 0.4378\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3995 - val_loss: 0.4387\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3987 - val_loss: 0.4377\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3983 - val_loss: 0.4368\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3976 - val_loss: 0.4366\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3968 - val_loss: 0.4353\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3964 - val_loss: 0.4352\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3957 - val_loss: 0.4359\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3949 - val_loss: 0.4334\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3947 - val_loss: 0.4337\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3940 - val_loss: 0.4336\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3937 - val_loss: 0.4336\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 32us/sample - loss: 0.3931 - val_loss: 0.4326\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3925 - val_loss: 0.4329\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.3919 - val_loss: 0.4309\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3916 - val_loss: 0.4328\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3910 - val_loss: 0.4320\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3903 - val_loss: 0.4310\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3899 - val_loss: 0.4304\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3896 - val_loss: 0.4300\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3890 - val_loss: 0.4298\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3883 - val_loss: 0.4286\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3879 - val_loss: 0.4285\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.3874 - val_loss: 0.4302\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3871 - val_loss: 0.4284\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3863 - val_loss: 0.4306\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3860 - val_loss: 0.4270\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3859 - val_loss: 0.4273\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.3853 - val_loss: 0.4282\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.4172\n",
      "[CV]  learning_rate=0.0014026850748945893, n_hidden=1, n_neurons=22, total=  19.1s\n",
      "[CV] learning_rate=0.0014026850748945893, n_hidden=1, n_neurons=22 ...\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 47us/sample - loss: 2.3340 - val_loss: 1.1668\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.0015 - val_loss: 0.8327\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8134 - val_loss: 0.7579\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7495 - val_loss: 0.7154\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.7105 - val_loss: 0.6841\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6786 - val_loss: 0.6560\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6502 - val_loss: 0.6318\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6249 - val_loss: 0.6105\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6020 - val_loss: 0.5920\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5834 - val_loss: 0.5767\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5672 - val_loss: 0.5638\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5548 - val_loss: 0.5512\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5431 - val_loss: 0.5421\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5336 - val_loss: 0.5336\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5250 - val_loss: 0.5259\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5173 - val_loss: 0.5195\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.5109 - val_loss: 0.5121\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.5042 - val_loss: 0.5067\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4982 - val_loss: 0.5022\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4933 - val_loss: 0.4978\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4885 - val_loss: 0.4931\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4848 - val_loss: 0.4896\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4810 - val_loss: 0.4864\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4775 - val_loss: 0.4841\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4743 - val_loss: 0.4802\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4715 - val_loss: 0.4774\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4687 - val_loss: 0.4754\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4663 - val_loss: 0.4729\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4642 - val_loss: 0.4709\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4618 - val_loss: 0.4705\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4602 - val_loss: 0.4675\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4582 - val_loss: 0.4653\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4565 - val_loss: 0.4638\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4548 - val_loss: 0.4633\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4532 - val_loss: 0.4620\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4514 - val_loss: 0.4614\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4505 - val_loss: 0.4596\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4488 - val_loss: 0.4586\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4475 - val_loss: 0.4589\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4463 - val_loss: 0.4575\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4451 - val_loss: 0.4556\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4440 - val_loss: 0.4546\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4427 - val_loss: 0.4524\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4416 - val_loss: 0.4527\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4406 - val_loss: 0.4521\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4395 - val_loss: 0.4520\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4385 - val_loss: 0.4495\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4374 - val_loss: 0.4491\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4363 - val_loss: 0.4489\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4356 - val_loss: 0.4471\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4346 - val_loss: 0.4465\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4336 - val_loss: 0.4474\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4326 - val_loss: 0.4466\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4319 - val_loss: 0.4448\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4308 - val_loss: 0.4429\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4300 - val_loss: 0.4436\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4294 - val_loss: 0.4431\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4284 - val_loss: 0.4407\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4275 - val_loss: 0.4396\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4269 - val_loss: 0.4401\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4260 - val_loss: 0.4386\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4253 - val_loss: 0.4390\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4247 - val_loss: 0.4393\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4238 - val_loss: 0.4373\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4233 - val_loss: 0.4366\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4225 - val_loss: 0.4370\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4217 - val_loss: 0.4367\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4214 - val_loss: 0.4349\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4205 - val_loss: 0.4349\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4197 - val_loss: 0.4331\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4193 - val_loss: 0.4335\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4186 - val_loss: 0.4320\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4178 - val_loss: 0.4322\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4175 - val_loss: 0.4322\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4168 - val_loss: 0.4318\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4163 - val_loss: 0.4318\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4155 - val_loss: 0.4306\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4148 - val_loss: 0.4302\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4145 - val_loss: 0.4294\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4138 - val_loss: 0.4285\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4132 - val_loss: 0.4284\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4126 - val_loss: 0.4274\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4120 - val_loss: 0.4281\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4114 - val_loss: 0.4287\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4109 - val_loss: 0.4274\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4103 - val_loss: 0.4257\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4098 - val_loss: 0.4255\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4094 - val_loss: 0.4249\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4087 - val_loss: 0.4249\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4081 - val_loss: 0.4253\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4076 - val_loss: 0.4241\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4072 - val_loss: 0.4234\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4066 - val_loss: 0.4230\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4061 - val_loss: 0.4231\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4057 - val_loss: 0.4225\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4051 - val_loss: 0.4215\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4047 - val_loss: 0.4223\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4042 - val_loss: 0.4209\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4036 - val_loss: 0.4204\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4033 - val_loss: 0.4197\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.3942\n",
      "[CV]  learning_rate=0.0014026850748945893, n_hidden=1, n_neurons=22, total=  18.8s\n",
      "[CV] learning_rate=0.0015787288731068127, n_hidden=1, n_neurons=4 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 49us/sample - loss: 2.2958 - val_loss: 1.5557\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 1.2606 - val_loss: 1.0717\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.9735 - val_loss: 0.9167\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8551 - val_loss: 0.8276\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7792 - val_loss: 0.7600\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7204 - val_loss: 0.7067\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6744 - val_loss: 0.6645\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6374 - val_loss: 0.6318\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6077 - val_loss: 0.6057\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5843 - val_loss: 0.5856\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5660 - val_loss: 0.5684\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5504 - val_loss: 0.5551\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5376 - val_loss: 0.5437\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5269 - val_loss: 0.5348\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5182 - val_loss: 0.5270\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5104 - val_loss: 0.5189\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5043 - val_loss: 0.5131\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4988 - val_loss: 0.5076\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4941 - val_loss: 0.5049\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4910 - val_loss: 0.5007\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4879 - val_loss: 0.4981\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4851 - val_loss: 0.4958\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4834 - val_loss: 0.4942\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4815 - val_loss: 0.4926\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4794 - val_loss: 0.4947\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4784 - val_loss: 0.4890\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4770 - val_loss: 0.4888\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4758 - val_loss: 0.4868\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4748 - val_loss: 0.4882\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4738 - val_loss: 0.4861\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4727 - val_loss: 0.4844\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4714 - val_loss: 0.4864\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4709 - val_loss: 0.4868\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4702 - val_loss: 0.4846\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4693 - val_loss: 0.4837\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4685 - val_loss: 0.4824\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4679 - val_loss: 0.4837\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4673 - val_loss: 0.4805\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4667 - val_loss: 0.4814\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4661 - val_loss: 0.4817\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4659 - val_loss: 0.4805\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4650 - val_loss: 0.4793\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4646 - val_loss: 0.4786\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4637 - val_loss: 0.4772\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4630 - val_loss: 0.4791\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4628 - val_loss: 0.4797\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4621 - val_loss: 0.4786\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4618 - val_loss: 0.4767\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4609 - val_loss: 0.4781\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4605 - val_loss: 0.4756\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4602 - val_loss: 0.4761\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4597 - val_loss: 0.4756\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4590 - val_loss: 0.4767\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4588 - val_loss: 0.4749\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4582 - val_loss: 0.4735\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4575 - val_loss: 0.4734\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4571 - val_loss: 0.4734\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4568 - val_loss: 0.4727\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4563 - val_loss: 0.4745\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4558 - val_loss: 0.4727\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4553 - val_loss: 0.4731\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4546 - val_loss: 0.4712\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4541 - val_loss: 0.4714\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4541 - val_loss: 0.4706\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4533 - val_loss: 0.4690\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4532 - val_loss: 0.4701\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4521 - val_loss: 0.4717\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4522 - val_loss: 0.4718\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4518 - val_loss: 0.4686\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4511 - val_loss: 0.4686\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4510 - val_loss: 0.4688\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4503 - val_loss: 0.4692\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4496 - val_loss: 0.4694\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4496 - val_loss: 0.4681\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4492 - val_loss: 0.4677\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4486 - val_loss: 0.4650\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4484 - val_loss: 0.4645\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4479 - val_loss: 0.4657\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4477 - val_loss: 0.4657\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4472 - val_loss: 0.4656\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4467 - val_loss: 0.4663\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4462 - val_loss: 0.4640\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4460 - val_loss: 0.4644\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4456 - val_loss: 0.4643\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4451 - val_loss: 0.4621\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4449 - val_loss: 0.4621\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4442 - val_loss: 0.4622\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4437 - val_loss: 0.4619\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4437 - val_loss: 0.4620\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4431 - val_loss: 0.4659\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4428 - val_loss: 0.4629\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4426 - val_loss: 0.4635\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - ETA: 0s - loss: 0.444 - 0s 23us/sample - loss: 0.4421 - val_loss: 0.4614\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4416 - val_loss: 0.4617\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4413 - val_loss: 0.4595\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4411 - val_loss: 0.4620\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4408 - val_loss: 0.4606\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4403 - val_loss: 0.4594\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4399 - val_loss: 0.4606\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4395 - val_loss: 0.4591\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.4305\n",
      "[CV]  learning_rate=0.0015787288731068127, n_hidden=1, n_neurons=4, total=  18.8s\n",
      "[CV] learning_rate=0.0015787288731068127, n_hidden=1, n_neurons=4 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 63us/sample - loss: 2.9120 - val_loss: 1.4319\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.1991 - val_loss: 0.9736\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.8739 - val_loss: 0.8075\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.7517 - val_loss: 0.7303\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6899 - val_loss: 0.6938\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6571 - val_loss: 0.6723\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6358 - val_loss: 0.6575\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6203 - val_loss: 0.6452\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6075 - val_loss: 0.6330\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5961 - val_loss: 0.6230\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5857 - val_loss: 0.6124\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5752 - val_loss: 0.6030\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5655 - val_loss: 0.5940\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5566 - val_loss: 0.5853\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5482 - val_loss: 0.5774\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5404 - val_loss: 0.5698\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5331 - val_loss: 0.5625\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5271 - val_loss: 0.5558\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5211 - val_loss: 0.5501\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5150 - val_loss: 0.5444\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5098 - val_loss: 0.5394\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5048 - val_loss: 0.5353\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5005 - val_loss: 0.5309\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4969 - val_loss: 0.5280\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4937 - val_loss: 0.5251\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4908 - val_loss: 0.5229\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4881 - val_loss: 0.5205\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4858 - val_loss: 0.5193\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4839 - val_loss: 0.5168\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4819 - val_loss: 0.5151\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4805 - val_loss: 0.5134\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4788 - val_loss: 0.5124\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4775 - val_loss: 0.5112\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4763 - val_loss: 0.5098\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4751 - val_loss: 0.5088\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4739 - val_loss: 0.5091\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4727 - val_loss: 0.5071\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4719 - val_loss: 0.5062\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4709 - val_loss: 0.5056\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4702 - val_loss: 0.5045\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4692 - val_loss: 0.5035\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4684 - val_loss: 0.5036\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4675 - val_loss: 0.5024\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4670 - val_loss: 0.5020\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4662 - val_loss: 0.5017\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4654 - val_loss: 0.5002\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4646 - val_loss: 0.5013\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4641 - val_loss: 0.4989\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4632 - val_loss: 0.4986\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4627 - val_loss: 0.4983\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4619 - val_loss: 0.4968\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4614 - val_loss: 0.4970\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4609 - val_loss: 0.4961\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4602 - val_loss: 0.4954\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4596 - val_loss: 0.4950\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4590 - val_loss: 0.4944\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4585 - val_loss: 0.4948\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4577 - val_loss: 0.4950\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4575 - val_loss: 0.4934\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4569 - val_loss: 0.4935\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4565 - val_loss: 0.4929\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4559 - val_loss: 0.4927\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4552 - val_loss: 0.4927\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4548 - val_loss: 0.4910\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4544 - val_loss: 0.4909\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4540 - val_loss: 0.4904\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4534 - val_loss: 0.4898\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4529 - val_loss: 0.4899\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4523 - val_loss: 0.4900\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4518 - val_loss: 0.4901\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4516 - val_loss: 0.4883\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4511 - val_loss: 0.4885\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4506 - val_loss: 0.4882\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4500 - val_loss: 0.4890\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4495 - val_loss: 0.4878\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4492 - val_loss: 0.4867\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4489 - val_loss: 0.4866\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4483 - val_loss: 0.4868\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4480 - val_loss: 0.4867\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4474 - val_loss: 0.4861\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4471 - val_loss: 0.4863\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4464 - val_loss: 0.4856\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4465 - val_loss: 0.4852\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4459 - val_loss: 0.4851\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4454 - val_loss: 0.4841\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4448 - val_loss: 0.4853\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4447 - val_loss: 0.4843\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4440 - val_loss: 0.4834\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4440 - val_loss: 0.4831\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4433 - val_loss: 0.4826\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4428 - val_loss: 0.4832\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4426 - val_loss: 0.4827\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4421 - val_loss: 0.4813\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.4417 - val_loss: 0.4816\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4415 - val_loss: 0.4806\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4410 - val_loss: 0.4806\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4406 - val_loss: 0.4798\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4403 - val_loss: 0.4801\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4397 - val_loss: 0.4806\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4395 - val_loss: 0.4787\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.4821\n",
      "[CV]  learning_rate=0.0015787288731068127, n_hidden=1, n_neurons=4, total=  18.8s\n",
      "[CV] learning_rate=0.0015787288731068127, n_hidden=1, n_neurons=4 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 48us/sample - loss: 4.9815 - val_loss: 2.2829\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.7586 - val_loss: 1.5171\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 1.4007 - val_loss: 1.3638\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.3072 - val_loss: 1.2902\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 1.2338 - val_loss: 1.1979\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 1.1330 - val_loss: 1.0696\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.9949 - val_loss: 0.9165\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.8462 - val_loss: 0.7839\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.7327 - val_loss: 0.7064\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.6735 - val_loss: 0.6737\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6469 - val_loss: 0.6577\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6321 - val_loss: 0.6455\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6204 - val_loss: 0.6348\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.6098 - val_loss: 0.6247\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5998 - val_loss: 0.6158\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5902 - val_loss: 0.6065\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5813 - val_loss: 0.5983\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5729 - val_loss: 0.5907\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5649 - val_loss: 0.5830\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5573 - val_loss: 0.5756\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5505 - val_loss: 0.5694\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5440 - val_loss: 0.5635\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5381 - val_loss: 0.5577\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5327 - val_loss: 0.5525\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5275 - val_loss: 0.5469\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5228 - val_loss: 0.5426\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5184 - val_loss: 0.5389\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5143 - val_loss: 0.5347\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5106 - val_loss: 0.5314\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5070 - val_loss: 0.5276\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.5035 - val_loss: 0.5244\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.5006 - val_loss: 0.5201\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4976 - val_loss: 0.5176\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4949 - val_loss: 0.5140\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4924 - val_loss: 0.5112\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4899 - val_loss: 0.5069\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4875 - val_loss: 0.5037\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4856 - val_loss: 0.5011\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4837 - val_loss: 0.4988\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4820 - val_loss: 0.4964\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4805 - val_loss: 0.4951\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4791 - val_loss: 0.4930\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4777 - val_loss: 0.4920\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4764 - val_loss: 0.4909\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4753 - val_loss: 0.4900\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4742 - val_loss: 0.4886\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4733 - val_loss: 0.4877\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4722 - val_loss: 0.4862\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4715 - val_loss: 0.4848\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4707 - val_loss: 0.4843\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.4699 - val_loss: 0.4835\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4690 - val_loss: 0.4820\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4682 - val_loss: 0.4817\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4675 - val_loss: 0.4806\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4667 - val_loss: 0.4803\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4660 - val_loss: 0.4802\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4652 - val_loss: 0.4790\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4645 - val_loss: 0.4793\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4638 - val_loss: 0.4782\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4631 - val_loss: 0.4773\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4623 - val_loss: 0.4775\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4618 - val_loss: 0.4768\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4611 - val_loss: 0.4763\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4603 - val_loss: 0.4757\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4596 - val_loss: 0.4746\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4590 - val_loss: 0.4744\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4584 - val_loss: 0.4734\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4578 - val_loss: 0.4733\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4571 - val_loss: 0.4726\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4563 - val_loss: 0.4729\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4560 - val_loss: 0.4717\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4551 - val_loss: 0.4718\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4546 - val_loss: 0.4714\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4540 - val_loss: 0.4709\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4534 - val_loss: 0.4707\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4528 - val_loss: 0.4689\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4524 - val_loss: 0.4692\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4516 - val_loss: 0.4682\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4511 - val_loss: 0.4680\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4506 - val_loss: 0.4681\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4502 - val_loss: 0.4675\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4497 - val_loss: 0.4672\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4491 - val_loss: 0.4663\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4486 - val_loss: 0.4656\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4481 - val_loss: 0.4664\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 23us/sample - loss: 0.4476 - val_loss: 0.4658\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4472 - val_loss: 0.4648\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4466 - val_loss: 0.4646\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4461 - val_loss: 0.4635\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4458 - val_loss: 0.4642\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4453 - val_loss: 0.4629\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4449 - val_loss: 0.4631\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4443 - val_loss: 0.4633\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4439 - val_loss: 0.4623\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4435 - val_loss: 0.4615\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4430 - val_loss: 0.4618\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4426 - val_loss: 0.4610\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4421 - val_loss: 0.4605\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4416 - val_loss: 0.4602\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 24us/sample - loss: 0.4412 - val_loss: 0.4601\n",
      "3870/3870 [==============================] - 0s 10us/sample - loss: 0.4259\n",
      "[CV]  learning_rate=0.0015787288731068127, n_hidden=1, n_neurons=4, total=  18.8s\n",
      "[CV] learning_rate=0.009307690450944048, n_hidden=2, n_neurons=98 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 52us/sample - loss: 0.8181 - val_loss: 0.5990\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.5404 - val_loss: 0.4953\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.4727 - val_loss: 0.4755\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4438 - val_loss: 0.4789\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4285 - val_loss: 0.4466\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4153 - val_loss: 0.4374\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4103 - val_loss: 0.4302\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4010 - val_loss: 0.4281\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3919 - val_loss: 0.4223\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3862 - val_loss: 0.4200\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3784 - val_loss: 0.4072\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3725 - val_loss: 0.3990\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3690 - val_loss: 0.4083\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3642 - val_loss: 0.3985\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3589 - val_loss: 0.3976\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3550 - val_loss: 0.3922\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3503 - val_loss: 0.3847\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3481 - val_loss: 0.3884\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3436 - val_loss: 0.4007\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3393 - val_loss: 0.3788\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3351 - val_loss: 0.3806\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3337 - val_loss: 0.3733\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3297 - val_loss: 0.3735\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3277 - val_loss: 0.3728\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3269 - val_loss: 0.3623\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3232 - val_loss: 0.3706\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3217 - val_loss: 0.3626\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3187 - val_loss: 0.3993\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3186 - val_loss: 0.3645\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3150 - val_loss: 0.3748\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3116 - val_loss: 0.4082\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3122 - val_loss: 0.3908\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3108 - val_loss: 0.3584\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3072 - val_loss: 0.3725\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3073 - val_loss: 0.3480\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3033 - val_loss: 0.3574\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2999 - val_loss: 0.3628\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2998 - val_loss: 0.3433\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2985 - val_loss: 0.3513\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2964 - val_loss: 0.3625\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2945 - val_loss: 0.3616\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2954 - val_loss: 0.3403\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2948 - val_loss: 0.3400\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2906 - val_loss: 0.3476\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2890 - val_loss: 0.3694\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2903 - val_loss: 0.3512\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2878 - val_loss: 0.3652\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2869 - val_loss: 0.3378\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2855 - val_loss: 0.3452\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2833 - val_loss: 0.3353\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2843 - val_loss: 0.3438\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2821 - val_loss: 0.3398\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2818 - val_loss: 0.3252\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2798 - val_loss: 0.3335\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2786 - val_loss: 0.3284\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2795 - val_loss: 0.3373\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2794 - val_loss: 0.3362\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2834 - val_loss: 0.3299\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2733 - val_loss: 0.3814\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2738 - val_loss: 0.3427\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2816 - val_loss: 0.3319\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2732 - val_loss: 0.3255\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2713 - val_loss: 0.3379\n",
      "3870/3870 [==============================] - 0s 12us/sample - loss: 0.3145\n",
      "[CV]  learning_rate=0.009307690450944048, n_hidden=2, n_neurons=98, total=  13.3s\n",
      "[CV] learning_rate=0.009307690450944048, n_hidden=2, n_neurons=98 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 56us/sample - loss: 1.3344 - val_loss: 0.6035\n",
      "Epoch 2/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.5289 - val_loss: 0.4933\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4445 - val_loss: 0.4556\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4193 - val_loss: 0.4391\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4040 - val_loss: 0.4259\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3933 - val_loss: 0.4204\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3844 - val_loss: 0.4139\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3776 - val_loss: 0.4098\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3702 - val_loss: 0.4063\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3663 - val_loss: 0.3967\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3604 - val_loss: 0.4094\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3578 - val_loss: 0.3908\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.3505 - val_loss: 0.3919\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3471 - val_loss: 0.3854\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3446 - val_loss: 0.3895\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3388 - val_loss: 0.3842\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3340 - val_loss: 0.3731\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3320 - val_loss: 0.3733\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3287 - val_loss: 0.3705\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3251 - val_loss: 0.3691\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3243 - val_loss: 0.3683\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3195 - val_loss: 0.3752\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3180 - val_loss: 0.3663\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3149 - val_loss: 0.3670\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3129 - val_loss: 0.3650\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.3099 - val_loss: 0.3645\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3081 - val_loss: 0.3570\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3061 - val_loss: 0.3543\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3054 - val_loss: 0.3531\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.3025 - val_loss: 0.3529\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3011 - val_loss: 0.3506\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3005 - val_loss: 0.3543\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2996 - val_loss: 0.3472\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2969 - val_loss: 0.3514\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2967 - val_loss: 0.3582\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2945 - val_loss: 0.3472\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2943 - val_loss: 0.3766\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2945 - val_loss: 0.3430\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2923 - val_loss: 0.3413\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2929 - val_loss: 0.3464\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2892 - val_loss: 0.3433\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2886 - val_loss: 0.3572\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2889 - val_loss: 0.3397\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2868 - val_loss: 0.3336\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2863 - val_loss: 0.3379\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2865 - val_loss: 0.3402\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2851 - val_loss: 0.3475\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2842 - val_loss: 0.3588\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2830 - val_loss: 0.3324\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2829 - val_loss: 0.3278\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2825 - val_loss: 0.3328\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2810 - val_loss: 0.3315\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2838 - val_loss: 0.3371\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2781 - val_loss: 0.3362\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2786 - val_loss: 0.3343\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2790 - val_loss: 0.3285\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2778 - val_loss: 0.3505\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2776 - val_loss: 0.3273\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2764 - val_loss: 0.3375\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2777 - val_loss: 0.3269\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2748 - val_loss: 0.3245\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2735 - val_loss: 0.3424\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2740 - val_loss: 0.3253\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2729 - val_loss: 0.3539\n",
      "Epoch 65/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2731 - val_loss: 0.3263\n",
      "Epoch 66/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2734 - val_loss: 0.3257\n",
      "Epoch 67/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2711 - val_loss: 0.3254\n",
      "Epoch 68/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2702 - val_loss: 0.3240\n",
      "Epoch 69/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2689 - val_loss: 0.3308\n",
      "Epoch 70/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2702 - val_loss: 0.3293\n",
      "Epoch 71/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2717 - val_loss: 0.3308\n",
      "Epoch 72/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2688 - val_loss: 0.3348\n",
      "Epoch 73/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2708 - val_loss: 0.3228\n",
      "Epoch 74/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2671 - val_loss: 0.3363\n",
      "Epoch 75/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2688 - val_loss: 0.3296\n",
      "Epoch 76/100\n",
      "7740/7740 [==============================] - 0s 29us/sample - loss: 0.2673 - val_loss: 0.3313\n",
      "Epoch 77/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2672 - val_loss: 0.3220\n",
      "Epoch 78/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2667 - val_loss: 0.3322\n",
      "Epoch 79/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2663 - val_loss: 0.3191\n",
      "Epoch 80/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2669 - val_loss: 0.3312\n",
      "Epoch 81/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2647 - val_loss: 0.3222\n",
      "Epoch 82/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2653 - val_loss: 0.3235\n",
      "Epoch 83/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2632 - val_loss: 0.3299\n",
      "Epoch 84/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2642 - val_loss: 0.3201\n",
      "Epoch 85/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2672 - val_loss: 0.3376\n",
      "Epoch 86/100\n",
      "7740/7740 [==============================] - 0s 30us/sample - loss: 0.2650 - val_loss: 0.3185\n",
      "Epoch 87/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2631 - val_loss: 0.3228\n",
      "Epoch 88/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2650 - val_loss: 0.3430\n",
      "Epoch 89/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2622 - val_loss: 0.3392\n",
      "Epoch 90/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2610 - val_loss: 0.3306\n",
      "Epoch 91/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2643 - val_loss: 0.3239\n",
      "Epoch 92/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2634 - val_loss: 0.3259\n",
      "Epoch 93/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2622 - val_loss: 0.3296\n",
      "Epoch 94/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2614 - val_loss: 0.3418\n",
      "Epoch 95/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2606 - val_loss: 0.3675\n",
      "Epoch 96/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2606 - val_loss: 0.3183\n",
      "Epoch 97/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2579 - val_loss: 0.3266\n",
      "Epoch 98/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2604 - val_loss: 0.3213\n",
      "Epoch 99/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2584 - val_loss: 0.3202\n",
      "Epoch 100/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2597 - val_loss: 0.3256\n",
      "3870/3870 [==============================] - 0s 12us/sample - loss: 0.3071\n",
      "[CV]  learning_rate=0.009307690450944048, n_hidden=2, n_neurons=98, total=  21.3s\n",
      "[CV] learning_rate=0.009307690450944048, n_hidden=2, n_neurons=98 ....\n",
      "Train on 7740 samples, validate on 3870 samples\n",
      "Epoch 1/100\n",
      "7740/7740 [==============================] - 0s 53us/sample - loss: 0.8518 - val_loss: 0.9125\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7740/7740 [==============================] - 0s 26us/sample - loss: 1.5768 - val_loss: 0.8294\n",
      "Epoch 3/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.9227 - val_loss: 0.4746\n",
      "Epoch 4/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.4443 - val_loss: 0.4508\n",
      "Epoch 5/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.4233 - val_loss: 0.4172\n",
      "Epoch 6/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3937 - val_loss: 0.4055\n",
      "Epoch 7/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3794 - val_loss: 0.4171\n",
      "Epoch 8/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3690 - val_loss: 0.3926\n",
      "Epoch 9/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3623 - val_loss: 0.3961\n",
      "Epoch 10/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3538 - val_loss: 0.3842\n",
      "Epoch 11/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.3477 - val_loss: 0.3789\n",
      "Epoch 12/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3409 - val_loss: 0.3731\n",
      "Epoch 13/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3377 - val_loss: 0.3660\n",
      "Epoch 14/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3321 - val_loss: 0.3627\n",
      "Epoch 15/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3277 - val_loss: 0.3675\n",
      "Epoch 16/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3234 - val_loss: 0.3563\n",
      "Epoch 17/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3191 - val_loss: 0.3571\n",
      "Epoch 18/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3167 - val_loss: 0.3552\n",
      "Epoch 19/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3125 - val_loss: 0.3716\n",
      "Epoch 20/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3102 - val_loss: 0.3470\n",
      "Epoch 21/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3055 - val_loss: 0.3499\n",
      "Epoch 22/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3005 - val_loss: 0.3459\n",
      "Epoch 23/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.3004 - val_loss: 0.3427\n",
      "Epoch 24/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2986 - val_loss: 0.3532\n",
      "Epoch 25/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2945 - val_loss: 0.3523\n",
      "Epoch 26/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2925 - val_loss: 0.3325\n",
      "Epoch 27/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2916 - val_loss: 0.3303\n",
      "Epoch 28/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2907 - val_loss: 0.3338\n",
      "Epoch 29/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2867 - val_loss: 0.3266\n",
      "Epoch 30/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2877 - val_loss: 0.3338\n",
      "Epoch 31/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2847 - val_loss: 0.3324\n",
      "Epoch 32/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2816 - val_loss: 0.3221\n",
      "Epoch 33/100\n",
      "7740/7740 [==============================] - 0s 28us/sample - loss: 0.2824 - val_loss: 0.3204\n",
      "Epoch 34/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2801 - val_loss: 0.3261\n",
      "Epoch 35/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2785 - val_loss: 0.3181\n",
      "Epoch 36/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2767 - val_loss: 0.3201\n",
      "Epoch 37/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2775 - val_loss: 0.3251\n",
      "Epoch 38/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2741 - val_loss: 0.3259\n",
      "Epoch 39/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2746 - val_loss: 0.3228\n",
      "Epoch 40/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2719 - val_loss: 0.3224\n",
      "Epoch 41/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2726 - val_loss: 0.3218\n",
      "Epoch 42/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2708 - val_loss: 0.3231\n",
      "Epoch 43/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2696 - val_loss: 0.3116\n",
      "Epoch 44/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2685 - val_loss: 0.3175\n",
      "Epoch 45/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2671 - val_loss: 0.3481\n",
      "Epoch 46/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2670 - val_loss: 0.3106\n",
      "Epoch 47/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2673 - val_loss: 0.3079\n",
      "Epoch 48/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2667 - val_loss: 0.3190\n",
      "Epoch 49/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2657 - val_loss: 0.3233\n",
      "Epoch 50/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2650 - val_loss: 0.3181\n",
      "Epoch 51/100\n",
      "7740/7740 [==============================] - 0s 25us/sample - loss: 0.2641 - val_loss: 0.3092\n",
      "Epoch 52/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2628 - val_loss: 0.3155\n",
      "Epoch 53/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2627 - val_loss: 0.3317\n",
      "Epoch 54/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2607 - val_loss: 0.3027\n",
      "Epoch 55/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2614 - val_loss: 0.3252\n",
      "Epoch 56/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2592 - val_loss: 0.3185\n",
      "Epoch 57/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2582 - val_loss: 0.3032\n",
      "Epoch 58/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2583 - val_loss: 0.3070\n",
      "Epoch 59/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2578 - val_loss: 0.3064\n",
      "Epoch 60/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2567 - val_loss: 0.3037\n",
      "Epoch 61/100\n",
      "7740/7740 [==============================] - 0s 27us/sample - loss: 0.2580 - val_loss: 0.3201\n",
      "Epoch 62/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2560 - val_loss: 0.3044\n",
      "Epoch 63/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2561 - val_loss: 0.3055\n",
      "Epoch 64/100\n",
      "7740/7740 [==============================] - 0s 26us/sample - loss: 0.2545 - val_loss: 0.3057\n",
      "3870/3870 [==============================] - 0s 11us/sample - loss: 0.2824\n",
      "[CV]  learning_rate=0.009307690450944048, n_hidden=2, n_neurons=98, total=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed:  9.0min finished\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002483BA14F08>, as the constructor either does not set or modifies parameter learning_rate",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-3d7402542265>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrnd_search_cv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\Administrator\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;31m# of the params are estimators as well.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             self.best_estimator_ = clone(clone(base_estimator).set_params(\n\u001b[1;32m--> 762\u001b[1;33m                 **self.best_params_))\n\u001b[0m\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Administrator\\anaconda3\\envs\\tf2\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     96\u001b[0m             raise RuntimeError('Cannot clone object %s, as the constructor '\n\u001b[0;32m     97\u001b[0m                                \u001b[1;34m'either does not set or modifies parameter %s'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m                                (estimator, name))\n\u001b[0m\u001b[0;32m     99\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Cannot clone object <tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x000002483BA14F08>, as the constructor either does not set or modifies parameter learning_rate"
     ]
    }
   ],
   "source": [
    "rnd_search_cv.fit(x_train, y_train, epochs=100, validation_data=(x_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.009307690450944048, 'n_hidden': 2, 'n_neurons': 98}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.30135538698680225"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.009307690450944048, 'n_hidden': 2, 'n_neurons': 98}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = rnd_search_cv.best_params_\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepModel(keras.models.Model):\n",
    "    def __init__(self, units, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.concatenate([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "       \n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DeepModel(30, 'relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11610 samples, validate on 3870 samples\n",
      "Epoch 1/10\n",
      "11610/11610 [==============================] - 1s 58us/sample - loss: 2.0629 - output_1_loss: 0.8444 - output_2_loss: 1.2180 - val_loss: 1.3857 - val_output_1_loss: 0.5837 - val_output_2_loss: 0.8017\n",
      "Epoch 2/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 1.1821 - output_1_loss: 0.4901 - output_2_loss: 0.6917 - val_loss: 1.1770 - val_output_1_loss: 0.5232 - val_output_2_loss: 0.6536\n",
      "Epoch 3/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 1.1315 - output_1_loss: 0.4980 - output_2_loss: 0.6334 - val_loss: 1.2724 - val_output_1_loss: 0.5572 - val_output_2_loss: 0.7148\n",
      "Epoch 4/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 1.3745 - output_1_loss: 0.6082 - output_2_loss: 0.7659 - val_loss: 1.0756 - val_output_1_loss: 0.4738 - val_output_2_loss: 0.6015\n",
      "Epoch 5/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 1.0126 - output_1_loss: 0.4446 - output_2_loss: 0.5680 - val_loss: 1.0040 - val_output_1_loss: 0.4452 - val_output_2_loss: 0.5586\n",
      "Epoch 6/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.9371 - output_1_loss: 0.4144 - output_2_loss: 0.5226 - val_loss: 0.9644 - val_output_1_loss: 0.4276 - val_output_2_loss: 0.5366\n",
      "Epoch 7/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.9070 - output_1_loss: 0.4074 - output_2_loss: 0.4993 - val_loss: 0.9692 - val_output_1_loss: 0.4429 - val_output_2_loss: 0.5261\n",
      "Epoch 8/10\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.8805 - output_1_loss: 0.3989 - output_2_loss: 0.4813 - val_loss: 1.2276 - val_output_1_loss: 0.6166 - val_output_2_loss: 0.6106\n",
      "Epoch 9/10\n",
      "11610/11610 [==============================] - 0s 26us/sample - loss: 0.8366 - output_1_loss: 0.3808 - output_2_loss: 0.4561 - val_loss: 0.8646 - val_output_1_loss: 0.3953 - val_output_2_loss: 0.4691\n",
      "Epoch 10/10\n",
      "11610/11610 [==============================] - 0s 25us/sample - loss: 0.8119 - output_1_loss: 0.3686 - output_2_loss: 0.4433 - val_loss: 0.8456 - val_output_1_loss: 0.4004 - val_output_2_loss: 0.4449\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='mse', optimizer='sgd')\n",
    "history = model2.fit((x_train_A, x_train_B), (y_train, y_train), epochs=10, validation_data=((x_valid_A, x_valid_B), (y_valid, y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 32,\n",
       " 'epochs': 10,\n",
       " 'steps': 363,\n",
       " 'samples': 11610,\n",
       " 'verbose': 0,\n",
       " 'do_validation': True,\n",
       " 'metrics': ['loss',\n",
       "  'output_1_loss',\n",
       "  'output_2_loss',\n",
       "  'val_loss',\n",
       "  'val_output_1_loss',\n",
       "  'val_output_2_loss']}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.63045937],\n",
       "       [1.5561782 ],\n",
       "       [3.3628025 ],\n",
       "       ...,\n",
       "       [1.7303405 ],\n",
       "       [2.2299876 ],\n",
       "       [3.741187  ]], dtype=float32)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
