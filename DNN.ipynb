{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_full, y_train_full),(x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0\n",
    "x_valid, x_train = x_train_full[:5000], x_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 활성화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# SELU 활성화\\nmodel = keras.models.Sequential([\\n    keras.layers.Dense(10, activation='selu', kernel_initializer='lecun_normal'),\\n])\\n\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "## 활성화 함수\n",
    "# HE init\n",
    "keras.layers.Dense(10, activation='relu', kernel_initializer='he_noraml')\n",
    "\n",
    "# fan out HE init\n",
    "he_avg_init = keras.initializers.VarianceScaling(scale=2., mode='fan_avg', distribution='uniform')\n",
    "keras.layers.Dense(10, activation='sigmoid', kernel_initializer=he_avg_init)\n",
    "'''\n",
    "'''\n",
    "# LeakyReLU 활성화\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(alpha=0.2),\n",
    "])\n",
    "'''\n",
    "'''\n",
    "# SELU 활성화\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(10, activation='selu', kernel_initializer='lecun_normal'),\n",
    "])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelcompile(model):\n",
    "        model.compile(loss = keras.losses.sparse_categorical_crossentropy, \n",
    "                  optimizer = keras.optimizers.SGD(1e-3),\n",
    "                 metrics=[keras.metrics.sparse_categorical_accuracy])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeakyReLU 활성화\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.LeakyReLU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcompile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 2s 44us/sample - loss: 1.2661 - sparse_categorical_accuracy: 0.6229 - val_loss: 0.8618 - val_sparse_categorical_accuracy: 0.7302\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 2s 38us/sample - loss: 0.7816 - sparse_categorical_accuracy: 0.7429 - val_loss: 0.7038 - val_sparse_categorical_accuracy: 0.7764\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.6748 - sparse_categorical_accuracy: 0.7756 - val_loss: 0.6310 - val_sparse_categorical_accuracy: 0.7916\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.6187 - sparse_categorical_accuracy: 0.7940 - val_loss: 0.5859 - val_sparse_categorical_accuracy: 0.8130\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 2s 42us/sample - loss: 0.5823 - sparse_categorical_accuracy: 0.8051 - val_loss: 0.5577 - val_sparse_categorical_accuracy: 0.8216\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 2s 43us/sample - loss: 0.5563 - sparse_categorical_accuracy: 0.8136 - val_loss: 0.5378 - val_sparse_categorical_accuracy: 0.8246\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 2s 41us/sample - loss: 0.5365 - sparse_categorical_accuracy: 0.8200 - val_loss: 0.5191 - val_sparse_categorical_accuracy: 0.8318\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.5204 - sparse_categorical_accuracy: 0.8241 - val_loss: 0.5069 - val_sparse_categorical_accuracy: 0.8368\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 2s 39us/sample - loss: 0.5077 - sparse_categorical_accuracy: 0.8275 - val_loss: 0.4924 - val_sparse_categorical_accuracy: 0.8384\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 2s 40us/sample - loss: 0.4965 - sparse_categorical_accuracy: 0.8307 - val_loss: 0.4852 - val_sparse_categorical_accuracy: 0.8388\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs=10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PReLU 활성화\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal'),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal'),\n",
    "    keras.layers.PReLU(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelcompile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 2s 42us/sample - loss: 1.2949 - sparse_categorical_accuracy: 0.6155 - val_loss: 0.8806 - val_sparse_categorical_accuracy: 0.7258\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 2s 37us/sample - loss: 0.7959 - sparse_categorical_accuracy: 0.7449 - val_loss: 0.7106 - val_sparse_categorical_accuracy: 0.7742\n",
      "Epoch 3/10\n",
      "53504/55000 [============================>.] - ETA: 0s - loss: 0.6842 - sparse_categorical_accuracy: 0.7786"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(x_train, y_train, epochs = 10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELU\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'))\n",
    "\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1571241d588>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcompile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이제 훈련해 보죠. 입력을 평균 0과 표준 편차 1로 바꾸어야 한다는 것을 잊지 마세요:\n",
    "pixel_means = x_train.mean(axis=0, keepdims=True)\n",
    "pixel_stds = x_train.std(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scaled = (x_train - pixel_means) / pixel_stds\n",
    "x_valid_scaled = (x_valid - pixel_means) / pixel_stds\n",
    "x_test_scaled = (x_test - pixel_means) / pixel_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 15s 280us/sample - loss: 1.2270 - sparse_categorical_accuracy: 0.5284 - val_loss: 0.9843 - val_sparse_categorical_accuracy: 0.6518\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 13s 243us/sample - loss: 0.7812 - sparse_categorical_accuracy: 0.7162 - val_loss: 0.6596 - val_sparse_categorical_accuracy: 0.7604\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 14s 250us/sample - loss: 0.6517 - sparse_categorical_accuracy: 0.7650 - val_loss: 0.6367 - val_sparse_categorical_accuracy: 0.7696\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 13s 240us/sample - loss: 0.6248 - sparse_categorical_accuracy: 0.7795 - val_loss: 0.5482 - val_sparse_categorical_accuracy: 0.8060\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 13s 241us/sample - loss: 0.6069 - sparse_categorical_accuracy: 0.7899 - val_loss: 0.6136 - val_sparse_categorical_accuracy: 0.7898\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 5, validation_data=(x_valid_scaled, y_valid) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "model.add(keras.layers.Dense(300, activation='relu', kernel_initializer='he_normal'))\n",
    "for layer in range(99):\n",
    "    model.add(keras.layers.Dense(100, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x15732027108>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcompile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/5\n",
      "55000/55000 [==============================] - 13s 242us/sample - loss: 1.9406 - sparse_categorical_accuracy: 0.2599 - val_loss: 1.9570 - val_sparse_categorical_accuracy: 0.2394\n",
      "Epoch 2/5\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 1.3449 - sparse_categorical_accuracy: 0.4602 - val_loss: 0.9059 - val_sparse_categorical_accuracy: 0.6606\n",
      "Epoch 3/5\n",
      "55000/55000 [==============================] - 11s 206us/sample - loss: 0.9194 - sparse_categorical_accuracy: 0.6304 - val_loss: 0.9223 - val_sparse_categorical_accuracy: 0.6374\n",
      "Epoch 4/5\n",
      "55000/55000 [==============================] - 11s 202us/sample - loss: 1.0759 - sparse_categorical_accuracy: 0.5682 - val_loss: 0.9257 - val_sparse_categorical_accuracy: 0.6042\n",
      "Epoch 5/5\n",
      "55000/55000 [==============================] - 11s 201us/sample - loss: 0.7768 - sparse_categorical_accuracy: 0.6842 - val_loss: 0.7739 - val_sparse_categorical_accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 5, validation_data = (x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Nomarlizaion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Nomarlization #1\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_4 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x1573b6923c8>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelcompile(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 64us/sample - loss: 0.8406 - sparse_categorical_accuracy: 0.7154 - val_loss: 0.5499 - val_sparse_categorical_accuracy: 0.8150\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.5718 - sparse_categorical_accuracy: 0.8041 - val_loss: 0.4775 - val_sparse_categorical_accuracy: 0.8344\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.5133 - sparse_categorical_accuracy: 0.8219 - val_loss: 0.4398 - val_sparse_categorical_accuracy: 0.8470\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.4796 - sparse_categorical_accuracy: 0.8330 - val_loss: 0.4214 - val_sparse_categorical_accuracy: 0.8512\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4563 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.4050 - val_sparse_categorical_accuracy: 0.8584\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4368 - sparse_categorical_accuracy: 0.8469 - val_loss: 0.3914 - val_sparse_categorical_accuracy: 0.8628\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4220 - sparse_categorical_accuracy: 0.8510 - val_loss: 0.3825 - val_sparse_categorical_accuracy: 0.8660\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4107 - sparse_categorical_accuracy: 0.8558 - val_loss: 0.3741 - val_sparse_categorical_accuracy: 0.8692\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.4001 - sparse_categorical_accuracy: 0.8588 - val_loss: 0.3682 - val_sparse_categorical_accuracy: 0.8710\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.3892 - sparse_categorical_accuracy: 0.8627 - val_loss: 0.3624 - val_sparse_categorical_accuracy: 0.8728\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Nomarlization #2\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(100, use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('relu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 1.0667 - sparse_categorical_accuracy: 0.6676 - val_loss: 0.6909 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.6911 - sparse_categorical_accuracy: 0.7787 - val_loss: 0.5654 - val_sparse_categorical_accuracy: 0.8174\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.6013 - sparse_categorical_accuracy: 0.8031 - val_loss: 0.5067 - val_sparse_categorical_accuracy: 0.8354\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.5494 - sparse_categorical_accuracy: 0.8168 - val_loss: 0.4718 - val_sparse_categorical_accuracy: 0.8472\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.5185 - sparse_categorical_accuracy: 0.8252 - val_loss: 0.4478 - val_sparse_categorical_accuracy: 0.8520\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.4924 - sparse_categorical_accuracy: 0.8328 - val_loss: 0.4294 - val_sparse_categorical_accuracy: 0.8546\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.4753 - sparse_categorical_accuracy: 0.8386 - val_loss: 0.4162 - val_sparse_categorical_accuracy: 0.8586\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4595 - sparse_categorical_accuracy: 0.8420 - val_loss: 0.4054 - val_sparse_categorical_accuracy: 0.8612\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.4470 - sparse_categorical_accuracy: 0.8450 - val_loss: 0.3961 - val_sparse_categorical_accuracy: 0.8618\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 54us/sample - loss: 0.4361 - sparse_categorical_accuracy: 0.8492 - val_loss: 0.3881 - val_sparse_categorical_accuracy: 0.8676\n"
     ]
    }
   ],
   "source": [
    "modelcompile(model)\n",
    "history = model.fit(x_train, y_train, epochs = 10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Nomarlization #3\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(10, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_214 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "dense_215 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_216 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 271,346\n",
      "Trainable params: 268,978\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_6/gamma:0', True),\n",
       " ('batch_normalization_6/beta:0', True),\n",
       " ('batch_normalization_6/moving_mean:0', False),\n",
       " ('batch_normalization_6/moving_variance:0', False)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(var.name, var.trainable) for var in model.layers[1].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Operation 'cond/Identity' type=Identity>,\n",
       " <tf.Operation 'cond_1/Identity' type=Identity>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers[1].updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 65us/sample - loss: 0.8502 - sparse_categorical_accuracy: 0.7091 - val_loss: 0.5834 - val_sparse_categorical_accuracy: 0.8028\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.5960 - sparse_categorical_accuracy: 0.7931 - val_loss: 0.5039 - val_sparse_categorical_accuracy: 0.8264\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.5384 - sparse_categorical_accuracy: 0.8120 - val_loss: 0.4694 - val_sparse_categorical_accuracy: 0.8412\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.5070 - sparse_categorical_accuracy: 0.8238 - val_loss: 0.4470 - val_sparse_categorical_accuracy: 0.8498\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 58us/sample - loss: 0.4861 - sparse_categorical_accuracy: 0.8297 - val_loss: 0.4335 - val_sparse_categorical_accuracy: 0.8528\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.4699 - sparse_categorical_accuracy: 0.8351 - val_loss: 0.4221 - val_sparse_categorical_accuracy: 0.8552\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.4577 - sparse_categorical_accuracy: 0.8375 - val_loss: 0.4126 - val_sparse_categorical_accuracy: 0.8582\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.4466 - sparse_categorical_accuracy: 0.8434 - val_loss: 0.4058 - val_sparse_categorical_accuracy: 0.8572\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 56us/sample - loss: 0.4399 - sparse_categorical_accuracy: 0.8449 - val_loss: 0.3993 - val_sparse_categorical_accuracy: 0.8610\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4294 - sparse_categorical_accuracy: 0.8486 - val_loss: 0.3923 - val_sparse_categorical_accuracy: 0.8646\n"
     ]
    }
   ],
   "source": [
    "modelcompile(model)\n",
    "history = model.fit(x_train, y_train, epochs = 10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch Nomarlization #4\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(300, kernel_initializer='he_normal', use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.Dense(100, kernel_initializer='he_normal', use_bias=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Activation('elu'),\n",
    "    keras.layers.Dense(10, activation='softmax'),    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_7 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_217 (Dense)            (None, 300)               235200    \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 300)               1200      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_218 (Dense)            (None, 100)               30000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_219 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 270,946\n",
      "Trainable params: 268,578\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('batch_normalization_10/gamma:0', True),\n",
       " ('batch_normalization_10/beta:0', True),\n",
       " ('batch_normalization_10/moving_mean:0', False),\n",
       " ('batch_normalization_10/moving_variance:0', False)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(model.summary())\n",
    "[(var.name, var.trainable) for var in model.layers[3].variables]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 66us/sample - loss: 0.9100 - sparse_categorical_accuracy: 0.7022 - val_loss: 0.6224 - val_sparse_categorical_accuracy: 0.7972\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.6237 - sparse_categorical_accuracy: 0.7887 - val_loss: 0.5377 - val_sparse_categorical_accuracy: 0.8212\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.5617 - sparse_categorical_accuracy: 0.8074 - val_loss: 0.4970 - val_sparse_categorical_accuracy: 0.8348\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.5288 - sparse_categorical_accuracy: 0.8191 - val_loss: 0.4720 - val_sparse_categorical_accuracy: 0.8418\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.5086 - sparse_categorical_accuracy: 0.8248 - val_loss: 0.4544 - val_sparse_categorical_accuracy: 0.8488\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4915 - sparse_categorical_accuracy: 0.8299 - val_loss: 0.4430 - val_sparse_categorical_accuracy: 0.8534\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4784 - sparse_categorical_accuracy: 0.8341 - val_loss: 0.4328 - val_sparse_categorical_accuracy: 0.8528\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4667 - sparse_categorical_accuracy: 0.8382 - val_loss: 0.4230 - val_sparse_categorical_accuracy: 0.8580\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4570 - sparse_categorical_accuracy: 0.8405 - val_loss: 0.4169 - val_sparse_categorical_accuracy: 0.8622\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.4503 - sparse_categorical_accuracy: 0.8433 - val_loss: 0.4110 - val_sparse_categorical_accuracy: 0.8634\n"
     ]
    }
   ],
   "source": [
    "modelcompile(model)\n",
    "history = model.fit(x_train, y_train, epochs = 10, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 그레이디언트 클리핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클리핑이 벡터의 방향을 바꾸지 못하게 할려면 clipvalue -> clipnorm\n",
    "optimizer = keras.optimizers.SGD(clipvalue = 1.0)\n",
    "optimizer = keras.optimizers.SGD(clipnorm = 1.0)\n",
    "model.compile(loss='mse', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 사전 훈련된 층 재사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(x, y):\n",
    "    y_5_or_6 = (y==5) | (y==6)\n",
    "    y_A = y[~y_5_or_6]\n",
    "    y_A[y_A > 6] -= 2\n",
    "    y_B = (y[y_5_or_6] ==6).astype(np.float32)\n",
    "    \n",
    "    return ((x[~y_5_or_6], y_A), (x[y_5_or_6], y_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_A, y_train_A), (x_train_B, y_train_B) = split_dataset(x_train, y_train)\n",
    "(x_valid_A, y_valid_A), (x_valid_B, y_valid_B) = split_dataset(x_valid, y_valid)\n",
    "(x_test_A, y_test_A), (x_test_B, y_test_B) = split_dataset(x_test, y_test)\n",
    "x_train_B = x_train_B[:200]\n",
    "y_train_B = y_train_B[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((43986, 28, 28), (200, 28, 28))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_A.shape, x_train_B.shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([4, 0, 5, 7, 7, 7, 4, 4, 3, 4, 0, 1, 6, 3, 4, 3, 2, 6, 5, 3, 4, 5,\n",
       "        1, 3, 4, 2, 0, 6, 7, 1], dtype=uint8),\n",
       " array([1., 1., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1.], dtype=float32))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_A[:30], y_train_B[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.Sequential()\n",
    "model_A.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_A.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
    "model_A.add(keras.layers.Dense(8, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 43986 samples, validate on 4014 samples\n",
      "Epoch 1/20\n",
      "43986/43986 [==============================] - 2s 47us/sample - loss: 0.5766 - sparse_categorical_accuracy: 0.8155 - val_loss: 0.3742 - val_sparse_categorical_accuracy: 0.8797\n",
      "Epoch 2/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.3514 - sparse_categorical_accuracy: 0.8814 - val_loss: 0.3205 - val_sparse_categorical_accuracy: 0.8924\n",
      "Epoch 3/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.3158 - sparse_categorical_accuracy: 0.8914 - val_loss: 0.3069 - val_sparse_categorical_accuracy: 0.8936\n",
      "Epoch 4/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2978 - sparse_categorical_accuracy: 0.8982 - val_loss: 0.2838 - val_sparse_categorical_accuracy: 0.9056\n",
      "Epoch 5/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2856 - sparse_categorical_accuracy: 0.9012 - val_loss: 0.2778 - val_sparse_categorical_accuracy: 0.9076\n",
      "Epoch 6/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2764 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.2701 - val_sparse_categorical_accuracy: 0.9081\n",
      "Epoch 7/20\n",
      "43986/43986 [==============================] - 2s 39us/sample - loss: 0.2690 - sparse_categorical_accuracy: 0.9076 - val_loss: 0.2652 - val_sparse_categorical_accuracy: 0.9118\n",
      "Epoch 8/20\n",
      "43986/43986 [==============================] - 2s 39us/sample - loss: 0.2623 - sparse_categorical_accuracy: 0.9111 - val_loss: 0.2585 - val_sparse_categorical_accuracy: 0.9118\n",
      "Epoch 9/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2573 - sparse_categorical_accuracy: 0.9119 - val_loss: 0.2550 - val_sparse_categorical_accuracy: 0.9143\n",
      "Epoch 10/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2525 - sparse_categorical_accuracy: 0.9139 - val_loss: 0.2537 - val_sparse_categorical_accuracy: 0.9145\n",
      "Epoch 11/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2486 - sparse_categorical_accuracy: 0.9154 - val_loss: 0.2732 - val_sparse_categorical_accuracy: 0.9013\n",
      "Epoch 12/20\n",
      "43986/43986 [==============================] - 2s 39us/sample - loss: 0.2447 - sparse_categorical_accuracy: 0.9167 - val_loss: 0.2478 - val_sparse_categorical_accuracy: 0.9168\n",
      "Epoch 13/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2409 - sparse_categorical_accuracy: 0.9178 - val_loss: 0.2502 - val_sparse_categorical_accuracy: 0.9131\n",
      "Epoch 14/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2380 - sparse_categorical_accuracy: 0.9187 - val_loss: 0.2492 - val_sparse_categorical_accuracy: 0.9131\n",
      "Epoch 15/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2350 - sparse_categorical_accuracy: 0.9197 - val_loss: 0.2508 - val_sparse_categorical_accuracy: 0.9131\n",
      "Epoch 16/20\n",
      "43986/43986 [==============================] - 2s 37us/sample - loss: 0.2326 - sparse_categorical_accuracy: 0.9196 - val_loss: 0.2414 - val_sparse_categorical_accuracy: 0.9185\n",
      "Epoch 17/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2298 - sparse_categorical_accuracy: 0.9209 - val_loss: 0.2396 - val_sparse_categorical_accuracy: 0.9178\n",
      "Epoch 18/20\n",
      "43986/43986 [==============================] - 2s 39us/sample - loss: 0.2276 - sparse_categorical_accuracy: 0.9224 - val_loss: 0.2365 - val_sparse_categorical_accuracy: 0.9190\n",
      "Epoch 19/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2247 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.2343 - val_sparse_categorical_accuracy: 0.9203\n",
      "Epoch 20/20\n",
      "43986/43986 [==============================] - 2s 38us/sample - loss: 0.2227 - sparse_categorical_accuracy: 0.9238 - val_loss: 0.2355 - val_sparse_categorical_accuracy: 0.9198\n"
     ]
    }
   ],
   "source": [
    "modelcompile(model_A)\n",
    "history_A = model_A.fit(x_train_A, y_train_A, epochs=20, validation_data=(x_valid_A, y_valid_A))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.save('.\\models\\my_model_A.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B = keras.models.Sequential()\n",
    "model_B.add(keras.layers.Flatten(input_shape=[28, 28]))\n",
    "for n_hidden in (300, 100, 50, 50, 50):\n",
    "    model_B.add(keras.layers.Dense(n_hidden, activation='selu'))\n",
    "model_B.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.compile(loss=\"binary_crossentropy\",\n",
    "                optimizer='sgd',\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.5037 - accuracy: 0.7500 - val_loss: 0.1158 - val_accuracy: 0.9817\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.0800 - accuracy: 0.9950 - val_loss: 0.0806 - val_accuracy: 0.9838\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0536 - accuracy: 0.9950 - val_loss: 0.0658 - val_accuracy: 0.9868\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.0415 - accuracy: 0.9950 - val_loss: 0.0572 - val_accuracy: 0.9858\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0334 - accuracy: 0.9950 - val_loss: 0.0520 - val_accuracy: 0.9858\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0280 - accuracy: 0.9950 - val_loss: 0.0478 - val_accuracy: 0.9868\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0240 - accuracy: 0.9950 - val_loss: 0.0459 - val_accuracy: 0.9868\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0210 - accuracy: 0.9950 - val_loss: 0.0431 - val_accuracy: 0.9878\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0184 - accuracy: 0.9950 - val_loss: 0.0410 - val_accuracy: 0.9899\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.0162 - accuracy: 0.9950 - val_loss: 0.0396 - val_accuracy: 0.9899\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 0s 194us/sample - loss: 0.0144 - accuracy: 1.0000 - val_loss: 0.0392 - val_accuracy: 0.9899\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0372 - val_accuracy: 0.9899\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 0s 175us/sample - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0354 - val_accuracy: 0.9909\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.0104 - accuracy: 1.0000 - val_loss: 0.0344 - val_accuracy: 0.9909\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0337 - val_accuracy: 0.9909\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 0s 189us/sample - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0329 - val_accuracy: 0.9919\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0325 - val_accuracy: 0.9919\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.0075 - accuracy: 1.0000 - val_loss: 0.0321 - val_accuracy: 0.9919\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 0s 177us/sample - loss: 0.0070 - accuracy: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9919\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 0s 194us/sample - loss: 0.0066 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9919\n"
     ]
    }
   ],
   "source": [
    "hitory_B =  model_B.fit(x_train_B, y_train_B, epochs=20, validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_B.save('.\\models\\my_model_B.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = keras.models.load_model('.\\models\\my_model_A.h5')\n",
    "model_B_on_A = keras.models.Sequential(model_A.layers[:-1])\n",
    "model_B_on_A.add(keras.layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A_clone = keras.models.clone_model(model_A)\n",
    "model_A_clone.set_weights(model_A.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model_B_on_A.compile(loss = 'binary_crossentropy', optimizer ='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/4\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 1.1185 - accuracy: 0.4350 - val_loss: 0.7842 - val_accuracy: 0.5913\n",
      "Epoch 2/4\n",
      "200/200 [==============================] - 0s 175us/sample - loss: 0.6545 - accuracy: 0.6500 - val_loss: 0.4983 - val_accuracy: 0.7465\n",
      "Epoch 3/4\n",
      "200/200 [==============================] - 0s 170us/sample - loss: 0.4268 - accuracy: 0.7850 - val_loss: 0.3580 - val_accuracy: 0.8550\n",
      "Epoch 4/4\n",
      "200/200 [==============================] - 0s 160us/sample - loss: 0.3136 - accuracy: 0.8700 - val_loss: 0.2818 - val_accuracy: 0.9026\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(x_train_B, y_train_B, epochs=4, validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model_B_on_A.layers[:-1]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(1e-4)\n",
    "model_B_on_A.compile(loss=\"binary_crossentropy\",\n",
    "                    optimizer = optimizer,\n",
    "                    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 200 samples, validate on 986 samples\n",
      "Epoch 1/16\n",
      "200/200 [==============================] - 0s 2ms/sample - loss: 0.2670 - accuracy: 0.9200 - val_loss: 0.2741 - val_accuracy: 0.9067\n",
      "Epoch 2/16\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.2595 - accuracy: 0.9300 - val_loss: 0.2666 - val_accuracy: 0.9097\n",
      "Epoch 3/16\n",
      "200/200 [==============================] - 0s 175us/sample - loss: 0.2521 - accuracy: 0.9350 - val_loss: 0.2594 - val_accuracy: 0.9189\n",
      "Epoch 4/16\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.2451 - accuracy: 0.9350 - val_loss: 0.2528 - val_accuracy: 0.9229\n",
      "Epoch 5/16\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.2386 - accuracy: 0.9400 - val_loss: 0.2463 - val_accuracy: 0.9249\n",
      "Epoch 6/16\n",
      "200/200 [==============================] - 0s 194us/sample - loss: 0.2321 - accuracy: 0.9400 - val_loss: 0.2408 - val_accuracy: 0.9249\n",
      "Epoch 7/16\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.2267 - accuracy: 0.9450 - val_loss: 0.2354 - val_accuracy: 0.9270\n",
      "Epoch 8/16\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.2215 - accuracy: 0.9450 - val_loss: 0.2303 - val_accuracy: 0.9280\n",
      "Epoch 9/16\n",
      "200/200 [==============================] - 0s 194us/sample - loss: 0.2163 - accuracy: 0.9450 - val_loss: 0.2252 - val_accuracy: 0.9320\n",
      "Epoch 10/16\n",
      "200/200 [==============================] - 0s 197us/sample - loss: 0.2113 - accuracy: 0.9500 - val_loss: 0.2203 - val_accuracy: 0.9371\n",
      "Epoch 11/16\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.2064 - accuracy: 0.9550 - val_loss: 0.2154 - val_accuracy: 0.9391\n",
      "Epoch 12/16\n",
      "200/200 [==============================] - 0s 189us/sample - loss: 0.2016 - accuracy: 0.9550 - val_loss: 0.2110 - val_accuracy: 0.9432\n",
      "Epoch 13/16\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.1973 - accuracy: 0.9600 - val_loss: 0.2068 - val_accuracy: 0.9462\n",
      "Epoch 14/16\n",
      "200/200 [==============================] - 0s 185us/sample - loss: 0.1931 - accuracy: 0.9600 - val_loss: 0.2027 - val_accuracy: 0.9503\n",
      "Epoch 15/16\n",
      "200/200 [==============================] - 0s 182us/sample - loss: 0.1890 - accuracy: 0.9650 - val_loss: 0.1990 - val_accuracy: 0.9523\n",
      "Epoch 16/16\n",
      "200/200 [==============================] - 0s 180us/sample - loss: 0.1852 - accuracy: 0.9650 - val_loss: 0.1951 - val_accuracy: 0.9523\n"
     ]
    }
   ],
   "source": [
    "history = model_B_on_A.fit(x_train_B, y_train_B, epochs=16, validation_data=(x_valid_B, y_valid_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.1978 - accuracy: 0.9495\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.19782071059942247, 0.9495]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B_on_A.evaluate(x_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 0s 21us/sample - loss: 0.0220 - accuracy: 0.9950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.022031672105193138, 0.995]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_B.evaluate(x_test_B, y_test_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 고속 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모멘텀 최적화 0.9에서 보통 잘 작동됨. == momentum\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9)\n",
    "\n",
    "# 네스테로프 가속 경사  == nesterov , monentum 도 같이 해야함\n",
    "optimizer = keras.optimizers.SGD(lr=0.001, momentum = 0.9, nesterov = True)\n",
    "\n",
    "# AdaGrad\n",
    "optimizer = keras.optimizers.Adagrad(lr=0.001)\n",
    "\n",
    "# RMSProp\n",
    "opmizer = keras.optimizers.RMSprop(lr = 0.001, rho=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adam Optimizer basic init\n",
    "optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "# AdaMax / Nadam  Adam 변종 최적화\n",
    "# AdamMax -> 실전에선 Adam보다 안정적이지만 성능이 더 낮음\n",
    "# Adam이 잘 작도오디지 않는다면 시도해볼 옵디마이저 중 하나\n",
    "optimizer = keras.optimizers.Adamax(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
    "# Nadam -> Adam + newterov\n",
    "optimizer = keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 스케줄링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 거듭제근 기반 스케줄링 -> decay 매개변수만 지정\n",
    "optimizer = keras.optimizers.SGD(lr=0.01, decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 2s 40us/sample - loss: 0.5874 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.4599 - val_sparse_categorical_accuracy: 0.8432\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.4517 - sparse_categorical_accuracy: 0.8409 - val_loss: 0.4241 - val_sparse_categorical_accuracy: 0.8512\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.4227 - sparse_categorical_accuracy: 0.8508 - val_loss: 0.4370 - val_sparse_categorical_accuracy: 0.8452\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.4058 - sparse_categorical_accuracy: 0.8564 - val_loss: 0.3996 - val_sparse_categorical_accuracy: 0.8634\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3938 - sparse_categorical_accuracy: 0.8607 - val_loss: 0.3982 - val_sparse_categorical_accuracy: 0.8594\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3839 - sparse_categorical_accuracy: 0.8653 - val_loss: 0.4081 - val_sparse_categorical_accuracy: 0.8552\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3767 - sparse_categorical_accuracy: 0.8662 - val_loss: 0.3768 - val_sparse_categorical_accuracy: 0.8688\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3691 - sparse_categorical_accuracy: 0.8695 - val_loss: 0.3865 - val_sparse_categorical_accuracy: 0.8620\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3637 - sparse_categorical_accuracy: 0.8712 - val_loss: 0.3718 - val_sparse_categorical_accuracy: 0.8690\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3584 - sparse_categorical_accuracy: 0.8725 - val_loss: 0.3674 - val_sparse_categorical_accuracy: 0.8704\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3550 - sparse_categorical_accuracy: 0.8738 - val_loss: 0.3631 - val_sparse_categorical_accuracy: 0.8714\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3506 - sparse_categorical_accuracy: 0.8760 - val_loss: 0.3641 - val_sparse_categorical_accuracy: 0.8702\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3471 - sparse_categorical_accuracy: 0.8768 - val_loss: 0.3625 - val_sparse_categorical_accuracy: 0.8728\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3437 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.3604 - val_sparse_categorical_accuracy: 0.8732\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3410 - sparse_categorical_accuracy: 0.8790 - val_loss: 0.3590 - val_sparse_categorical_accuracy: 0.8714\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3376 - sparse_categorical_accuracy: 0.8800 - val_loss: 0.3556 - val_sparse_categorical_accuracy: 0.8758\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 2s 35us/sample - loss: 0.3351 - sparse_categorical_accuracy: 0.8806 - val_loss: 0.3524 - val_sparse_categorical_accuracy: 0.8742\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3323 - sparse_categorical_accuracy: 0.8816 - val_loss: 0.3561 - val_sparse_categorical_accuracy: 0.8726\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3298 - sparse_categorical_accuracy: 0.8819 - val_loss: 0.3533 - val_sparse_categorical_accuracy: 0.8760\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3282 - sparse_categorical_accuracy: 0.8833 - val_loss: 0.3497 - val_sparse_categorical_accuracy: 0.8770\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3261 - sparse_categorical_accuracy: 0.8831 - val_loss: 0.3585 - val_sparse_categorical_accuracy: 0.8778\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3238 - sparse_categorical_accuracy: 0.8853 - val_loss: 0.3483 - val_sparse_categorical_accuracy: 0.8760\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3224 - sparse_categorical_accuracy: 0.8854 - val_loss: 0.3539 - val_sparse_categorical_accuracy: 0.8734\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3204 - sparse_categorical_accuracy: 0.8865 - val_loss: 0.3485 - val_sparse_categorical_accuracy: 0.8756\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 2s 34us/sample - loss: 0.3194 - sparse_categorical_accuracy: 0.8864 - val_loss: 0.3457 - val_sparse_categorical_accuracy: 0.8766\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer = optimizer,\n",
    "             metrics = [keras.metrics.sparse_categorical_accuracy])\n",
    "n_epochs = 25\n",
    "history = model.fit(x_train, y_train, epochs=n_epochs, validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "decay = 1e-4\n",
    "batch_size = 32\n",
    "n_steps_per_epoch = len(x_train) // batch_size\n",
    "epochs = np.arange(n_epochs)\n",
    "lrs = learning_rate / (1 + decay * epochs * n_steps_per_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, lrs,  \"o-\")\n",
    "plt.axis([0, n_epochs - 1, 0, 0.01])\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Power Scheduling\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지수 기반 스케일링\n",
    "def exponential_decay_fn(epoch):\n",
    "    return 0.01 * 0.1 **(epoch/20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return 0.01 * 0.1 **(epoch/20)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0 = 0.01, s = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer = 'nadam',\n",
    "             metrics = ['accuracy'])\n",
    "n_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/25\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.8464 - accuracy: 0.7589 - val_loss: 0.6881 - val_accuracy: 0.8044\n",
      "Epoch 2/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.6563 - accuracy: 0.8022 - val_loss: 0.6128 - val_accuracy: 0.8168\n",
      "Epoch 3/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.5846 - accuracy: 0.8205 - val_loss: 0.5814 - val_accuracy: 0.7914\n",
      "Epoch 4/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.5370 - accuracy: 0.8341 - val_loss: 0.5250 - val_accuracy: 0.8486\n",
      "Epoch 5/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.4747 - accuracy: 0.8525 - val_loss: 0.6173 - val_accuracy: 0.8010\n",
      "Epoch 6/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.4422 - accuracy: 0.8607 - val_loss: 0.4674 - val_accuracy: 0.8684\n",
      "Epoch 7/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.4170 - accuracy: 0.8676 - val_loss: 0.4624 - val_accuracy: 0.8604\n",
      "Epoch 8/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.3878 - accuracy: 0.8753 - val_loss: 0.4553 - val_accuracy: 0.8688\n",
      "Epoch 9/25\n",
      "55000/55000 [==============================] - 3s 59us/sample - loss: 0.3483 - accuracy: 0.8855 - val_loss: 0.4214 - val_accuracy: 0.8754\n",
      "Epoch 10/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.3230 - accuracy: 0.8929 - val_loss: 0.4632 - val_accuracy: 0.8702\n",
      "Epoch 11/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.3093 - accuracy: 0.8998 - val_loss: 0.5386 - val_accuracy: 0.8680\n",
      "Epoch 12/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2798 - accuracy: 0.9075 - val_loss: 0.4363 - val_accuracy: 0.8770\n",
      "Epoch 13/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2553 - accuracy: 0.9145 - val_loss: 0.4114 - val_accuracy: 0.8878\n",
      "Epoch 14/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2396 - accuracy: 0.9200 - val_loss: 0.4350 - val_accuracy: 0.8834\n",
      "Epoch 15/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2264 - accuracy: 0.9249 - val_loss: 0.4873 - val_accuracy: 0.8806\n",
      "Epoch 16/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.2078 - accuracy: 0.9306 - val_loss: 0.4983 - val_accuracy: 0.8842\n",
      "Epoch 17/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.1929 - accuracy: 0.9352 - val_loss: 0.4542 - val_accuracy: 0.8872\n",
      "Epoch 18/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.1826 - accuracy: 0.9405 - val_loss: 0.4832 - val_accuracy: 0.8832\n",
      "Epoch 19/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.1717 - accuracy: 0.9439 - val_loss: 0.5003 - val_accuracy: 0.8816\n",
      "Epoch 20/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.1560 - accuracy: 0.9482 - val_loss: 0.5634 - val_accuracy: 0.8852\n",
      "Epoch 21/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.1481 - accuracy: 0.9515 - val_loss: 0.5238 - val_accuracy: 0.8860\n",
      "Epoch 22/25\n",
      "55000/55000 [==============================] - 3s 63us/sample - loss: 0.1369 - accuracy: 0.9558 - val_loss: 0.5402 - val_accuracy: 0.8898\n",
      "Epoch 23/25\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.1280 - accuracy: 0.9581 - val_loss: 0.5596 - val_accuracy: 0.8932\n",
      "Epoch 24/25\n",
      "55000/55000 [==============================] - 3s 61us/sample - loss: 0.1174 - accuracy: 0.9627 - val_loss: 0.5709 - val_accuracy: 0.8862\n",
      "Epoch 25/25\n",
      "55000/55000 [==============================] - 3s 60us/sample - loss: 0.1091 - accuracy: 0.9656 - val_loss: 0.5779 - val_accuracy: 0.8906\n"
     ]
    }
   ],
   "source": [
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "history = model.fit(x_train_scaled, y_train, epochs = n_epochs, validation_data=(x_valid_scaled, y_valid), callbacks=[lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epochs, lrs, \"-\", linewidth=2)\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.title(\"Exponential Scheduling (per batch)\", fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 규제를 사용해 과대적합 피하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l1과 l2 규제\n",
    "layer = keras.layers.Dense(100, activation='elu', \n",
    "                           kernel_initializer='he_normal', \n",
    "                           kernel_regularizer=keras.regularizers.l2(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dense(300, activation ='elu',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(100, activation ='elu',\n",
    "                      kernel_initializer='he_normal',\n",
    "                      kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "    keras.layers.Dense(300, activation ='softmax',\n",
    "                      kernel_regularizer=keras.regularizers.l2(0.01)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer = keras.optimizers.Nadam(),\n",
    "             metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 5s 86us/sample - loss: 1.4536 - sparse_categorical_accuracy: 0.8043 - val_loss: 0.8336 - val_sparse_categorical_accuracy: 0.7860\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.7543 - sparse_categorical_accuracy: 0.8244 - val_loss: 0.7283 - val_sparse_categorical_accuracy: 0.8354\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Refactoring\n",
    "from functools import partial\n",
    "\n",
    "RegularizedDense = partial(keras.layers.Dense,\n",
    "                          activation='elu',\n",
    "                          kernel_initializer = 'he_normal',\n",
    "                          kernel_regularizer = keras.regularizers.l2(0.01))\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    RegularizedDense(300),\n",
    "    RegularizedDense(100),\n",
    "    RegularizedDense(10, activation='softmax', kernel_initializer='glorot_uniform')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer = keras.optimizers.Nadam(),\n",
    "             metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 1.6002 - sparse_categorical_accuracy: 0.8123 - val_loss: 0.7244 - val_sparse_categorical_accuracy: 0.8302\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 4s 68us/sample - loss: 0.7185 - sparse_categorical_accuracy: 0.8282 - val_loss: 0.7158 - val_sparse_categorical_accuracy: 0.8258\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs=2, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DropOut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(300, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(100, activation='elu', kernel_initializer='he_normal'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer = keras.optimizers.Nadam(),\n",
    "             metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 5s 83us/sample - loss: 0.5723 - sparse_categorical_accuracy: 0.8025 - val_loss: 0.3798 - val_sparse_categorical_accuracy: 0.8570\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 4s 75us/sample - loss: 0.4252 - sparse_categorical_accuracy: 0.8450 - val_loss: 0.3457 - val_sparse_categorical_accuracy: 0.8690\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs =2 , validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELU base dropout\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    keras.layers.AlphaDropout(0.2),\n",
    "    keras.layers.Dense(300, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.AlphaDropout(0.2),\n",
    "    keras.layers.Dense(100, activation='selu', kernel_initializer='lecun_normal'),\n",
    "    keras.layers.AlphaDropout(0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "optimizer = keras.optimizers.SGD(lr = 0.01, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer =optimizer,\n",
    "             metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/2\n",
      "55000/55000 [==============================] - 3s 64us/sample - loss: 0.6578 - sparse_categorical_accuracy: 0.7589 - val_loss: 0.6375 - val_sparse_categorical_accuracy: 0.8308\n",
      "Epoch 2/2\n",
      "55000/55000 [==============================] - 3s 55us/sample - loss: 0.5532 - sparse_categorical_accuracy: 0.7973 - val_loss: 0.5928 - val_sparse_categorical_accuracy: 0.8410\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs =2 , validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 19us/sample - loss: 0.6596 - sparse_categorical_accuracy: 0.8255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6596381865978241, 0.8255]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 19us/sample - loss: 0.6596 - sparse_categorical_accuracy: 0.8255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6596381865978241, 0.8255]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples\n",
      "55000/55000 [==============================] - 3s 53us/sample - loss: 0.5284 - sparse_categorical_accuracy: 0.8039\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monete Carlo dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer flatten_15 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_probas = np.stack([model(x_test_scaled, training=True) for sample in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_proba = y_probas.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_std = y_probas.std(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.07, 0.  , 0.8 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(x_test_scaled[:1]), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.05, 0.01, 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.66, 0.  , 0.19, 0.  , 0.15]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.12, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.84, 0.  , 0.01, 0.  , 0.15]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.07, 0.  , 0.5 , 0.  , 0.44]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.23, 0.  , 0.72]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.04, 0.  , 0.8 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.18, 0.  , 0.76]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.35, 0.  , 0.33, 0.  , 0.32]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.32, 0.  , 0.15, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.02, 0.02, 0.88]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.53, 0.  , 0.35, 0.  , 0.13]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.4 , 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.54, 0.  , 0.33]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.65, 0.  , 0.19, 0.  , 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.07, 0.  , 0.75]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.3 , 0.  , 0.06, 0.  , 0.63]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.24, 0.  , 0.34, 0.04, 0.37]],\n",
       "\n",
       "       [[0.  , 0.  , 0.02, 0.  , 0.05, 0.07, 0.4 , 0.02, 0.27, 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.41, 0.  , 0.14, 0.  , 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.36, 0.11, 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.78, 0.  , 0.01, 0.  , 0.21]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.13, 0.  , 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.7 , 0.  , 0.23]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.13, 0.  , 0.06, 0.01, 0.81]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.81, 0.  , 0.06, 0.  , 0.13]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.5 , 0.  , 0.12, 0.  , 0.38]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.19, 0.  , 0.77, 0.  , 0.04]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.33, 0.  , 0.57, 0.02, 0.07]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.19, 0.  , 0.23]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.14, 0.  , 0.13, 0.  , 0.74]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.09, 0.01, 0.33]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.06, 0.  , 0.64]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.16, 0.  , 0.54, 0.  , 0.3 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.38, 0.  , 0.2 , 0.  , 0.42]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.92, 0.  , 0.02, 0.  , 0.06]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.62, 0.  , 0.09, 0.  , 0.29]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.56, 0.01, 0.34]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.63, 0.  , 0.32]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.06, 0.  , 0.25, 0.  , 0.69]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.01, 0.  , 0.72, 0.  , 0.03, 0.  , 0.23]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.  , 0.08, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.27, 0.  , 0.57, 0.  , 0.15]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.29, 0.  , 0.63]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.22, 0.02, 0.46]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.  , 0.03, 0.01, 0.62]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.47, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.1 , 0.  , 0.22, 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.  , 0.23, 0.  , 0.02]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.02, 0.  , 0.82, 0.  , 0.17]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.51, 0.  , 0.31]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.49, 0.  , 0.45]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.05, 0.  , 0.74, 0.01, 0.19]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.81, 0.  , 0.14, 0.  , 0.05]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.87, 0.  , 0.02, 0.  , 0.12]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.33, 0.  , 0.5 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.75, 0.  , 0.17, 0.  , 0.08]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.27, 0.  , 0.31]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.61, 0.  , 0.17, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.09, 0.  , 0.08, 0.  , 0.83]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.21, 0.  , 0.16, 0.01, 0.62]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.04, 0.  , 0.02, 0.  , 0.94]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.34, 0.  , 0.07, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.71, 0.  , 0.04, 0.  , 0.26]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.3 , 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.42, 0.  , 0.04, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.31, 0.  , 0.29, 0.  , 0.4 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.01, 0.41, 0.03, 0.06, 0.  , 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.01, 0.  , 0.  , 0.31, 0.04, 0.43, 0.04, 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.53, 0.  , 0.25, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.11, 0.  , 0.47, 0.02, 0.41]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.01, 0.01, 0.95]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.68, 0.  , 0.26, 0.  , 0.06]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.99, 0.  , 0.  , 0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.66, 0.  , 0.11, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.03, 0.  , 0.73, 0.  , 0.24]],\n",
       "\n",
       "       [[0.  , 0.  , 0.01, 0.  , 0.  , 0.2 , 0.02, 0.23, 0.  , 0.53]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.08, 0.  , 0.33, 0.  , 0.59]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.12, 0.  , 0.49]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.81, 0.  , 0.05, 0.  , 0.13]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.54, 0.  , 0.3 , 0.  , 0.16]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.25, 0.  , 0.55, 0.01, 0.19]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.7 , 0.  , 0.18, 0.01, 0.11]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.44, 0.  , 0.02, 0.  , 0.54]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.91, 0.  , 0.05, 0.02, 0.02]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.17, 0.  , 0.16, 0.  , 0.66]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.23, 0.  , 0.06, 0.  , 0.71]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.7 , 0.  , 0.08, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.53, 0.  , 0.04, 0.  , 0.43]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.52, 0.  , 0.41, 0.  , 0.06]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.41, 0.  , 0.46, 0.03, 0.1 ]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.43, 0.  , 0.26, 0.  , 0.31]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.63, 0.  , 0.15, 0.  , 0.22]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.15, 0.  , 0.67, 0.  , 0.18]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.92, 0.  , 0.07, 0.  , 0.01]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.18, 0.  , 0.5 , 0.  , 0.32]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.53, 0.  , 0.09, 0.  , 0.38]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.29, 0.  , 0.03, 0.  , 0.68]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.58, 0.  , 0.23, 0.  , 0.19]],\n",
       "\n",
       "       [[0.  , 0.  , 0.  , 0.  , 0.  , 0.26, 0.  , 0.23, 0.  , 0.51]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_probas[:, :1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.37, 0.01, 0.24, 0.01, 0.38]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_proba[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.01, 0.27, 0.04, 0.21, 0.03, 0.25]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(y_std[:1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8424"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.argmax(y_proba, axis=1)\n",
    "accuracy = np.sum(y_pred == y_test) / len(y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BatchNormalization 층과 같은 층을 가지고 있으면 훈련 모드를 강제로 설정하면 안됨.\n",
    "# 대신 dropout 층 아래와 같은 클래스를 작성하여 변경할 것\n",
    "class MCDropout(keras.layers.Dropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training =True)\n",
    "class MCAlphaDropout(keras.layers.AlphaDropout):\n",
    "    def call(self, inputs):\n",
    "        return super().call(inputs, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model = keras.models.Sequential([\n",
    "    MCAlphaDropout(layer.rate) if isinstance(layer, keras.layers.AlphaDropout) else layer\n",
    "    for layer in model.layers\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_15 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout (MCAlphaDro (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 300)               235500    \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_1 (MCAlphaD (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "mc_alpha_dropout_2 (MCAlphaD (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 266,610\n",
      "Trainable params: 266,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.SGD(lr =0.01, momentum=0.9, nesterov=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.compile( loss = keras.losses.sparse_categorical_crossentropy,\n",
    "                optimizer = optimizer,\n",
    "                metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_model.set_weights(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.  , 0.  , 0.  , 0.39, 0.  , 0.22, 0.01, 0.37]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 윗 단계를 해야 mcDropout을 사용 할 수 있음.\n",
    "np.round(np.mean([mc_model.predict(x_test_scaled[:1]) for sample in range(100)], axis=0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAX-Norm 규제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(100, activation='elu', \n",
    "                           kernel_initializer='he_normal', \n",
    "                           kernel_constraint=keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "MaxNormDense = partial(keras.layers.Dense,\n",
    "                      activation = 'selu', kernel_initializer='lecun_normal',\n",
    "                      kernel_constraint = keras.constraints.max_norm(1.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]),\n",
    "    MaxNormDense(300),\n",
    "    MaxNormDense(100),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = keras.losses.sparse_categorical_crossentropy,\n",
    "             optimizer = keras.optimizers.Nadam(),\n",
    "             metrics = [keras.metrics.sparse_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 55000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3296 - sparse_categorical_accuracy: 0.8779 - val_loss: 0.3365 - val_sparse_categorical_accuracy: 0.8780\n",
      "Epoch 2/10\n",
      "55000/55000 [==============================] - 4s 71us/sample - loss: 0.3178 - sparse_categorical_accuracy: 0.8817 - val_loss: 0.3460 - val_sparse_categorical_accuracy: 0.8776\n",
      "Epoch 3/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3115 - sparse_categorical_accuracy: 0.8836 - val_loss: 0.3453 - val_sparse_categorical_accuracy: 0.8752\n",
      "Epoch 4/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3063 - sparse_categorical_accuracy: 0.8858 - val_loss: 0.3665 - val_sparse_categorical_accuracy: 0.8698\n",
      "Epoch 5/10\n",
      "55000/55000 [==============================] - 4s 79us/sample - loss: 0.3072 - sparse_categorical_accuracy: 0.8863 - val_loss: 0.3368 - val_sparse_categorical_accuracy: 0.8786\n",
      "Epoch 6/10\n",
      "55000/55000 [==============================] - 4s 76us/sample - loss: 0.3043 - sparse_categorical_accuracy: 0.8881 - val_loss: 0.3338 - val_sparse_categorical_accuracy: 0.8800\n",
      "Epoch 7/10\n",
      "55000/55000 [==============================] - 4s 70us/sample - loss: 0.3028 - sparse_categorical_accuracy: 0.8872 - val_loss: 0.3733 - val_sparse_categorical_accuracy: 0.8628\n",
      "Epoch 8/10\n",
      "55000/55000 [==============================] - 4s 72us/sample - loss: 0.2990 - sparse_categorical_accuracy: 0.8880 - val_loss: 0.3300 - val_sparse_categorical_accuracy: 0.8862\n",
      "Epoch 9/10\n",
      "55000/55000 [==============================] - 4s 77us/sample - loss: 0.3008 - sparse_categorical_accuracy: 0.8877 - val_loss: 0.3708 - val_sparse_categorical_accuracy: 0.8720\n",
      "Epoch 10/10\n",
      "55000/55000 [==============================] - 32404s 589ms/sample - loss: 0.2970 - sparse_categorical_accuracy: 0.8882 - val_loss: 0.3497 - val_sparse_categorical_accuracy: 0.8762\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train_scaled, y_train, epochs = 10, validation_data=(x_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
